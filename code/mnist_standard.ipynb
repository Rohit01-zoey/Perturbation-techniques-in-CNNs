{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "#fetch the mnist dataset\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_n = x.to_numpy()\n",
    "x_n = x\n",
    "#y_n = y.to_numpy()\n",
    "y_n = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 784) (7000, 784) (63000,) (7000,)\n",
      "(784, 63000) (784, 7000)\n"
     ]
    }
   ],
   "source": [
    "y_n = y_n.astype('int') #convert output to integers 0-9\n",
    "x_norm = x_n/255.0 #normalise input data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_norm, y_n, test_size=0.1, random_state=42) #split the data into train and validation\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "x_train = x_train.T #take the transpose of the training data m*784 -> 784*m\n",
    "x_val = x_val.T #take the transpose of the test data m*784 -> 784*m\n",
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_init(mu, sigma):\n",
    "  np.random.seed(2)\n",
    "\n",
    "  gauss_w1 = np.random.normal(mu, sigma, (400, 784))\n",
    "  gauss_b1 = np.random.normal(mu, sigma, (400, 1))\n",
    "  gauss_w2 = np.random.normal(mu, sigma, (250, 400))\n",
    "  gauss_b2 = np.random.normal(mu, sigma, (250, 1))\n",
    "  gauss_w3 = np.random.normal(mu, sigma, (200, 250))\n",
    "  gauss_b3 = np.random.normal(mu, sigma, (200, 1))\n",
    "  gauss_w4 = np.random.normal(mu, sigma, (50, 200))\n",
    "  gauss_b4 = np.random.normal(mu, sigma, (50, 1))\n",
    "  gauss_w5 = np.random.normal(mu, sigma, (10, 50))\n",
    "  gauss_b5 = np.random.normal(mu, sigma, (10, 1)) \n",
    "\n",
    "  gauss_w1[gauss_w1 < 0.1] = 0.1\n",
    "  gauss_b1[gauss_b1 < 0.1] = 0.1\n",
    "  gauss_w2[gauss_w2 < 0.1] = 0.1\n",
    "  gauss_b2[gauss_b2 < 0.1] = 0.1  \n",
    "  gauss_w3[gauss_w3 < 0.1] = 0.1\n",
    "  gauss_b3[gauss_b3 < 0.1] = 0.1 \n",
    "  gauss_w4[gauss_w4 < 0.1] = 0.1\n",
    "  gauss_b4[gauss_b4 < 0.1] = 0.1 \n",
    "  gauss_w5[gauss_w5 < 0.1] = 0.1\n",
    "  gauss_b5[gauss_b5 < 0.1] = 0.1 \n",
    "\n",
    "\n",
    "  return (gauss_w1, gauss_b1, gauss_w2, gauss_b2, gauss_w3, gauss_b3, gauss_w4, gauss_b4, gauss_w5, gauss_b5)\n",
    "  \n",
    "#have to change with different number of layers\n",
    "def params_init():\n",
    "\n",
    "  np.random.seed(2)\n",
    "  W1 = np.random.rand(400,784) - 0.5\n",
    "  b1 = np.random.rand(400,1) - 0.5\n",
    "  W2 = np.random.rand(250,400) - 0.5\n",
    "  b2 = np.random.rand(250,1) - 0.5\n",
    "  W3 = np.random.rand(200,250) - 0.5 \n",
    "  b3 = np.random.rand(200,1) - 0.5\n",
    "  W4 = np.random.rand(50,200) - 0.5   \n",
    "  b4 = np.random.rand(50,1) - 0.5    \n",
    "  W5 = np.random.rand(10,50) - 0.5  \n",
    "  b5 = np.random.rand(10,1) - 0.5    \n",
    "  print(\"Params Initialised\")\n",
    "\n",
    "  return (W1, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def forward(x_train, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5):\n",
    "  #print(\"Entered FP\")\n",
    "  Z1 = np.matmul(W1,x_train) + b1 #W1 is 50*784, x_train is 748*m, Z1 is 50*m\n",
    "  A1 = relu(Z1)\n",
    "\n",
    "  Z2 = np.matmul(W2,A1) + b2 \n",
    "  A2 = relu(Z2)\n",
    "\n",
    "  Z3 = np.matmul(W3,A2) + b3\n",
    "  A3 = relu(Z3)\n",
    "  \n",
    "  Z4 = np.matmul(W4,A3) + b4\n",
    "  A4 = relu(Z4)\n",
    "\n",
    "  Z5 = np.matmul(W5,A4) + b5\n",
    "  A5 = softmax(Z5)\n",
    "\n",
    "  #W2 is 10*50, A1 is 50*m\n",
    "  # print(np.exp(Z2))\n",
    "  # print(np.sum(np.exp(Z2)))\n",
    "\n",
    "  #A2 is 10*m, final predictions\n",
    "  # print(\"Fp Done\")\n",
    "\n",
    "  return Z1, A1, Z2, A2, Z3, A3, Z4, A4, Z5, A5\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "   return np.maximum(x,0)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "  return np.exp(Z) / np.sum(np.exp(Z),0)\n",
    "\n",
    "\n",
    "def relu_d(x):\n",
    "  return x>0\n",
    "\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "  shape = (y.shape[0], 10)\n",
    "  one_hot = np.zeros(shape)\n",
    "  rows = np.arange(y.size)\n",
    "  one_hot[rows, y] = 1\n",
    "  return one_hot.T\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def backprop(Z1, A1, Z2, A2, Z3, A3, Z4, A4, Z5, A5, W1, W2, W3, W4, W5, X, y):\n",
    "  # print(\"Entered Backprop\")\n",
    "  m = y.shape[0] #m is the number of training examples\n",
    "  Y = one_hot_encoding(y)\n",
    "\n",
    "  dZ5 = (A5 - Y)\n",
    "  \n",
    "  dW5 = 1/m*np.matmul(dZ5,A4.T)\n",
    "\n",
    "  db5 = 1/m*np.sum(dZ5)\n",
    "\n",
    "  dZ4 = np.matmul(W5.T, dZ5)*relu_d(Z4)  #shape of A2, Y, dZ2 = 10*m\n",
    "\n",
    "  dW4 = 1/m*np.matmul(dZ4,A3.T) #shape of dZ2 is 10*m, A1 is 50*m, dW2 = 10*50\n",
    "\n",
    "  db4 = 1/m*np.sum(dZ4) #db1 is 50,1\n",
    "\n",
    "  dZ3 = np.matmul(W4.T, dZ4)*relu_d(Z3)  #shape of A2, Y, dZ2 = 10*m\n",
    "\n",
    "  dW3 = 1/m*np.matmul(dZ3,A2.T) #shape of dZ2 is 10*m, A1 is 50*m, dW2 = 10*50\n",
    "\n",
    "  db3 = 1/m*np.sum(dZ3) #db1 is 50,1\n",
    "\n",
    "  dZ2 = np.matmul(W3.T, dZ3)*relu_d(Z2) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db2 = 1/m*np.sum(dZ2) #db1 is 50*1\n",
    "\n",
    "  dZ1 = np.matmul(W2.T, dZ2)*relu_d(Z1) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW1 = 1/m*np.matmul(dZ1,X.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db1 = 1/m*np.sum(dZ1) #db1 is 50*1\n",
    "\n",
    "\n",
    "  return dW1, db1, dW2, db2, dW3, db3, dW4, db4, dW5, db5\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def param_update(W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, dW1, db1, dW2, db2, dW3, db3, dW4, db4, dW5, db5, lr, factor):\n",
    "\n",
    "  #updates the parameters based on backpropogation and decay rate\n",
    "  #decay = np.exp(factor)\n",
    "\n",
    "  #W1 = W1*np.exp(-5*factor) - lr*dW1\n",
    "  #b1 = b1*np.exp(-5*factor) - lr*db1\n",
    "  #W2 = W2*np.exp(-4*factor) - lr*dW2\n",
    "  #b2 = b2*np.exp(-4*factor) - lr*db2\n",
    "  #W3 = W3*np.exp(-3*factor) - lr*dW3\n",
    "  #b3 = b3*np.exp(-3*factor) - lr*db3\n",
    "  #W4 = W4*np.exp(-2*factor) - lr*dW4\n",
    "  #b4 = b4*np.exp(-2*factor) - lr*db4\n",
    "  #W5 = W5*np.exp(-1*factor) - lr*dW5\n",
    "  #b5 = b5*np.exp(-1*factor) - lr*db5\n",
    "\n",
    "  W1 = W1 - lr*dW1\n",
    "  b1 = b1 - lr*db1\n",
    "  W2 = W2 - lr*dW2\n",
    "  b2 = b2 - lr*db2\n",
    "  W3 = W3 - lr*dW3\n",
    "  b3 = b3 - lr*db3\n",
    "  W4 = W4 - lr*dW4\n",
    "  b4 = b4 - lr*db4\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, W4, b4, W5, b5\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def grad_descent(X,Y,iter, lr, print_op, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3, W4, b4, W5, b5 = params_init()\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630],random_state = 3) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3, Z4, A4, Z5, A5 = forward(X1, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3, dW4, db4, dW5, db5 = backprop(Z1, A1, Z2, A2, Z3, A3, Z4, A4, Z5, A5, W1, W2, W3, W4, W5, X1, Y1)\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3, W4, b4, W5, b5 = param_update(W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, dW1, db1, dW2, db2, dW3, db3, dW4, db4, dW5, db5, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, _, _, _, _, A5_train = forward(X, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A5_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _, _, _, _, _, A5_val = forward(x_val, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A5_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "def predictions(A):\n",
    "  #argmax returns the index of maximum value, we will feed the sigmoid output to this function \n",
    "  return np.argmax(A,0)\n",
    "\n",
    "\n",
    "def accuracy(A,Y):\n",
    "  #this will compare the predicted output to the ground truth\n",
    "  return np.sum(A == Y)/Y.shape[0]*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.64216912, 1.39439907, 1.25496977, ..., 0.74765953, 1.04911182,\n",
       "        0.836776  ],\n",
       "       [0.18802981, 0.86990418, 0.93236434, ..., 1.15288235, 0.19606468,\n",
       "        0.72459413],\n",
       "       [0.13304573, 1.12252183, 0.9635371 , ..., 1.44661342, 1.50232978,\n",
       "        1.56696072],\n",
       "       ...,\n",
       "       [1.24097613, 1.2226803 , 0.70459404, ..., 1.02941433, 0.91141151,\n",
       "        1.18248608],\n",
       "       [0.68897542, 1.66844111, 0.84355318, ..., 1.45458812, 0.37232834,\n",
       "        1.0448195 ],\n",
       "       [1.34528938, 1.28740747, 1.31651719, ..., 1.24924178, 1.4962482 ,\n",
       "        2.05080316]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_w1 = np.random.normal(1, 0.4, (400, 784))\n",
    "gauss_w1[gauss_w1<0.1]=0.1\n",
    "gauss_w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 22.36190476190476\n",
      "Val accuracy: 23.085714285714285\n",
      "Iteration: 2\n",
      "Train accuracy: 25.112698412698414\n",
      "Val accuracy: 25.428571428571427\n",
      "Iteration: 3\n",
      "Train accuracy: 29.807936507936507\n",
      "Val accuracy: 29.542857142857144\n",
      "Iteration: 4\n",
      "Train accuracy: 35.612698412698414\n",
      "Val accuracy: 35.4\n",
      "Iteration: 5\n",
      "Train accuracy: 41.13174603174603\n",
      "Val accuracy: 40.92857142857143\n",
      "Iteration: 6\n",
      "Train accuracy: 46.5031746031746\n",
      "Val accuracy: 46.07142857142857\n",
      "Iteration: 7\n",
      "Train accuracy: 51.11904761904762\n",
      "Val accuracy: 50.44285714285714\n",
      "Iteration: 8\n",
      "Train accuracy: 54.95873015873016\n",
      "Val accuracy: 54.41428571428572\n",
      "Iteration: 9\n",
      "Train accuracy: 58.05873015873016\n",
      "Val accuracy: 57.31428571428572\n",
      "Iteration: 10\n",
      "Train accuracy: 60.87619047619047\n",
      "Val accuracy: 59.94285714285714\n",
      "Iteration: 11\n",
      "Train accuracy: 63.30476190476191\n",
      "Val accuracy: 62.07142857142857\n",
      "Iteration: 12\n",
      "Train accuracy: 65.46349206349207\n",
      "Val accuracy: 64.1\n",
      "Iteration: 13\n",
      "Train accuracy: 67.24920634920635\n",
      "Val accuracy: 65.81428571428572\n",
      "Iteration: 14\n",
      "Train accuracy: 68.81111111111112\n",
      "Val accuracy: 67.44285714285714\n",
      "Iteration: 15\n",
      "Train accuracy: 70.41587301587302\n",
      "Val accuracy: 68.95714285714286\n",
      "Iteration: 16\n",
      "Train accuracy: 71.74126984126984\n",
      "Val accuracy: 70.37142857142857\n",
      "Iteration: 17\n",
      "Train accuracy: 72.92857142857143\n",
      "Val accuracy: 71.51428571428572\n",
      "Iteration: 18\n",
      "Train accuracy: 74.02380952380952\n",
      "Val accuracy: 72.34285714285714\n",
      "Iteration: 19\n",
      "Train accuracy: 75.08253968253969\n",
      "Val accuracy: 73.58571428571429\n",
      "Iteration: 20\n",
      "Train accuracy: 75.93809523809524\n",
      "Val accuracy: 74.31428571428572\n",
      "Iteration: 21\n",
      "Train accuracy: 76.8\n",
      "Val accuracy: 74.92857142857143\n",
      "Iteration: 22\n",
      "Train accuracy: 77.52063492063492\n",
      "Val accuracy: 75.68571428571428\n",
      "Iteration: 23\n",
      "Train accuracy: 78.16984126984127\n",
      "Val accuracy: 76.32857142857142\n",
      "Iteration: 24\n",
      "Train accuracy: 78.77460317460317\n",
      "Val accuracy: 76.87142857142857\n",
      "Iteration: 25\n",
      "Train accuracy: 79.3047619047619\n",
      "Val accuracy: 77.62857142857142\n",
      "Iteration: 26\n",
      "Train accuracy: 79.91111111111111\n",
      "Val accuracy: 78.22857142857143\n",
      "Iteration: 27\n",
      "Train accuracy: 80.43174603174603\n",
      "Val accuracy: 78.68571428571428\n",
      "Iteration: 28\n",
      "Train accuracy: 80.87301587301587\n",
      "Val accuracy: 79.02857142857142\n",
      "Iteration: 29\n",
      "Train accuracy: 81.28888888888889\n",
      "Val accuracy: 79.47142857142858\n",
      "Iteration: 30\n",
      "Train accuracy: 81.68888888888888\n",
      "Val accuracy: 79.84285714285714\n",
      "Iteration: 31\n",
      "Train accuracy: 82.08730158730158\n",
      "Val accuracy: 80.10000000000001\n",
      "Iteration: 32\n",
      "Train accuracy: 82.41904761904762\n",
      "Val accuracy: 80.32857142857142\n",
      "Iteration: 33\n",
      "Train accuracy: 82.76349206349207\n",
      "Val accuracy: 80.55714285714286\n",
      "Iteration: 34\n",
      "Train accuracy: 83.07142857142857\n",
      "Val accuracy: 80.81428571428572\n",
      "Iteration: 35\n",
      "Train accuracy: 83.39047619047619\n",
      "Val accuracy: 81.18571428571428\n",
      "Iteration: 36\n",
      "Train accuracy: 83.68095238095238\n",
      "Val accuracy: 81.41428571428571\n",
      "Iteration: 37\n",
      "Train accuracy: 83.93650793650794\n",
      "Val accuracy: 81.71428571428572\n",
      "Iteration: 38\n",
      "Train accuracy: 84.1952380952381\n",
      "Val accuracy: 81.89999999999999\n",
      "Iteration: 39\n",
      "Train accuracy: 84.45396825396826\n",
      "Val accuracy: 82.25714285714287\n",
      "Iteration: 40\n",
      "Train accuracy: 84.69047619047619\n",
      "Val accuracy: 82.51428571428572\n",
      "Iteration: 41\n",
      "Train accuracy: 84.92222222222222\n",
      "Val accuracy: 82.74285714285713\n",
      "Iteration: 42\n",
      "Train accuracy: 85.15396825396824\n",
      "Val accuracy: 83.01428571428572\n",
      "Iteration: 43\n",
      "Train accuracy: 85.31746031746032\n",
      "Val accuracy: 83.24285714285715\n",
      "Iteration: 44\n",
      "Train accuracy: 85.51587301587301\n",
      "Val accuracy: 83.58571428571429\n",
      "Iteration: 45\n",
      "Train accuracy: 85.70793650793651\n",
      "Val accuracy: 83.7\n",
      "Iteration: 46\n",
      "Train accuracy: 85.86507936507937\n",
      "Val accuracy: 83.82857142857144\n",
      "Iteration: 47\n",
      "Train accuracy: 86.07936507936508\n",
      "Val accuracy: 83.92857142857143\n",
      "Iteration: 48\n",
      "Train accuracy: 86.25396825396825\n",
      "Val accuracy: 84.2\n",
      "Iteration: 49\n",
      "Train accuracy: 86.41428571428571\n",
      "Val accuracy: 84.3\n",
      "Iteration: 50\n",
      "Train accuracy: 86.6\n",
      "Val accuracy: 84.45714285714286\n",
      "Iteration: 51\n",
      "Train accuracy: 86.76507936507937\n",
      "Val accuracy: 84.64285714285714\n",
      "Iteration: 52\n",
      "Train accuracy: 86.91428571428571\n",
      "Val accuracy: 84.85714285714285\n",
      "Iteration: 53\n",
      "Train accuracy: 87.0984126984127\n",
      "Val accuracy: 85.02857142857142\n",
      "Iteration: 54\n",
      "Train accuracy: 87.24920634920636\n",
      "Val accuracy: 85.1\n",
      "Iteration: 55\n",
      "Train accuracy: 87.41587301587302\n",
      "Val accuracy: 85.22857142857143\n",
      "Iteration: 56\n",
      "Train accuracy: 87.55714285714285\n",
      "Val accuracy: 85.45714285714286\n",
      "Iteration: 57\n",
      "Train accuracy: 87.68412698412699\n",
      "Val accuracy: 85.54285714285714\n",
      "Iteration: 58\n",
      "Train accuracy: 87.84603174603176\n",
      "Val accuracy: 85.58571428571429\n",
      "Iteration: 59\n",
      "Train accuracy: 87.97301587301587\n",
      "Val accuracy: 85.74285714285715\n",
      "Iteration: 60\n",
      "Train accuracy: 88.0968253968254\n",
      "Val accuracy: 85.97142857142858\n",
      "Iteration: 61\n",
      "Train accuracy: 88.21904761904761\n",
      "Val accuracy: 86.12857142857143\n",
      "Iteration: 62\n",
      "Train accuracy: 88.32222222222222\n",
      "Val accuracy: 86.25714285714285\n",
      "Iteration: 63\n",
      "Train accuracy: 88.45396825396826\n",
      "Val accuracy: 86.31428571428572\n",
      "Iteration: 64\n",
      "Train accuracy: 88.56190476190477\n",
      "Val accuracy: 86.41428571428571\n",
      "Iteration: 65\n",
      "Train accuracy: 88.71269841269842\n",
      "Val accuracy: 86.4857142857143\n",
      "Iteration: 66\n",
      "Train accuracy: 88.81428571428572\n",
      "Val accuracy: 86.5142857142857\n",
      "Iteration: 67\n",
      "Train accuracy: 88.92222222222223\n",
      "Val accuracy: 86.6\n",
      "Iteration: 68\n",
      "Train accuracy: 89.02698412698413\n",
      "Val accuracy: 86.68571428571428\n",
      "Iteration: 69\n",
      "Train accuracy: 89.14126984126985\n",
      "Val accuracy: 86.77142857142857\n",
      "Iteration: 70\n",
      "Train accuracy: 89.26666666666667\n",
      "Val accuracy: 86.8\n",
      "Iteration: 71\n",
      "Train accuracy: 89.3984126984127\n",
      "Val accuracy: 86.82857142857144\n",
      "Iteration: 72\n",
      "Train accuracy: 89.4968253968254\n",
      "Val accuracy: 86.88571428571429\n",
      "Iteration: 73\n",
      "Train accuracy: 89.6015873015873\n",
      "Val accuracy: 87.0\n",
      "Iteration: 74\n",
      "Train accuracy: 89.73174603174603\n",
      "Val accuracy: 87.1\n",
      "Iteration: 75\n",
      "Train accuracy: 89.83174603174604\n",
      "Val accuracy: 87.1\n",
      "Iteration: 76\n",
      "Train accuracy: 89.91111111111111\n",
      "Val accuracy: 87.14285714285714\n",
      "Iteration: 77\n",
      "Train accuracy: 89.9920634920635\n",
      "Val accuracy: 87.24285714285715\n",
      "Iteration: 78\n",
      "Train accuracy: 90.07142857142857\n",
      "Val accuracy: 87.31428571428572\n",
      "Iteration: 79\n",
      "Train accuracy: 90.17936507936508\n",
      "Val accuracy: 87.35714285714286\n",
      "Iteration: 80\n",
      "Train accuracy: 90.27142857142857\n",
      "Val accuracy: 87.38571428571429\n",
      "Iteration: 81\n",
      "Train accuracy: 90.33492063492064\n",
      "Val accuracy: 87.47142857142856\n",
      "Iteration: 82\n",
      "Train accuracy: 90.42063492063492\n",
      "Val accuracy: 87.5142857142857\n",
      "Iteration: 83\n",
      "Train accuracy: 90.49047619047619\n",
      "Val accuracy: 87.6\n",
      "Iteration: 84\n",
      "Train accuracy: 90.57619047619048\n",
      "Val accuracy: 87.74285714285715\n",
      "Iteration: 85\n",
      "Train accuracy: 90.64285714285715\n",
      "Val accuracy: 87.78571428571429\n",
      "Iteration: 86\n",
      "Train accuracy: 90.6952380952381\n",
      "Val accuracy: 87.8\n",
      "Iteration: 87\n",
      "Train accuracy: 90.75396825396825\n",
      "Val accuracy: 87.78571428571429\n",
      "Iteration: 88\n",
      "Train accuracy: 90.83650793650794\n",
      "Val accuracy: 87.81428571428572\n",
      "Iteration: 89\n",
      "Train accuracy: 90.9063492063492\n",
      "Val accuracy: 87.82857142857144\n",
      "Iteration: 90\n",
      "Train accuracy: 90.9968253968254\n",
      "Val accuracy: 87.88571428571429\n",
      "Iteration: 91\n",
      "Train accuracy: 91.05555555555556\n",
      "Val accuracy: 88.04285714285714\n",
      "Iteration: 92\n",
      "Train accuracy: 91.12222222222222\n",
      "Val accuracy: 88.08571428571429\n",
      "Iteration: 93\n",
      "Train accuracy: 91.20793650793651\n",
      "Val accuracy: 88.1\n",
      "Iteration: 94\n",
      "Train accuracy: 91.26984126984127\n",
      "Val accuracy: 88.07142857142857\n",
      "Iteration: 95\n",
      "Train accuracy: 91.31428571428572\n",
      "Val accuracy: 88.11428571428571\n",
      "Iteration: 96\n",
      "Train accuracy: 91.36666666666666\n",
      "Val accuracy: 88.14285714285714\n",
      "Iteration: 97\n",
      "Train accuracy: 91.43650793650794\n",
      "Val accuracy: 88.15714285714286\n",
      "Iteration: 98\n",
      "Train accuracy: 91.5\n",
      "Val accuracy: 88.2\n",
      "Iteration: 99\n",
      "Train accuracy: 91.54126984126985\n",
      "Val accuracy: 88.28571428571429\n",
      "Iteration: 100\n",
      "Train accuracy: 91.62698412698413\n",
      "Val accuracy: 88.31428571428572\n",
      "Iteration: 101\n",
      "Train accuracy: 91.6920634920635\n",
      "Val accuracy: 88.34285714285714\n",
      "Iteration: 102\n",
      "Train accuracy: 91.75555555555556\n",
      "Val accuracy: 88.35714285714286\n",
      "Iteration: 103\n",
      "Train accuracy: 91.79523809523809\n",
      "Val accuracy: 88.4\n",
      "Iteration: 104\n",
      "Train accuracy: 91.85079365079365\n",
      "Val accuracy: 88.47142857142856\n",
      "Iteration: 105\n",
      "Train accuracy: 91.91269841269842\n",
      "Val accuracy: 88.5\n",
      "Iteration: 106\n",
      "Train accuracy: 91.97142857142858\n",
      "Val accuracy: 88.5142857142857\n",
      "Iteration: 107\n",
      "Train accuracy: 92.0047619047619\n",
      "Val accuracy: 88.57142857142857\n",
      "Iteration: 108\n",
      "Train accuracy: 92.05555555555556\n",
      "Val accuracy: 88.67142857142856\n",
      "Iteration: 109\n",
      "Train accuracy: 92.11428571428571\n",
      "Val accuracy: 88.7\n",
      "Iteration: 110\n",
      "Train accuracy: 92.15714285714286\n",
      "Val accuracy: 88.68571428571428\n",
      "Iteration: 111\n",
      "Train accuracy: 92.21428571428572\n",
      "Val accuracy: 88.71428571428571\n",
      "Iteration: 112\n",
      "Train accuracy: 92.27460317460317\n",
      "Val accuracy: 88.72857142857143\n",
      "Iteration: 113\n",
      "Train accuracy: 92.32380952380952\n",
      "Val accuracy: 88.74285714285715\n",
      "Iteration: 114\n",
      "Train accuracy: 92.38412698412698\n",
      "Val accuracy: 88.74285714285715\n",
      "Iteration: 115\n",
      "Train accuracy: 92.43333333333334\n",
      "Val accuracy: 88.8\n",
      "Iteration: 116\n",
      "Train accuracy: 92.4936507936508\n",
      "Val accuracy: 88.8\n",
      "Iteration: 117\n",
      "Train accuracy: 92.53650793650795\n",
      "Val accuracy: 88.82857142857142\n",
      "Iteration: 118\n",
      "Train accuracy: 92.58571428571429\n",
      "Val accuracy: 88.85714285714286\n",
      "Iteration: 119\n",
      "Train accuracy: 92.63333333333334\n",
      "Val accuracy: 88.91428571428571\n",
      "Iteration: 120\n",
      "Train accuracy: 92.70158730158731\n",
      "Val accuracy: 88.97142857142856\n",
      "Iteration: 121\n",
      "Train accuracy: 92.75396825396825\n",
      "Val accuracy: 88.9857142857143\n",
      "Iteration: 122\n",
      "Train accuracy: 92.78571428571428\n",
      "Val accuracy: 89.04285714285714\n",
      "Iteration: 123\n",
      "Train accuracy: 92.85714285714286\n",
      "Val accuracy: 89.07142857142857\n",
      "Iteration: 124\n",
      "Train accuracy: 92.9063492063492\n",
      "Val accuracy: 89.17142857142856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-86f97e0e4bb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#have to change with different number of layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-1de137e1c97e>\u001b[0m in \u001b[0;36mgrad_descent\u001b[1;34m(X, Y, iter, lr, print_op, decay_factor)\u001b[0m\n\u001b[0;32m    192\u001b[0m       \u001b[0mZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m       \u001b[0mdW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m       \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecay_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-1de137e1c97e>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(Z1, A1, Z2, A2, Z3, A3, Z4, A4, Z5, A5, W1, W2, W3, W4, W5, X, y)\u001b[0m\n\u001b[0;32m     98\u001b[0m   \u001b[1;31m# print(\"Entered Backprop\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m   \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#m is the number of training examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m   \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m   \u001b[0mdZ5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA5\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-1de137e1c97e>\u001b[0m in \u001b[0;36mone_hot_encoding\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mone_hot_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m   \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m   \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[0mone_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#have to change with different number of layers\n",
    "\n",
    "W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, train_acc, val_acc, train_loss, val_loss, sum_weights = grad_descent(x_train, y_train, iter = 400, lr =  0.01, print_op = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden Layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_init(mu, sigma):\n",
    "  np.random.seed(2)\n",
    "\n",
    "  gauss_w1 = np.random.normal(mu, sigma, (500, 784))\n",
    "  gauss_b1 = np.random.normal(mu, sigma, (500, 1))\n",
    "  gauss_w2 = np.random.normal(mu, sigma, (500, 500))\n",
    "  gauss_b2 = np.random.normal(mu, sigma, (500, 1))\n",
    "  gauss_w3 = np.random.normal(mu, sigma, (10,500))\n",
    "  gauss_b3 = np.random.normal(mu, sigma, (10, 1))\n",
    "  #gauss_w4 = np.random.normal(mu, sigma, (50, 200))\n",
    "  #gauss_b4 = np.random.normal(mu, sigma, (50, 1))\n",
    "  #gauss_w5 = np.random.normal(mu, sigma, (10, 50))\n",
    "  #gauss_b5 = np.random.normal(mu, sigma, (10, 1)) \n",
    "\n",
    "  gauss_w1[gauss_w1 < 0.1] = 0.1\n",
    "  gauss_b1[gauss_b1 < 0.1] = 0.1\n",
    "  gauss_w2[gauss_w2 < 0.1] = 0.1\n",
    "  gauss_b2[gauss_b2 < 0.1] = 0.1  \n",
    "  gauss_w3[gauss_w3 < 0.1] = 0.1\n",
    "  gauss_b3[gauss_b3 < 0.1] = 0.1 \n",
    "  #gauss_w4[gauss_w4 < 0.1] = 0.1\n",
    "  #gauss_b4[gauss_b4 < 0.1] = 0.1 \n",
    "  #gauss_w5[gauss_w5 < 0.1] = 0.1\n",
    "  #gauss_b5[gauss_b5 < 0.1] = 0.1 \n",
    "\n",
    "\n",
    "  return (gauss_w1, gauss_b1, gauss_w2, gauss_b2, gauss_w3, gauss_b3)\n",
    "  \n",
    "#have to change with different number of layers\n",
    "def params_init():\n",
    "\n",
    "  #np.random.seed(2)\n",
    "  W1 = np.random.rand(500,784) - 0.5\n",
    "  b1 = np.random.rand(500,1) - 0.5\n",
    "  W2 = np.random.rand(500,500) - 0.5\n",
    "  b2 = np.random.rand(500,1) - 0.5\n",
    "  W3 = np.random.rand(10,500) - 0.5 \n",
    "  b3 = np.random.rand(10,1) - 0.5\n",
    "  #W4 = np.random.rand(50,200) - 0.5   \n",
    "  #b4 = np.random.rand(50,1) - 0.5    \n",
    "  #W5 = np.random.rand(10,50) - 0.5  \n",
    "  #b5 = np.random.rand(10,1) - 0.5    \n",
    "  print(\"Params Initialised\")\n",
    "\n",
    "  return (W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def forward(x_train, W1, b1, W2, b2, W3, b3):\n",
    "  #print(\"Entered FP\")\n",
    "  Z1 = np.matmul(W1,x_train) + b1 #W1 is 50*784, x_train is 748*m, Z1 is 50*m\n",
    "  A1 = relu(Z1)\n",
    "\n",
    "  Z2 = np.matmul(W2,A1) + b2 \n",
    "  A2 = relu(Z2)\n",
    "\n",
    "  Z3 = np.matmul(W3,A2) + b3\n",
    "  A3 = softmax(Z3)\n",
    "  \n",
    "  #Z4 = np.matmul(W4,A3) + b4\n",
    "  #A4 = relu(Z4)\n",
    "\n",
    "  #Z5 = np.matmul(W5,A4) + b5\n",
    "  #A5 = softmax(Z5)\n",
    "\n",
    "  #W2 is 10*50, A1 is 50*m\n",
    "  # print(np.exp(Z2))\n",
    "  # print(np.sum(np.exp(Z2)))\n",
    "\n",
    "  #A2 is 10*m, final predictions\n",
    "  # print(\"Fp Done\")\n",
    "\n",
    "  return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "   return np.maximum(x,0)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "  return np.exp(Z) / np.sum(np.exp(Z),0)\n",
    "\n",
    "\n",
    "def relu_d(x):\n",
    "  return x>0\n",
    "\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "  shape = (y.shape[0], 10)\n",
    "  one_hot = np.zeros(shape)\n",
    "  rows = np.arange(y.size)\n",
    "  one_hot[rows, y] = 1\n",
    "  return one_hot.T\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, y):\n",
    "  # print(\"Entered Backprop\")\n",
    "  m = y.shape[0] #m is the number of training examples\n",
    "  Y = one_hot_encoding(y)\n",
    "\n",
    "  dZ3 = (A3 - Y)\n",
    "  \n",
    "  dW3 = 1/m*np.matmul(dZ3,A2.T)\n",
    "\n",
    "  db3 = 1/m*np.sum(dZ3, axis=1)\n",
    "\n",
    "  dZ2 = np.matmul(W3.T, dZ3)*relu_d(Z2) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db2 = 1/m*np.sum(dZ2, axis=1) #db1 is 50*1\n",
    "\n",
    "  dZ1 = np.matmul(W2.T, dZ2)*relu_d(Z1) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW1 = 1/m*np.matmul(dZ1,X.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db1 = 1/m*np.sum(dZ1, axis = 1) #db1 is 50*1\n",
    "\n",
    "\n",
    "  return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr, factor=0):\n",
    "\n",
    "  #updates the parameters based on backpropogation and decay rate\n",
    "  #decay = np.exp(factor)\n",
    "\n",
    "  #W1 = W1*np.exp(-5*factor) - lr*dW1\n",
    "  #b1 = b1*np.exp(-5*factor) - lr*db1\n",
    "  #W2 = W2*np.exp(-4*factor) - lr*dW2\n",
    "  #b2 = b2*np.exp(-4*factor) - lr*db2\n",
    "  #W3 = W3*np.exp(-3*factor) - lr*dW3\n",
    "  #b3 = b3*np.exp(-3*factor) - lr*db3\n",
    "  #W4 = W4*np.exp(-2*factor) - lr*dW4\n",
    "  #b4 = b4*np.exp(-2*factor) - lr*db4\n",
    "  #W5 = W5*np.exp(-1*factor) - lr*dW5\n",
    "  #b5 = b5*np.exp(-1*factor) - lr*db5\n",
    "\n",
    "  W1 = W1 - lr*dW1\n",
    "  b1 = b1 - lr*(db1.reshape(b1.shape))\n",
    "  W2 = W2 - lr*dW2\n",
    "  b2 = b2 - lr*(db2.reshape(b2.shape))\n",
    "  W3 = W3 - lr*dW3\n",
    "  b3 = b3 - lr*(db3.reshape(b3.shape))\n",
    "  #W4 = W4 - lr*dW4\n",
    "  #b4 = b4 - lr*db4\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "def param_update_with_variability(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, gW1, gb1, gW2, gb2, gW3, gb3, lr):\n",
    "\n",
    "  #updates the parameters based on backpropogation and decay rate\n",
    "  #decay = np.exp(factor) #calculate the decay factor\n",
    "  \n",
    "  #alpha = t/t_ret, alpha around 5e-4, t_ret around 10ms, thus t_forw aorund 5e-6\n",
    "  t_forw = 5e-6\n",
    "  decay_w1 = np.exp(-3*t_forw/gW1)\n",
    "  decay_b1 = np.exp(-3*t_forw/gb1)\n",
    "  decay_w2 = np.exp(-2*t_forw/gW2)\n",
    "  decay_b2 = np.exp(-2*t_forw/gb2)\n",
    "  decay_w3 = np.exp(-1*t_forw/gW3)\n",
    "  decay_b3 = np.exp(-1*t_forw/gb3)\n",
    "\n",
    "  W1 = W1*decay_w1 - lr*dW1\n",
    "  b1 = b1*decay_b1 - lr*(db1.reshape(b1.shape))\n",
    "  W2 = W2*decay_w2 - lr*dW2\n",
    "  b2 = b2*decay_b2 - lr*(db2.reshape(b2.shape))\n",
    "  W3 = W3*decay_w3 - lr*dW3\n",
    "  b3 = b3*decay_b3 - lr*(db3.reshape(b3.shape))\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def batch_grad_descent(X,Y,iter, lr, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "def batch_grad_descentwith_var(X,Y,iter, lr, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3 = param_update_with_variability(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3,lr)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stocastic_batch_grad_descent(X,Y,iter, lr, batchsize, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    max_value_j = 63000//batchsize\n",
    "    j = np.random.randint(0, max_value_j) #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "    X1, Y1 = shuffle(X[:, j*batchsize: (j+1)*batchsize].T,Y[j*batchsize: (j+1)*batchsize]) #shuffle each batch\n",
    "    X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "    Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "    dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "    #W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = param_update_with_variability(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3,lr)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grad_descent(X,Y,iter, lr, print_op, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    X1, Y1 = X.T, Y\n",
    "    X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "    Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "    dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "def predictions(A):\n",
    "  #argmax returns the index of maximum value, we will feed the sigmoid output to this function \n",
    "  return np.argmax(A,0)\n",
    "\n",
    "\n",
    "def accuracy(A,Y):\n",
    "  #this will compare the predicted output to the ground truth\n",
    "  return np.sum(A == Y)/Y.shape[0]*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(0.001511,3) + 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import decimal\n",
    "decimal.getcontext().prec = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context(prec=4, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999, capitals=1, clamp=0, flags=[Inexact, FloatOperation, Rounded], traps=[InvalidOperation, DivisionByZero, Overflow])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decimal.getcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('0.0001429')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decimal(0.001) / Decimal(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([Decimal(i) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('0.001000000000000000020816681711721685132943093776702880859375')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decimal(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Decimal('1.000E-24'), Decimal('1.000'), Decimal('2.000'),\n",
       "       Decimal('3.000'), Decimal('4.000'), Decimal('5.000'),\n",
       "       Decimal('6.000'), Decimal('7.000'), Decimal('8.000'),\n",
       "       Decimal('9.000')], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr+Decimal(0.000000000000000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n"
     ]
    }
   ],
   "source": [
    "W1, _, _, _, _, _ =params_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 83.10793650793651\n",
      "Val accuracy: 82.37142857142857\n",
      "Iteration: 2\n",
      "Train accuracy: 86.89047619047619\n",
      "Val accuracy: 86.04285714285714\n",
      "Iteration: 3\n",
      "Train accuracy: 88.7095238095238\n",
      "Val accuracy: 87.57142857142857\n",
      "Iteration: 4\n",
      "Train accuracy: 89.87619047619047\n",
      "Val accuracy: 88.74285714285715\n",
      "Iteration: 5\n",
      "Train accuracy: 90.7095238095238\n",
      "Val accuracy: 89.52857142857142\n",
      "Iteration: 6\n",
      "Train accuracy: 91.36825396825397\n",
      "Val accuracy: 89.85714285714286\n",
      "Iteration: 7\n",
      "Train accuracy: 91.98253968253968\n",
      "Val accuracy: 90.22857142857143\n",
      "Iteration: 8\n",
      "Train accuracy: 92.45238095238095\n",
      "Val accuracy: 90.62857142857142\n",
      "Iteration: 9\n",
      "Train accuracy: 92.87619047619047\n",
      "Val accuracy: 90.92857142857143\n",
      "Iteration: 10\n",
      "Train accuracy: 93.1984126984127\n",
      "Val accuracy: 91.14285714285715\n",
      "Iteration: 11\n",
      "Train accuracy: 93.4952380952381\n",
      "Val accuracy: 91.37142857142857\n",
      "Iteration: 12\n",
      "Train accuracy: 93.77619047619048\n",
      "Val accuracy: 91.58571428571427\n",
      "Iteration: 13\n",
      "Train accuracy: 94.05238095238096\n",
      "Val accuracy: 91.74285714285715\n",
      "Iteration: 14\n",
      "Train accuracy: 94.3015873015873\n",
      "Val accuracy: 91.9\n",
      "Iteration: 15\n",
      "Train accuracy: 94.54603174603174\n",
      "Val accuracy: 92.02857142857142\n",
      "Iteration: 16\n",
      "Train accuracy: 94.8079365079365\n",
      "Val accuracy: 92.14285714285714\n",
      "Iteration: 17\n",
      "Train accuracy: 94.98571428571428\n",
      "Val accuracy: 92.14285714285714\n",
      "Iteration: 18\n",
      "Train accuracy: 95.14761904761905\n",
      "Val accuracy: 92.35714285714286\n",
      "Iteration: 19\n",
      "Train accuracy: 95.3031746031746\n",
      "Val accuracy: 92.51428571428572\n",
      "Iteration: 20\n",
      "Train accuracy: 95.44285714285714\n",
      "Val accuracy: 92.61428571428571\n",
      "Iteration: 21\n",
      "Train accuracy: 95.54761904761905\n",
      "Val accuracy: 92.64285714285714\n",
      "Iteration: 22\n",
      "Train accuracy: 95.65238095238095\n",
      "Val accuracy: 92.64285714285714\n",
      "Iteration: 23\n",
      "Train accuracy: 95.76984126984127\n",
      "Val accuracy: 92.74285714285713\n",
      "Iteration: 24\n",
      "Train accuracy: 95.85873015873015\n",
      "Val accuracy: 92.77142857142857\n",
      "Iteration: 25\n",
      "Train accuracy: 95.96190476190476\n",
      "Val accuracy: 92.85714285714286\n",
      "Iteration: 26\n",
      "Train accuracy: 96.05873015873016\n",
      "Val accuracy: 92.97142857142858\n",
      "Iteration: 27\n",
      "Train accuracy: 96.17460317460318\n",
      "Val accuracy: 93.01428571428572\n",
      "Iteration: 28\n",
      "Train accuracy: 96.26984126984127\n",
      "Val accuracy: 93.04285714285714\n",
      "Iteration: 29\n",
      "Train accuracy: 96.36349206349206\n",
      "Val accuracy: 93.07142857142857\n",
      "Iteration: 30\n",
      "Train accuracy: 96.48253968253968\n",
      "Val accuracy: 93.08571428571429\n",
      "Iteration: 31\n",
      "Train accuracy: 96.56507936507937\n",
      "Val accuracy: 93.15714285714286\n",
      "Iteration: 32\n",
      "Train accuracy: 96.65238095238095\n",
      "Val accuracy: 93.27142857142857\n",
      "Iteration: 33\n",
      "Train accuracy: 96.73174603174604\n",
      "Val accuracy: 93.31428571428572\n",
      "Iteration: 34\n",
      "Train accuracy: 96.8079365079365\n",
      "Val accuracy: 93.28571428571428\n",
      "Iteration: 35\n",
      "Train accuracy: 96.89047619047619\n",
      "Val accuracy: 93.30000000000001\n",
      "Iteration: 36\n",
      "Train accuracy: 96.94920634920635\n",
      "Val accuracy: 93.31428571428572\n",
      "Iteration: 37\n",
      "Train accuracy: 97.02857142857142\n",
      "Val accuracy: 93.4\n",
      "Iteration: 38\n",
      "Train accuracy: 97.07460317460318\n",
      "Val accuracy: 93.44285714285714\n",
      "Iteration: 39\n",
      "Train accuracy: 97.13333333333334\n",
      "Val accuracy: 93.5\n",
      "Iteration: 40\n",
      "Train accuracy: 97.2\n",
      "Val accuracy: 93.51428571428572\n",
      "Iteration: 41\n",
      "Train accuracy: 97.27301587301588\n",
      "Val accuracy: 93.5\n",
      "Iteration: 42\n",
      "Train accuracy: 97.31587301587301\n",
      "Val accuracy: 93.48571428571428\n",
      "Iteration: 43\n",
      "Train accuracy: 97.37777777777778\n",
      "Val accuracy: 93.51428571428572\n",
      "Iteration: 44\n",
      "Train accuracy: 97.42063492063492\n",
      "Val accuracy: 93.54285714285714\n",
      "Iteration: 45\n",
      "Train accuracy: 97.46825396825398\n",
      "Val accuracy: 93.62857142857143\n",
      "Iteration: 46\n",
      "Train accuracy: 97.53015873015873\n",
      "Val accuracy: 93.68571428571428\n",
      "Iteration: 47\n",
      "Train accuracy: 97.58571428571429\n",
      "Val accuracy: 93.67142857142858\n",
      "Iteration: 48\n",
      "Train accuracy: 97.64285714285714\n",
      "Val accuracy: 93.74285714285713\n",
      "Iteration: 49\n",
      "Train accuracy: 97.7\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 50\n",
      "Train accuracy: 97.73174603174604\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 51\n",
      "Train accuracy: 97.77142857142857\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 52\n",
      "Train accuracy: 97.82222222222222\n",
      "Val accuracy: 93.74285714285713\n",
      "Iteration: 53\n",
      "Train accuracy: 97.86984126984127\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 54\n",
      "Train accuracy: 97.91587301587302\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 55\n",
      "Train accuracy: 97.96349206349207\n",
      "Val accuracy: 93.77142857142857\n",
      "Iteration: 56\n",
      "Train accuracy: 98.0142857142857\n",
      "Val accuracy: 93.8\n",
      "Iteration: 57\n",
      "Train accuracy: 98.06666666666666\n",
      "Val accuracy: 93.82857142857142\n",
      "Iteration: 58\n",
      "Train accuracy: 98.10793650793651\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 59\n",
      "Train accuracy: 98.15238095238095\n",
      "Val accuracy: 93.88571428571429\n",
      "Iteration: 60\n",
      "Train accuracy: 98.19682539682539\n",
      "Val accuracy: 93.88571428571429\n",
      "Iteration: 61\n",
      "Train accuracy: 98.23333333333333\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 62\n",
      "Train accuracy: 98.28253968253968\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 63\n",
      "Train accuracy: 98.31111111111112\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 64\n",
      "Train accuracy: 98.35714285714286\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 65\n",
      "Train accuracy: 98.40952380952382\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 66\n",
      "Train accuracy: 98.42857142857143\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 67\n",
      "Train accuracy: 98.46666666666667\n",
      "Val accuracy: 93.88571428571429\n",
      "Iteration: 68\n",
      "Train accuracy: 98.49365079365079\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 69\n",
      "Train accuracy: 98.52539682539683\n",
      "Val accuracy: 93.88571428571429\n",
      "Iteration: 70\n",
      "Train accuracy: 98.55873015873016\n",
      "Val accuracy: 93.88571428571429\n",
      "Iteration: 71\n",
      "Train accuracy: 98.5984126984127\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 72\n",
      "Train accuracy: 98.63015873015874\n",
      "Val accuracy: 93.89999999999999\n",
      "Iteration: 73\n",
      "Train accuracy: 98.64761904761905\n",
      "Val accuracy: 93.92857142857143\n",
      "Iteration: 74\n",
      "Train accuracy: 98.68095238095238\n",
      "Val accuracy: 93.95714285714286\n",
      "Iteration: 75\n",
      "Train accuracy: 98.71904761904761\n",
      "Val accuracy: 93.98571428571428\n",
      "Iteration: 76\n",
      "Train accuracy: 98.73968253968253\n",
      "Val accuracy: 94.0\n",
      "Iteration: 77\n",
      "Train accuracy: 98.77936507936508\n",
      "Val accuracy: 94.0\n",
      "Iteration: 78\n",
      "Train accuracy: 98.8047619047619\n",
      "Val accuracy: 93.98571428571428\n",
      "Iteration: 79\n",
      "Train accuracy: 98.83333333333333\n",
      "Val accuracy: 93.98571428571428\n",
      "Iteration: 80\n",
      "Train accuracy: 98.86666666666667\n",
      "Val accuracy: 93.98571428571428\n",
      "Iteration: 81\n",
      "Train accuracy: 98.8984126984127\n",
      "Val accuracy: 93.98571428571428\n",
      "Iteration: 82\n",
      "Train accuracy: 98.92222222222222\n",
      "Val accuracy: 93.97142857142858\n",
      "Iteration: 83\n",
      "Train accuracy: 98.94920634920635\n",
      "Val accuracy: 93.95714285714286\n",
      "Iteration: 84\n",
      "Train accuracy: 98.98253968253968\n",
      "Val accuracy: 93.97142857142858\n",
      "Iteration: 85\n",
      "Train accuracy: 99.0079365079365\n",
      "Val accuracy: 93.97142857142858\n",
      "Iteration: 86\n",
      "Train accuracy: 99.03492063492064\n",
      "Val accuracy: 93.97142857142858\n",
      "Iteration: 87\n",
      "Train accuracy: 99.05714285714285\n",
      "Val accuracy: 93.97142857142858\n",
      "Iteration: 88\n",
      "Train accuracy: 99.08253968253969\n",
      "Val accuracy: 93.97142857142858\n",
      "Iteration: 89\n",
      "Train accuracy: 99.10317460317461\n",
      "Val accuracy: 94.0\n",
      "Iteration: 90\n",
      "Train accuracy: 99.11904761904762\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 91\n",
      "Train accuracy: 99.14920634920635\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 92\n",
      "Train accuracy: 99.16190476190476\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 93\n",
      "Train accuracy: 99.18412698412699\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 94\n",
      "Train accuracy: 99.20952380952382\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 95\n",
      "Train accuracy: 99.22698412698414\n",
      "Val accuracy: 94.0\n",
      "Iteration: 96\n",
      "Train accuracy: 99.24285714285715\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 97\n",
      "Train accuracy: 99.25555555555555\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 98\n",
      "Train accuracy: 99.27777777777777\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 99\n",
      "Train accuracy: 99.29523809523809\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 100\n",
      "Train accuracy: 99.31269841269841\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 101\n",
      "Train accuracy: 99.33968253968254\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 102\n",
      "Train accuracy: 99.36031746031746\n",
      "Val accuracy: 94.0\n",
      "Iteration: 103\n",
      "Train accuracy: 99.37460317460317\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 104\n",
      "Train accuracy: 99.3888888888889\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 105\n",
      "Train accuracy: 99.39682539682539\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 106\n",
      "Train accuracy: 99.40793650793651\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 107\n",
      "Train accuracy: 99.42222222222222\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 108\n",
      "Train accuracy: 99.43333333333332\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 109\n",
      "Train accuracy: 99.44920634920635\n",
      "Val accuracy: 94.05714285714286\n",
      "Iteration: 110\n",
      "Train accuracy: 99.46031746031746\n",
      "Val accuracy: 94.07142857142857\n",
      "Iteration: 111\n",
      "Train accuracy: 99.46984126984127\n",
      "Val accuracy: 94.1\n",
      "Iteration: 112\n",
      "Train accuracy: 99.48730158730159\n",
      "Val accuracy: 94.11428571428571\n",
      "Iteration: 113\n",
      "Train accuracy: 99.4968253968254\n",
      "Val accuracy: 94.11428571428571\n",
      "Iteration: 114\n",
      "Train accuracy: 99.50952380952381\n",
      "Val accuracy: 94.11428571428571\n",
      "Iteration: 115\n",
      "Train accuracy: 99.5142857142857\n",
      "Val accuracy: 94.12857142857143\n",
      "Iteration: 116\n",
      "Train accuracy: 99.52222222222223\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 117\n",
      "Train accuracy: 99.54126984126984\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 118\n",
      "Train accuracy: 99.55714285714285\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 119\n",
      "Train accuracy: 99.56825396825397\n",
      "Val accuracy: 94.17142857142858\n",
      "Iteration: 120\n",
      "Train accuracy: 99.58253968253969\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 121\n",
      "Train accuracy: 99.5936507936508\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 122\n",
      "Train accuracy: 99.60634920634921\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 123\n",
      "Train accuracy: 99.61428571428571\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 124\n",
      "Train accuracy: 99.615873015873\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 125\n",
      "Train accuracy: 99.62063492063493\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 126\n",
      "Train accuracy: 99.62539682539683\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 127\n",
      "Train accuracy: 99.63809523809523\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 128\n",
      "Train accuracy: 99.64126984126985\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 129\n",
      "Train accuracy: 99.65396825396824\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 130\n",
      "Train accuracy: 99.66031746031746\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 131\n",
      "Train accuracy: 99.66825396825398\n",
      "Val accuracy: 94.27142857142857\n",
      "Iteration: 132\n",
      "Train accuracy: 99.67460317460318\n",
      "Val accuracy: 94.27142857142857\n",
      "Iteration: 133\n",
      "Train accuracy: 99.69047619047619\n",
      "Val accuracy: 94.28571428571428\n",
      "Iteration: 134\n",
      "Train accuracy: 99.6984126984127\n",
      "Val accuracy: 94.28571428571428\n",
      "Iteration: 135\n",
      "Train accuracy: 99.70476190476191\n",
      "Val accuracy: 94.31428571428572\n",
      "Iteration: 136\n",
      "Train accuracy: 99.70634920634922\n",
      "Val accuracy: 94.31428571428572\n",
      "Iteration: 137\n",
      "Train accuracy: 99.70952380952382\n",
      "Val accuracy: 94.35714285714286\n",
      "Iteration: 138\n",
      "Train accuracy: 99.71269841269842\n",
      "Val accuracy: 94.35714285714286\n",
      "Iteration: 139\n",
      "Train accuracy: 99.72380952380952\n",
      "Val accuracy: 94.35714285714286\n",
      "Iteration: 140\n",
      "Train accuracy: 99.72857142857143\n",
      "Val accuracy: 94.37142857142857\n",
      "Iteration: 141\n",
      "Train accuracy: 99.73492063492063\n",
      "Val accuracy: 94.39999999999999\n",
      "Iteration: 142\n",
      "Train accuracy: 99.73809523809524\n",
      "Val accuracy: 94.42857142857143\n",
      "Iteration: 143\n",
      "Train accuracy: 99.74603174603175\n",
      "Val accuracy: 94.42857142857143\n",
      "Iteration: 144\n",
      "Train accuracy: 99.75238095238095\n",
      "Val accuracy: 94.41428571428571\n",
      "Iteration: 145\n",
      "Train accuracy: 99.76190476190476\n",
      "Val accuracy: 94.41428571428571\n",
      "Iteration: 146\n",
      "Train accuracy: 99.76666666666667\n",
      "Val accuracy: 94.42857142857143\n",
      "Iteration: 147\n",
      "Train accuracy: 99.76984126984128\n",
      "Val accuracy: 94.44285714285714\n",
      "Iteration: 148\n",
      "Train accuracy: 99.77936507936508\n",
      "Val accuracy: 94.42857142857143\n",
      "Iteration: 149\n",
      "Train accuracy: 99.78253968253968\n",
      "Val accuracy: 94.47142857142858\n",
      "Iteration: 150\n",
      "Train accuracy: 99.79206349206349\n",
      "Val accuracy: 94.5\n",
      "Iteration: 151\n",
      "Train accuracy: 99.79365079365078\n",
      "Val accuracy: 94.52857142857142\n",
      "Iteration: 152\n",
      "Train accuracy: 99.7984126984127\n",
      "Val accuracy: 94.52857142857142\n",
      "Iteration: 153\n",
      "Train accuracy: 99.8047619047619\n",
      "Val accuracy: 94.52857142857142\n",
      "Iteration: 154\n",
      "Train accuracy: 99.80793650793652\n",
      "Val accuracy: 94.54285714285714\n",
      "Iteration: 155\n",
      "Train accuracy: 99.81587301587301\n",
      "Val accuracy: 94.52857142857142\n",
      "Iteration: 156\n",
      "Train accuracy: 99.82222222222222\n",
      "Val accuracy: 94.52857142857142\n",
      "Iteration: 157\n",
      "Train accuracy: 99.82539682539682\n",
      "Val accuracy: 94.55714285714286\n",
      "Iteration: 158\n",
      "Train accuracy: 99.83015873015873\n",
      "Val accuracy: 94.55714285714286\n",
      "Iteration: 159\n",
      "Train accuracy: 99.83650793650793\n",
      "Val accuracy: 94.55714285714286\n",
      "Iteration: 160\n",
      "Train accuracy: 99.84126984126985\n",
      "Val accuracy: 94.55714285714286\n",
      "Iteration: 161\n",
      "Train accuracy: 99.84126984126985\n",
      "Val accuracy: 94.57142857142857\n",
      "Iteration: 162\n",
      "Train accuracy: 99.84444444444445\n",
      "Val accuracy: 94.55714285714286\n",
      "Iteration: 163\n",
      "Train accuracy: 99.84761904761905\n",
      "Val accuracy: 94.57142857142857\n",
      "Iteration: 164\n",
      "Train accuracy: 99.85079365079365\n",
      "Val accuracy: 94.57142857142857\n",
      "Iteration: 165\n",
      "Train accuracy: 99.85873015873015\n",
      "Val accuracy: 94.6\n",
      "Iteration: 166\n",
      "Train accuracy: 99.86190476190477\n",
      "Val accuracy: 94.6\n",
      "Iteration: 167\n",
      "Train accuracy: 99.86507936507937\n",
      "Val accuracy: 94.6\n",
      "Iteration: 168\n",
      "Train accuracy: 99.86666666666667\n",
      "Val accuracy: 94.6\n",
      "Iteration: 169\n",
      "Train accuracy: 99.86825396825397\n",
      "Val accuracy: 94.6\n",
      "Iteration: 170\n",
      "Train accuracy: 99.86984126984127\n",
      "Val accuracy: 94.6\n",
      "Iteration: 171\n",
      "Train accuracy: 99.87460317460317\n",
      "Val accuracy: 94.62857142857143\n",
      "Iteration: 172\n",
      "Train accuracy: 99.87460317460317\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 173\n",
      "Train accuracy: 99.87936507936507\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 174\n",
      "Train accuracy: 99.884126984127\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 175\n",
      "Train accuracy: 99.8873015873016\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 176\n",
      "Train accuracy: 99.8873015873016\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 177\n",
      "Train accuracy: 99.8873015873016\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 178\n",
      "Train accuracy: 99.8888888888889\n",
      "Val accuracy: 94.69999999999999\n",
      "Iteration: 179\n",
      "Train accuracy: 99.8888888888889\n",
      "Val accuracy: 94.71428571428572\n",
      "Iteration: 180\n",
      "Train accuracy: 99.89047619047618\n",
      "Val accuracy: 94.71428571428572\n",
      "Iteration: 181\n",
      "Train accuracy: 99.89206349206349\n",
      "Val accuracy: 94.72857142857143\n",
      "Iteration: 182\n",
      "Train accuracy: 99.89365079365079\n",
      "Val accuracy: 94.72857142857143\n",
      "Iteration: 183\n",
      "Train accuracy: 99.9\n",
      "Val accuracy: 94.72857142857143\n",
      "Iteration: 184\n",
      "Train accuracy: 99.9\n",
      "Val accuracy: 94.74285714285713\n",
      "Iteration: 185\n",
      "Train accuracy: 99.9\n",
      "Val accuracy: 94.74285714285713\n",
      "Iteration: 186\n",
      "Train accuracy: 99.9031746031746\n",
      "Val accuracy: 94.75714285714287\n",
      "Iteration: 187\n",
      "Train accuracy: 99.9031746031746\n",
      "Val accuracy: 94.74285714285713\n",
      "Iteration: 188\n",
      "Train accuracy: 99.9031746031746\n",
      "Val accuracy: 94.74285714285713\n",
      "Iteration: 189\n",
      "Train accuracy: 99.9031746031746\n",
      "Val accuracy: 94.74285714285713\n",
      "Iteration: 190\n",
      "Train accuracy: 99.9063492063492\n",
      "Val accuracy: 94.77142857142857\n",
      "Iteration: 191\n",
      "Train accuracy: 99.91111111111111\n",
      "Val accuracy: 94.77142857142857\n",
      "Iteration: 192\n",
      "Train accuracy: 99.9126984126984\n",
      "Val accuracy: 94.8\n",
      "Iteration: 193\n",
      "Train accuracy: 99.91587301587302\n",
      "Val accuracy: 94.8\n",
      "Iteration: 194\n",
      "Train accuracy: 99.91587301587302\n",
      "Val accuracy: 94.8\n",
      "Iteration: 195\n",
      "Train accuracy: 99.91904761904762\n",
      "Val accuracy: 94.78571428571428\n",
      "Iteration: 196\n",
      "Train accuracy: 99.91904761904762\n",
      "Val accuracy: 94.78571428571428\n",
      "Iteration: 197\n",
      "Train accuracy: 99.92063492063492\n",
      "Val accuracy: 94.78571428571428\n",
      "Iteration: 198\n",
      "Train accuracy: 99.92222222222222\n",
      "Val accuracy: 94.78571428571428\n",
      "Iteration: 199\n",
      "Train accuracy: 99.92857142857143\n",
      "Val accuracy: 94.8\n",
      "Iteration: 200\n",
      "Train accuracy: 99.93015873015872\n",
      "Val accuracy: 94.81428571428572\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = batch_grad_descentwith_var(x_train,y_train,200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 83.24603174603175\n",
      "Val accuracy: 82.67142857142858\n",
      "Iteration: 2\n",
      "Train accuracy: 86.9888888888889\n",
      "Val accuracy: 86.4857142857143\n",
      "Iteration: 3\n",
      "Train accuracy: 88.77142857142857\n",
      "Val accuracy: 88.18571428571428\n",
      "Iteration: 4\n",
      "Train accuracy: 89.91587301587302\n",
      "Val accuracy: 88.91428571428571\n",
      "Iteration: 5\n",
      "Train accuracy: 90.66031746031746\n",
      "Val accuracy: 89.61428571428571\n",
      "Iteration: 6\n",
      "Train accuracy: 91.31269841269841\n",
      "Val accuracy: 90.04285714285714\n",
      "Iteration: 7\n",
      "Train accuracy: 91.8079365079365\n",
      "Val accuracy: 90.45714285714286\n",
      "Iteration: 8\n",
      "Train accuracy: 92.22857142857143\n",
      "Val accuracy: 90.68571428571428\n",
      "Iteration: 9\n",
      "Train accuracy: 92.64285714285714\n",
      "Val accuracy: 91.05714285714286\n",
      "Iteration: 10\n",
      "Train accuracy: 92.97460317460317\n",
      "Val accuracy: 91.21428571428571\n",
      "Iteration: 11\n",
      "Train accuracy: 93.29047619047618\n",
      "Val accuracy: 91.38571428571429\n",
      "Iteration: 12\n",
      "Train accuracy: 93.58730158730158\n",
      "Val accuracy: 91.67142857142856\n",
      "Iteration: 13\n",
      "Train accuracy: 93.84761904761905\n",
      "Val accuracy: 91.78571428571428\n",
      "Iteration: 14\n",
      "Train accuracy: 94.12380952380953\n",
      "Val accuracy: 91.9\n",
      "Iteration: 15\n",
      "Train accuracy: 94.31904761904762\n",
      "Val accuracy: 92.08571428571429\n",
      "Iteration: 16\n",
      "Train accuracy: 94.52857142857142\n",
      "Val accuracy: 92.2\n",
      "Iteration: 17\n",
      "Train accuracy: 94.6968253968254\n",
      "Val accuracy: 92.28571428571428\n",
      "Iteration: 18\n",
      "Train accuracy: 94.8968253968254\n",
      "Val accuracy: 92.35714285714286\n",
      "Iteration: 19\n",
      "Train accuracy: 95.10634920634921\n",
      "Val accuracy: 92.42857142857143\n",
      "Iteration: 20\n",
      "Train accuracy: 95.28412698412698\n",
      "Val accuracy: 92.5\n",
      "Iteration: 21\n",
      "Train accuracy: 95.46825396825398\n",
      "Val accuracy: 92.58571428571429\n",
      "Iteration: 22\n",
      "Train accuracy: 95.61904761904762\n",
      "Val accuracy: 92.64285714285714\n",
      "Iteration: 23\n",
      "Train accuracy: 95.7904761904762\n",
      "Val accuracy: 92.7\n",
      "Iteration: 24\n",
      "Train accuracy: 95.88571428571429\n",
      "Val accuracy: 92.82857142857142\n",
      "Iteration: 25\n",
      "Train accuracy: 95.99682539682539\n",
      "Val accuracy: 92.82857142857142\n",
      "Iteration: 26\n",
      "Train accuracy: 96.12857142857143\n",
      "Val accuracy: 92.87142857142857\n",
      "Iteration: 27\n",
      "Train accuracy: 96.24444444444444\n",
      "Val accuracy: 92.88571428571429\n",
      "Iteration: 28\n",
      "Train accuracy: 96.35714285714285\n",
      "Val accuracy: 93.0\n",
      "Iteration: 29\n",
      "Train accuracy: 96.45873015873015\n",
      "Val accuracy: 93.0\n",
      "Iteration: 30\n",
      "Train accuracy: 96.57301587301588\n",
      "Val accuracy: 93.04285714285714\n",
      "Iteration: 31\n",
      "Train accuracy: 96.67460317460318\n",
      "Val accuracy: 93.07142857142857\n",
      "Iteration: 32\n",
      "Train accuracy: 96.75396825396825\n",
      "Val accuracy: 93.12857142857143\n",
      "Iteration: 33\n",
      "Train accuracy: 96.83809523809524\n",
      "Val accuracy: 93.22857142857143\n",
      "Iteration: 34\n",
      "Train accuracy: 96.9015873015873\n",
      "Val accuracy: 93.27142857142857\n",
      "Iteration: 35\n",
      "Train accuracy: 97.0031746031746\n",
      "Val accuracy: 93.32857142857142\n",
      "Iteration: 36\n",
      "Train accuracy: 97.06666666666666\n",
      "Val accuracy: 93.32857142857142\n",
      "Iteration: 37\n",
      "Train accuracy: 97.12539682539682\n",
      "Val accuracy: 93.37142857142857\n",
      "Iteration: 38\n",
      "Train accuracy: 97.17777777777778\n",
      "Val accuracy: 93.44285714285714\n",
      "Iteration: 39\n",
      "Train accuracy: 97.23492063492063\n",
      "Val accuracy: 93.42857142857143\n",
      "Iteration: 40\n",
      "Train accuracy: 97.28571428571429\n",
      "Val accuracy: 93.47142857142858\n",
      "Iteration: 41\n",
      "Train accuracy: 97.34920634920636\n",
      "Val accuracy: 93.5\n",
      "Iteration: 42\n",
      "Train accuracy: 97.39523809523808\n",
      "Val accuracy: 93.51428571428572\n",
      "Iteration: 43\n",
      "Train accuracy: 97.46190476190476\n",
      "Val accuracy: 93.52857142857142\n",
      "Iteration: 44\n",
      "Train accuracy: 97.5047619047619\n",
      "Val accuracy: 93.57142857142857\n",
      "Iteration: 45\n",
      "Train accuracy: 97.55396825396825\n",
      "Val accuracy: 93.55714285714286\n",
      "Iteration: 46\n",
      "Train accuracy: 97.62380952380953\n",
      "Val accuracy: 93.57142857142857\n",
      "Iteration: 47\n",
      "Train accuracy: 97.6888888888889\n",
      "Val accuracy: 93.58571428571429\n",
      "Iteration: 48\n",
      "Train accuracy: 97.77460317460317\n",
      "Val accuracy: 93.60000000000001\n",
      "Iteration: 49\n",
      "Train accuracy: 97.81111111111112\n",
      "Val accuracy: 93.64285714285714\n",
      "Iteration: 50\n",
      "Train accuracy: 97.85873015873015\n",
      "Val accuracy: 93.65714285714286\n",
      "Iteration: 51\n",
      "Train accuracy: 97.91904761904762\n",
      "Val accuracy: 93.64285714285714\n",
      "Iteration: 52\n",
      "Train accuracy: 97.97301587301588\n",
      "Val accuracy: 93.65714285714286\n",
      "Iteration: 53\n",
      "Train accuracy: 98.04285714285714\n",
      "Val accuracy: 93.7\n",
      "Iteration: 54\n",
      "Train accuracy: 98.0904761904762\n",
      "Val accuracy: 93.7\n",
      "Iteration: 55\n",
      "Train accuracy: 98.13015873015874\n",
      "Val accuracy: 93.7\n",
      "Iteration: 56\n",
      "Train accuracy: 98.18571428571428\n",
      "Val accuracy: 93.7\n",
      "Iteration: 57\n",
      "Train accuracy: 98.23650793650793\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 58\n",
      "Train accuracy: 98.29523809523809\n",
      "Val accuracy: 93.74285714285713\n",
      "Iteration: 59\n",
      "Train accuracy: 98.34603174603174\n",
      "Val accuracy: 93.78571428571428\n",
      "Iteration: 60\n",
      "Train accuracy: 98.4\n",
      "Val accuracy: 93.8\n",
      "Iteration: 61\n",
      "Train accuracy: 98.43968253968254\n",
      "Val accuracy: 93.78571428571428\n",
      "Iteration: 62\n",
      "Train accuracy: 98.47619047619047\n",
      "Val accuracy: 93.78571428571428\n",
      "Iteration: 63\n",
      "Train accuracy: 98.52063492063492\n",
      "Val accuracy: 93.8\n",
      "Iteration: 64\n",
      "Train accuracy: 98.55714285714285\n",
      "Val accuracy: 93.74285714285713\n",
      "Iteration: 65\n",
      "Train accuracy: 98.57301587301586\n",
      "Val accuracy: 93.74285714285713\n",
      "Iteration: 66\n",
      "Train accuracy: 98.61111111111111\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 67\n",
      "Train accuracy: 98.65079365079366\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 68\n",
      "Train accuracy: 98.68253968253968\n",
      "Val accuracy: 93.74285714285713\n",
      "Iteration: 69\n",
      "Train accuracy: 98.70476190476191\n",
      "Val accuracy: 93.7\n",
      "Iteration: 70\n",
      "Train accuracy: 98.73492063492063\n",
      "Val accuracy: 93.71428571428572\n",
      "Iteration: 71\n",
      "Train accuracy: 98.75873015873016\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 72\n",
      "Train accuracy: 98.7904761904762\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 73\n",
      "Train accuracy: 98.81746031746032\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 74\n",
      "Train accuracy: 98.84920634920636\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 75\n",
      "Train accuracy: 98.89523809523808\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 76\n",
      "Train accuracy: 98.91111111111111\n",
      "Val accuracy: 93.71428571428572\n",
      "Iteration: 77\n",
      "Train accuracy: 98.94126984126984\n",
      "Val accuracy: 93.72857142857143\n",
      "Iteration: 78\n",
      "Train accuracy: 98.96666666666667\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 79\n",
      "Train accuracy: 99.00634920634921\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 80\n",
      "Train accuracy: 99.03015873015873\n",
      "Val accuracy: 93.78571428571428\n",
      "Iteration: 81\n",
      "Train accuracy: 99.06349206349206\n",
      "Val accuracy: 93.78571428571428\n",
      "Iteration: 82\n",
      "Train accuracy: 99.0936507936508\n",
      "Val accuracy: 93.81428571428572\n",
      "Iteration: 83\n",
      "Train accuracy: 99.1126984126984\n",
      "Val accuracy: 93.81428571428572\n",
      "Iteration: 84\n",
      "Train accuracy: 99.13968253968254\n",
      "Val accuracy: 93.82857142857142\n",
      "Iteration: 85\n",
      "Train accuracy: 99.16507936507936\n",
      "Val accuracy: 93.84285714285714\n",
      "Iteration: 86\n",
      "Train accuracy: 99.19206349206348\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 87\n",
      "Train accuracy: 99.20793650793651\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 88\n",
      "Train accuracy: 99.24126984126984\n",
      "Val accuracy: 93.87142857142857\n",
      "Iteration: 89\n",
      "Train accuracy: 99.26825396825397\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 90\n",
      "Train accuracy: 99.28730158730158\n",
      "Val accuracy: 93.85714285714286\n",
      "Iteration: 91\n",
      "Train accuracy: 99.30793650793652\n",
      "Val accuracy: 93.88571428571429\n",
      "Iteration: 92\n",
      "Train accuracy: 99.31746031746032\n",
      "Val accuracy: 93.91428571428571\n",
      "Iteration: 93\n",
      "Train accuracy: 99.33809523809524\n",
      "Val accuracy: 93.89999999999999\n",
      "Iteration: 94\n",
      "Train accuracy: 99.34920634920636\n",
      "Val accuracy: 93.91428571428571\n",
      "Iteration: 95\n",
      "Train accuracy: 99.35873015873015\n",
      "Val accuracy: 93.92857142857143\n",
      "Iteration: 96\n",
      "Train accuracy: 99.36984126984127\n",
      "Val accuracy: 93.94285714285714\n",
      "Iteration: 97\n",
      "Train accuracy: 99.39047619047619\n",
      "Val accuracy: 93.95714285714286\n",
      "Iteration: 98\n",
      "Train accuracy: 99.4015873015873\n",
      "Val accuracy: 93.98571428571428\n",
      "Iteration: 99\n",
      "Train accuracy: 99.41746031746031\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 100\n",
      "Train accuracy: 99.42698412698412\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 101\n",
      "Train accuracy: 99.44920634920635\n",
      "Val accuracy: 94.01428571428572\n",
      "Iteration: 102\n",
      "Train accuracy: 99.47142857142856\n",
      "Val accuracy: 94.04285714285714\n",
      "Iteration: 103\n",
      "Train accuracy: 99.47460317460317\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 104\n",
      "Train accuracy: 99.4920634920635\n",
      "Val accuracy: 94.04285714285714\n",
      "Iteration: 105\n",
      "Train accuracy: 99.5079365079365\n",
      "Val accuracy: 94.04285714285714\n",
      "Iteration: 106\n",
      "Train accuracy: 99.52063492063492\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 107\n",
      "Train accuracy: 99.53174603174602\n",
      "Val accuracy: 94.07142857142857\n",
      "Iteration: 108\n",
      "Train accuracy: 99.55079365079365\n",
      "Val accuracy: 94.07142857142857\n",
      "Iteration: 109\n",
      "Train accuracy: 99.56666666666666\n",
      "Val accuracy: 94.05714285714286\n",
      "Iteration: 110\n",
      "Train accuracy: 99.57936507936508\n",
      "Val accuracy: 94.05714285714286\n",
      "Iteration: 111\n",
      "Train accuracy: 99.5936507936508\n",
      "Val accuracy: 94.02857142857142\n",
      "Iteration: 112\n",
      "Train accuracy: 99.6015873015873\n",
      "Val accuracy: 94.04285714285714\n",
      "Iteration: 113\n",
      "Train accuracy: 99.60793650793651\n",
      "Val accuracy: 94.08571428571429\n",
      "Iteration: 114\n",
      "Train accuracy: 99.62539682539683\n",
      "Val accuracy: 94.08571428571429\n",
      "Iteration: 115\n",
      "Train accuracy: 99.63809523809523\n",
      "Val accuracy: 94.11428571428571\n",
      "Iteration: 116\n",
      "Train accuracy: 99.64761904761905\n",
      "Val accuracy: 94.11428571428571\n",
      "Iteration: 117\n",
      "Train accuracy: 99.66031746031746\n",
      "Val accuracy: 94.1\n",
      "Iteration: 118\n",
      "Train accuracy: 99.67460317460318\n",
      "Val accuracy: 94.11428571428571\n",
      "Iteration: 119\n",
      "Train accuracy: 99.68253968253968\n",
      "Val accuracy: 94.12857142857143\n",
      "Iteration: 120\n",
      "Train accuracy: 99.69047619047619\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 121\n",
      "Train accuracy: 99.69206349206348\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 122\n",
      "Train accuracy: 99.7\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 123\n",
      "Train accuracy: 99.70793650793651\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 124\n",
      "Train accuracy: 99.71904761904761\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 125\n",
      "Train accuracy: 99.72698412698414\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 126\n",
      "Train accuracy: 99.73333333333333\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 127\n",
      "Train accuracy: 99.73809523809524\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 128\n",
      "Train accuracy: 99.74920634920636\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 129\n",
      "Train accuracy: 99.75873015873016\n",
      "Val accuracy: 94.14285714285714\n",
      "Iteration: 130\n",
      "Train accuracy: 99.76031746031747\n",
      "Val accuracy: 94.15714285714286\n",
      "Iteration: 131\n",
      "Train accuracy: 99.76666666666667\n",
      "Val accuracy: 94.17142857142858\n",
      "Iteration: 132\n",
      "Train accuracy: 99.76825396825397\n",
      "Val accuracy: 94.17142857142858\n",
      "Iteration: 133\n",
      "Train accuracy: 99.77142857142857\n",
      "Val accuracy: 94.18571428571428\n",
      "Iteration: 134\n",
      "Train accuracy: 99.77619047619048\n",
      "Val accuracy: 94.18571428571428\n",
      "Iteration: 135\n",
      "Train accuracy: 99.78253968253968\n",
      "Val accuracy: 94.17142857142858\n",
      "Iteration: 136\n",
      "Train accuracy: 99.78730158730158\n",
      "Val accuracy: 94.17142857142858\n",
      "Iteration: 137\n",
      "Train accuracy: 99.8\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 138\n",
      "Train accuracy: 99.80317460317461\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 139\n",
      "Train accuracy: 99.8047619047619\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 140\n",
      "Train accuracy: 99.81428571428572\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 141\n",
      "Train accuracy: 99.81587301587301\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 142\n",
      "Train accuracy: 99.82698412698413\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 143\n",
      "Train accuracy: 99.83492063492064\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 144\n",
      "Train accuracy: 99.84126984126985\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 145\n",
      "Train accuracy: 99.84761904761905\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 146\n",
      "Train accuracy: 99.84920634920636\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 147\n",
      "Train accuracy: 99.86031746031746\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 148\n",
      "Train accuracy: 99.86031746031746\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 149\n",
      "Train accuracy: 99.86507936507937\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 150\n",
      "Train accuracy: 99.86984126984127\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 151\n",
      "Train accuracy: 99.87619047619047\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 152\n",
      "Train accuracy: 99.88571428571429\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 153\n",
      "Train accuracy: 99.89206349206349\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 154\n",
      "Train accuracy: 99.89682539682539\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 155\n",
      "Train accuracy: 99.9015873015873\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 156\n",
      "Train accuracy: 99.9063492063492\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 157\n",
      "Train accuracy: 99.90476190476191\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 158\n",
      "Train accuracy: 99.91111111111111\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 159\n",
      "Train accuracy: 99.9126984126984\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 160\n",
      "Train accuracy: 99.91428571428571\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 161\n",
      "Train accuracy: 99.91746031746031\n",
      "Val accuracy: 94.19999999999999\n",
      "Iteration: 162\n",
      "Train accuracy: 99.92063492063492\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 163\n",
      "Train accuracy: 99.92380952380952\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 164\n",
      "Train accuracy: 99.92698412698414\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 165\n",
      "Train accuracy: 99.93174603174603\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 166\n",
      "Train accuracy: 99.93492063492063\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 167\n",
      "Train accuracy: 99.93650793650794\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 168\n",
      "Train accuracy: 99.94285714285715\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 169\n",
      "Train accuracy: 99.94444444444444\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 170\n",
      "Train accuracy: 99.94444444444444\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 171\n",
      "Train accuracy: 99.94603174603175\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 172\n",
      "Train accuracy: 99.94603174603175\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 173\n",
      "Train accuracy: 99.94761904761906\n",
      "Val accuracy: 94.21428571428572\n",
      "Iteration: 174\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 175\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 176\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 177\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 178\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 179\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.22857142857143\n",
      "Iteration: 180\n",
      "Train accuracy: 99.94920634920635\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 181\n",
      "Train accuracy: 99.95079365079364\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 182\n",
      "Train accuracy: 99.95238095238095\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 183\n",
      "Train accuracy: 99.95396825396826\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 184\n",
      "Train accuracy: 99.95555555555555\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 185\n",
      "Train accuracy: 99.95714285714286\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 186\n",
      "Train accuracy: 99.95714285714286\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 187\n",
      "Train accuracy: 99.95873015873016\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 188\n",
      "Train accuracy: 99.96349206349207\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 189\n",
      "Train accuracy: 99.96507936507936\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 190\n",
      "Train accuracy: 99.96666666666667\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 191\n",
      "Train accuracy: 99.96666666666667\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 192\n",
      "Train accuracy: 99.96666666666667\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 193\n",
      "Train accuracy: 99.96825396825398\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 194\n",
      "Train accuracy: 99.97142857142856\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 195\n",
      "Train accuracy: 99.97460317460317\n",
      "Val accuracy: 94.27142857142857\n",
      "Iteration: 196\n",
      "Train accuracy: 99.97777777777777\n",
      "Val accuracy: 94.27142857142857\n",
      "Iteration: 197\n",
      "Train accuracy: 99.97777777777777\n",
      "Val accuracy: 94.27142857142857\n",
      "Iteration: 198\n",
      "Train accuracy: 99.97777777777777\n",
      "Val accuracy: 94.25714285714287\n",
      "Iteration: 199\n",
      "Train accuracy: 99.97777777777777\n",
      "Val accuracy: 94.24285714285713\n",
      "Iteration: 200\n",
      "Train accuracy: 99.97936507936508\n",
      "Val accuracy: 94.24285714285713\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc_n, val_acc_n, train_loss_n, val_loss_n, sum_weights_n = batch_grad_descent(x_train,y_train,200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs Iterations for Back Propagation')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_op=1\n",
    "#iters = [print_op*i for i in range(1,(iter//print_op)+1)]\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(train_acc)\n",
    "plt.plot(train_acc_n)\n",
    "plt.legend(['Training accuracy with variability', 'Training Accuracy without variability'])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim(80,100)\n",
    "plt.title(\"Accuracy vs Iterations for Back Propagation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 14.217460317460318\n",
      "Val accuracy: 14.257142857142856\n",
      "Iteration: 2\n",
      "Train accuracy: 32.766666666666666\n",
      "Val accuracy: 32.042857142857144\n",
      "Iteration: 3\n",
      "Train accuracy: 21.14920634920635\n",
      "Val accuracy: 21.857142857142858\n",
      "Iteration: 4\n",
      "Train accuracy: 47.37777777777778\n",
      "Val accuracy: 47.385714285714286\n",
      "Iteration: 5\n",
      "Train accuracy: 48.769841269841265\n",
      "Val accuracy: 48.98571428571429\n",
      "Iteration: 6\n",
      "Train accuracy: 53.614285714285714\n",
      "Val accuracy: 53.87142857142857\n",
      "Iteration: 7\n",
      "Train accuracy: 64.26666666666667\n",
      "Val accuracy: 64.25714285714285\n",
      "Iteration: 8\n",
      "Train accuracy: 69.14285714285714\n",
      "Val accuracy: 69.69999999999999\n",
      "Iteration: 9\n",
      "Train accuracy: 71.3047619047619\n",
      "Val accuracy: 71.78571428571429\n",
      "Iteration: 10\n",
      "Train accuracy: 72.38095238095238\n",
      "Val accuracy: 72.8142857142857\n",
      "Iteration: 11\n",
      "Train accuracy: 73.62857142857143\n",
      "Val accuracy: 73.94285714285715\n",
      "Iteration: 12\n",
      "Train accuracy: 74.26666666666667\n",
      "Val accuracy: 74.62857142857143\n",
      "Iteration: 13\n",
      "Train accuracy: 75.27777777777777\n",
      "Val accuracy: 75.84285714285714\n",
      "Iteration: 14\n",
      "Train accuracy: 75.98730158730159\n",
      "Val accuracy: 76.61428571428571\n",
      "Iteration: 15\n",
      "Train accuracy: 76.61587301587302\n",
      "Val accuracy: 77.21428571428571\n",
      "Iteration: 16\n",
      "Train accuracy: 77.4095238095238\n",
      "Val accuracy: 77.77142857142857\n",
      "Iteration: 17\n",
      "Train accuracy: 77.85555555555555\n",
      "Val accuracy: 78.22857142857143\n",
      "Iteration: 18\n",
      "Train accuracy: 78.3047619047619\n",
      "Val accuracy: 78.62857142857142\n",
      "Iteration: 19\n",
      "Train accuracy: 78.95555555555556\n",
      "Val accuracy: 79.10000000000001\n",
      "Iteration: 20\n",
      "Train accuracy: 79.22222222222223\n",
      "Val accuracy: 79.45714285714286\n",
      "Iteration: 21\n",
      "Train accuracy: 79.71746031746032\n",
      "Val accuracy: 79.91428571428571\n",
      "Iteration: 22\n",
      "Train accuracy: 80.26984126984127\n",
      "Val accuracy: 80.28571428571428\n",
      "Iteration: 23\n",
      "Train accuracy: 80.55238095238096\n",
      "Val accuracy: 80.9\n",
      "Iteration: 24\n",
      "Train accuracy: 80.89365079365079\n",
      "Val accuracy: 80.92857142857143\n",
      "Iteration: 25\n",
      "Train accuracy: 81.16666666666667\n",
      "Val accuracy: 81.27142857142857\n",
      "Iteration: 26\n",
      "Train accuracy: 81.57301587301588\n",
      "Val accuracy: 81.77142857142857\n",
      "Iteration: 27\n",
      "Train accuracy: 81.74920634920635\n",
      "Val accuracy: 81.87142857142857\n",
      "Iteration: 28\n",
      "Train accuracy: 82.01904761904761\n",
      "Val accuracy: 82.24285714285713\n",
      "Iteration: 29\n",
      "Train accuracy: 82.17301587301587\n",
      "Val accuracy: 82.31428571428572\n",
      "Iteration: 30\n",
      "Train accuracy: 82.43650793650794\n",
      "Val accuracy: 82.78571428571428\n",
      "Iteration: 31\n",
      "Train accuracy: 82.61746031746033\n",
      "Val accuracy: 83.05714285714285\n",
      "Iteration: 32\n",
      "Train accuracy: 82.80634920634921\n",
      "Val accuracy: 83.08571428571429\n",
      "Iteration: 33\n",
      "Train accuracy: 82.96349206349205\n",
      "Val accuracy: 82.84285714285714\n",
      "Iteration: 34\n",
      "Train accuracy: 83.1888888888889\n",
      "Val accuracy: 83.3\n",
      "Iteration: 35\n",
      "Train accuracy: 83.55238095238096\n",
      "Val accuracy: 83.52857142857142\n",
      "Iteration: 36\n",
      "Train accuracy: 83.56349206349206\n",
      "Val accuracy: 83.48571428571428\n",
      "Iteration: 37\n",
      "Train accuracy: 83.81269841269841\n",
      "Val accuracy: 83.88571428571429\n",
      "Iteration: 38\n",
      "Train accuracy: 83.88412698412698\n",
      "Val accuracy: 83.8\n",
      "Iteration: 39\n",
      "Train accuracy: 83.98095238095237\n",
      "Val accuracy: 84.07142857142857\n",
      "Iteration: 40\n",
      "Train accuracy: 84.32857142857144\n",
      "Val accuracy: 84.28571428571429\n",
      "Iteration: 41\n",
      "Train accuracy: 84.59523809523809\n",
      "Val accuracy: 84.52857142857142\n",
      "Iteration: 42\n",
      "Train accuracy: 84.54444444444445\n",
      "Val accuracy: 84.47142857142858\n",
      "Iteration: 43\n",
      "Train accuracy: 84.78412698412698\n",
      "Val accuracy: 84.62857142857143\n",
      "Iteration: 44\n",
      "Train accuracy: 85.04285714285714\n",
      "Val accuracy: 84.94285714285714\n",
      "Iteration: 45\n",
      "Train accuracy: 85.02698412698413\n",
      "Val accuracy: 84.74285714285715\n",
      "Iteration: 46\n",
      "Train accuracy: 85.115873015873\n",
      "Val accuracy: 84.85714285714285\n",
      "Iteration: 47\n",
      "Train accuracy: 85.23968253968253\n",
      "Val accuracy: 85.1\n",
      "Iteration: 48\n",
      "Train accuracy: 85.37460317460317\n",
      "Val accuracy: 85.07142857142857\n",
      "Iteration: 49\n",
      "Train accuracy: 85.2968253968254\n",
      "Val accuracy: 85.3\n",
      "Iteration: 50\n",
      "Train accuracy: 85.56031746031746\n",
      "Val accuracy: 85.21428571428571\n",
      "Iteration: 51\n",
      "Train accuracy: 85.65238095238095\n",
      "Val accuracy: 85.24285714285715\n",
      "Iteration: 52\n",
      "Train accuracy: 85.73492063492063\n",
      "Val accuracy: 85.5142857142857\n",
      "Iteration: 53\n",
      "Train accuracy: 85.8873015873016\n",
      "Val accuracy: 85.55714285714285\n",
      "Iteration: 54\n",
      "Train accuracy: 85.97460317460317\n",
      "Val accuracy: 85.7\n",
      "Iteration: 55\n",
      "Train accuracy: 86.03015873015873\n",
      "Val accuracy: 85.74285714285715\n",
      "Iteration: 56\n",
      "Train accuracy: 86.10634920634921\n",
      "Val accuracy: 85.65714285714286\n",
      "Iteration: 57\n",
      "Train accuracy: 86.25555555555555\n",
      "Val accuracy: 86.0\n",
      "Iteration: 58\n",
      "Train accuracy: 86.29841269841269\n",
      "Val accuracy: 85.78571428571429\n",
      "Iteration: 59\n",
      "Train accuracy: 86.36349206349206\n",
      "Val accuracy: 86.05714285714285\n",
      "Iteration: 60\n",
      "Train accuracy: 86.48095238095237\n",
      "Val accuracy: 86.08571428571429\n",
      "Iteration: 61\n",
      "Train accuracy: 86.54285714285714\n",
      "Val accuracy: 86.22857142857143\n",
      "Iteration: 62\n",
      "Train accuracy: 86.63650793650794\n",
      "Val accuracy: 86.32857142857144\n",
      "Iteration: 63\n",
      "Train accuracy: 86.6888888888889\n",
      "Val accuracy: 86.38571428571429\n",
      "Iteration: 64\n",
      "Train accuracy: 86.86507936507937\n",
      "Val accuracy: 86.38571428571429\n",
      "Iteration: 65\n",
      "Train accuracy: 86.91587301587302\n",
      "Val accuracy: 86.52857142857144\n",
      "Iteration: 66\n",
      "Train accuracy: 87.03650793650793\n",
      "Val accuracy: 86.42857142857143\n",
      "Iteration: 67\n",
      "Train accuracy: 87.08253968253969\n",
      "Val accuracy: 86.65714285714286\n",
      "Iteration: 68\n",
      "Train accuracy: 87.1\n",
      "Val accuracy: 86.4857142857143\n",
      "Iteration: 69\n",
      "Train accuracy: 87.07777777777778\n",
      "Val accuracy: 86.7\n",
      "Iteration: 70\n",
      "Train accuracy: 87.16031746031746\n",
      "Val accuracy: 86.72857142857143\n",
      "Iteration: 71\n",
      "Train accuracy: 87.2968253968254\n",
      "Val accuracy: 86.74285714285715\n",
      "Iteration: 72\n",
      "Train accuracy: 87.45873015873016\n",
      "Val accuracy: 86.75714285714285\n",
      "Iteration: 73\n",
      "Train accuracy: 87.46031746031746\n",
      "Val accuracy: 86.77142857142857\n",
      "Iteration: 74\n",
      "Train accuracy: 87.50634920634921\n",
      "Val accuracy: 87.04285714285714\n",
      "Iteration: 75\n",
      "Train accuracy: 87.65079365079364\n",
      "Val accuracy: 87.15714285714286\n",
      "Iteration: 76\n",
      "Train accuracy: 87.6888888888889\n",
      "Val accuracy: 87.3\n",
      "Iteration: 77\n",
      "Train accuracy: 87.78253968253968\n",
      "Val accuracy: 87.24285714285715\n",
      "Iteration: 78\n",
      "Train accuracy: 87.81746031746032\n",
      "Val accuracy: 87.28571428571429\n",
      "Iteration: 79\n",
      "Train accuracy: 87.69682539682539\n",
      "Val accuracy: 87.28571428571429\n",
      "Iteration: 80\n",
      "Train accuracy: 87.96666666666667\n",
      "Val accuracy: 87.54285714285714\n",
      "Iteration: 81\n",
      "Train accuracy: 88.02380952380953\n",
      "Val accuracy: 87.44285714285715\n",
      "Iteration: 82\n",
      "Train accuracy: 87.93333333333334\n",
      "Val accuracy: 87.28571428571429\n",
      "Iteration: 83\n",
      "Train accuracy: 88.10793650793651\n",
      "Val accuracy: 87.42857142857143\n",
      "Iteration: 84\n",
      "Train accuracy: 88.03492063492064\n",
      "Val accuracy: 87.4\n",
      "Iteration: 85\n",
      "Train accuracy: 88.03650793650793\n",
      "Val accuracy: 87.52857142857144\n",
      "Iteration: 86\n",
      "Train accuracy: 88.18571428571428\n",
      "Val accuracy: 87.72857142857143\n",
      "Iteration: 87\n",
      "Train accuracy: 88.26507936507937\n",
      "Val accuracy: 87.62857142857143\n",
      "Iteration: 88\n",
      "Train accuracy: 88.21904761904761\n",
      "Val accuracy: 87.58571428571429\n",
      "Iteration: 89\n",
      "Train accuracy: 88.2873015873016\n",
      "Val accuracy: 87.6\n",
      "Iteration: 90\n",
      "Train accuracy: 88.38095238095238\n",
      "Val accuracy: 87.71428571428571\n",
      "Iteration: 91\n",
      "Train accuracy: 88.35714285714286\n",
      "Val accuracy: 87.67142857142856\n",
      "Iteration: 92\n",
      "Train accuracy: 88.39206349206349\n",
      "Val accuracy: 87.91428571428571\n",
      "Iteration: 93\n",
      "Train accuracy: 88.4857142857143\n",
      "Val accuracy: 87.81428571428572\n",
      "Iteration: 94\n",
      "Train accuracy: 88.4952380952381\n",
      "Val accuracy: 87.77142857142857\n",
      "Iteration: 95\n",
      "Train accuracy: 88.6015873015873\n",
      "Val accuracy: 87.9857142857143\n",
      "Iteration: 96\n",
      "Train accuracy: 88.64444444444445\n",
      "Val accuracy: 88.08571428571429\n",
      "Iteration: 97\n",
      "Train accuracy: 88.70476190476191\n",
      "Val accuracy: 88.2\n",
      "Iteration: 98\n",
      "Train accuracy: 88.7968253968254\n",
      "Val accuracy: 88.12857142857143\n",
      "Iteration: 99\n",
      "Train accuracy: 88.83968253968254\n",
      "Val accuracy: 87.94285714285715\n",
      "Iteration: 100\n",
      "Train accuracy: 88.96190476190476\n",
      "Val accuracy: 88.08571428571429\n",
      "Iteration: 101\n",
      "Train accuracy: 88.99047619047619\n",
      "Val accuracy: 88.18571428571428\n",
      "Iteration: 102\n",
      "Train accuracy: 88.98253968253968\n",
      "Val accuracy: 88.08571428571429\n",
      "Iteration: 103\n",
      "Train accuracy: 88.97777777777777\n",
      "Val accuracy: 88.25714285714285\n",
      "Iteration: 104\n",
      "Train accuracy: 89.08095238095238\n",
      "Val accuracy: 88.17142857142856\n",
      "Iteration: 105\n",
      "Train accuracy: 89.10952380952381\n",
      "Val accuracy: 88.22857142857143\n",
      "Iteration: 106\n",
      "Train accuracy: 89.12539682539683\n",
      "Val accuracy: 88.38571428571429\n",
      "Iteration: 107\n",
      "Train accuracy: 89.26349206349207\n",
      "Val accuracy: 88.24285714285715\n",
      "Iteration: 108\n",
      "Train accuracy: 89.29206349206349\n",
      "Val accuracy: 88.5\n",
      "Iteration: 109\n",
      "Train accuracy: 89.36666666666667\n",
      "Val accuracy: 88.5142857142857\n",
      "Iteration: 110\n",
      "Train accuracy: 89.32857142857142\n",
      "Val accuracy: 88.41428571428571\n",
      "Iteration: 111\n",
      "Train accuracy: 89.4079365079365\n",
      "Val accuracy: 88.78571428571429\n",
      "Iteration: 112\n",
      "Train accuracy: 89.38253968253969\n",
      "Val accuracy: 88.45714285714286\n",
      "Iteration: 113\n",
      "Train accuracy: 89.55079365079365\n",
      "Val accuracy: 88.81428571428572\n",
      "Iteration: 114\n",
      "Train accuracy: 89.56349206349206\n",
      "Val accuracy: 88.68571428571428\n",
      "Iteration: 115\n",
      "Train accuracy: 89.66666666666666\n",
      "Val accuracy: 88.87142857142857\n",
      "Iteration: 116\n",
      "Train accuracy: 89.5111111111111\n",
      "Val accuracy: 88.61428571428571\n",
      "Iteration: 117\n",
      "Train accuracy: 89.66825396825396\n",
      "Val accuracy: 88.64285714285714\n",
      "Iteration: 118\n",
      "Train accuracy: 89.6952380952381\n",
      "Val accuracy: 88.87142857142857\n",
      "Iteration: 119\n",
      "Train accuracy: 89.67936507936508\n",
      "Val accuracy: 88.97142857142856\n",
      "Iteration: 120\n",
      "Train accuracy: 89.78253968253969\n",
      "Val accuracy: 88.9\n",
      "Iteration: 121\n",
      "Train accuracy: 89.86190476190477\n",
      "Val accuracy: 88.81428571428572\n",
      "Iteration: 122\n",
      "Train accuracy: 89.89682539682539\n",
      "Val accuracy: 88.82857142857142\n",
      "Iteration: 123\n",
      "Train accuracy: 89.93809523809524\n",
      "Val accuracy: 88.9\n",
      "Iteration: 124\n",
      "Train accuracy: 89.9079365079365\n",
      "Val accuracy: 88.91428571428571\n",
      "Iteration: 125\n",
      "Train accuracy: 89.98412698412699\n",
      "Val accuracy: 88.97142857142856\n",
      "Iteration: 126\n",
      "Train accuracy: 90.04444444444445\n",
      "Val accuracy: 88.92857142857142\n",
      "Iteration: 127\n",
      "Train accuracy: 89.95079365079364\n",
      "Val accuracy: 88.9857142857143\n",
      "Iteration: 128\n",
      "Train accuracy: 90.08571428571429\n",
      "Val accuracy: 88.9857142857143\n",
      "Iteration: 129\n",
      "Train accuracy: 90.06031746031746\n",
      "Val accuracy: 88.94285714285715\n",
      "Iteration: 130\n",
      "Train accuracy: 90.05873015873016\n",
      "Val accuracy: 89.1\n",
      "Iteration: 131\n",
      "Train accuracy: 90.19365079365079\n",
      "Val accuracy: 89.18571428571428\n",
      "Iteration: 132\n",
      "Train accuracy: 90.17777777777778\n",
      "Val accuracy: 89.18571428571428\n",
      "Iteration: 133\n",
      "Train accuracy: 90.15873015873017\n",
      "Val accuracy: 89.17142857142856\n",
      "Iteration: 134\n",
      "Train accuracy: 90.23492063492064\n",
      "Val accuracy: 89.07142857142857\n",
      "Iteration: 135\n",
      "Train accuracy: 90.17936507936508\n",
      "Val accuracy: 89.11428571428571\n",
      "Iteration: 136\n",
      "Train accuracy: 90.2095238095238\n",
      "Val accuracy: 89.1\n",
      "Iteration: 137\n",
      "Train accuracy: 90.25714285714285\n",
      "Val accuracy: 89.08571428571429\n",
      "Iteration: 138\n",
      "Train accuracy: 90.17142857142856\n",
      "Val accuracy: 89.12857142857142\n",
      "Iteration: 139\n",
      "Train accuracy: 90.2984126984127\n",
      "Val accuracy: 89.42857142857143\n",
      "Iteration: 140\n",
      "Train accuracy: 90.43968253968254\n",
      "Val accuracy: 89.4\n",
      "Iteration: 141\n",
      "Train accuracy: 90.41904761904762\n",
      "Val accuracy: 89.31428571428572\n",
      "Iteration: 142\n",
      "Train accuracy: 90.30317460317461\n",
      "Val accuracy: 89.28571428571429\n",
      "Iteration: 143\n",
      "Train accuracy: 90.32063492063493\n",
      "Val accuracy: 89.24285714285715\n",
      "Iteration: 144\n",
      "Train accuracy: 90.54920634920634\n",
      "Val accuracy: 89.31428571428572\n",
      "Iteration: 145\n",
      "Train accuracy: 90.50317460317461\n",
      "Val accuracy: 89.2\n",
      "Iteration: 146\n",
      "Train accuracy: 90.56507936507937\n",
      "Val accuracy: 89.27142857142857\n",
      "Iteration: 147\n",
      "Train accuracy: 90.5936507936508\n",
      "Val accuracy: 89.31428571428572\n",
      "Iteration: 148\n",
      "Train accuracy: 90.58730158730158\n",
      "Val accuracy: 89.3\n",
      "Iteration: 149\n",
      "Train accuracy: 90.7\n",
      "Val accuracy: 89.37142857142857\n",
      "Iteration: 150\n",
      "Train accuracy: 90.67142857142856\n",
      "Val accuracy: 89.42857142857143\n",
      "Iteration: 151\n",
      "Train accuracy: 90.73650793650793\n",
      "Val accuracy: 89.42857142857143\n",
      "Iteration: 152\n",
      "Train accuracy: 90.73809523809524\n",
      "Val accuracy: 89.5\n",
      "Iteration: 153\n",
      "Train accuracy: 90.7063492063492\n",
      "Val accuracy: 89.42857142857143\n",
      "Iteration: 154\n",
      "Train accuracy: 90.81904761904762\n",
      "Val accuracy: 89.52857142857142\n",
      "Iteration: 155\n",
      "Train accuracy: 90.85714285714286\n",
      "Val accuracy: 89.60000000000001\n",
      "Iteration: 156\n",
      "Train accuracy: 90.82063492063493\n",
      "Val accuracy: 89.4857142857143\n",
      "Iteration: 157\n",
      "Train accuracy: 90.884126984127\n",
      "Val accuracy: 89.67142857142856\n",
      "Iteration: 158\n",
      "Train accuracy: 90.85873015873017\n",
      "Val accuracy: 89.44285714285715\n",
      "Iteration: 159\n",
      "Train accuracy: 90.85714285714286\n",
      "Val accuracy: 89.57142857142857\n",
      "Iteration: 160\n",
      "Train accuracy: 90.92539682539682\n",
      "Val accuracy: 89.74285714285715\n",
      "Iteration: 161\n",
      "Train accuracy: 91.02063492063492\n",
      "Val accuracy: 89.81428571428572\n",
      "Iteration: 162\n",
      "Train accuracy: 91.03174603174602\n",
      "Val accuracy: 89.77142857142857\n",
      "Iteration: 163\n",
      "Train accuracy: 91.05079365079365\n",
      "Val accuracy: 89.7\n",
      "Iteration: 164\n",
      "Train accuracy: 91.05714285714286\n",
      "Val accuracy: 89.74285714285715\n",
      "Iteration: 165\n",
      "Train accuracy: 91.03174603174602\n",
      "Val accuracy: 89.54285714285714\n",
      "Iteration: 166\n",
      "Train accuracy: 91.1015873015873\n",
      "Val accuracy: 89.6857142857143\n",
      "Iteration: 167\n",
      "Train accuracy: 91.06349206349206\n",
      "Val accuracy: 89.71428571428571\n",
      "Iteration: 168\n",
      "Train accuracy: 91.11904761904762\n",
      "Val accuracy: 89.61428571428571\n",
      "Iteration: 169\n",
      "Train accuracy: 91.07777777777778\n",
      "Val accuracy: 89.67142857142856\n",
      "Iteration: 170\n",
      "Train accuracy: 91.18730158730159\n",
      "Val accuracy: 89.81428571428572\n",
      "Iteration: 171\n",
      "Train accuracy: 91.17619047619047\n",
      "Val accuracy: 89.74285714285715\n",
      "Iteration: 172\n",
      "Train accuracy: 91.23015873015873\n",
      "Val accuracy: 89.82857142857142\n",
      "Iteration: 173\n",
      "Train accuracy: 91.1984126984127\n",
      "Val accuracy: 89.77142857142857\n",
      "Iteration: 174\n",
      "Train accuracy: 91.18412698412698\n",
      "Val accuracy: 89.78571428571429\n",
      "Iteration: 175\n",
      "Train accuracy: 91.33492063492064\n",
      "Val accuracy: 89.81428571428572\n",
      "Iteration: 176\n",
      "Train accuracy: 91.35873015873017\n",
      "Val accuracy: 89.9\n",
      "Iteration: 177\n",
      "Train accuracy: 91.35873015873017\n",
      "Val accuracy: 89.91428571428571\n",
      "Iteration: 178\n",
      "Train accuracy: 91.36349206349207\n",
      "Val accuracy: 89.78571428571429\n",
      "Iteration: 179\n",
      "Train accuracy: 91.33968253968254\n",
      "Val accuracy: 89.87142857142857\n",
      "Iteration: 180\n",
      "Train accuracy: 91.45714285714286\n",
      "Val accuracy: 89.9\n",
      "Iteration: 181\n",
      "Train accuracy: 91.47460317460317\n",
      "Val accuracy: 89.91428571428571\n",
      "Iteration: 182\n",
      "Train accuracy: 91.48888888888888\n",
      "Val accuracy: 89.92857142857143\n",
      "Iteration: 183\n",
      "Train accuracy: 91.48571428571428\n",
      "Val accuracy: 89.91428571428571\n",
      "Iteration: 184\n",
      "Train accuracy: 91.51746031746032\n",
      "Val accuracy: 89.92857142857143\n",
      "Iteration: 185\n",
      "Train accuracy: 91.52063492063492\n",
      "Val accuracy: 90.02857142857142\n",
      "Iteration: 186\n",
      "Train accuracy: 91.48412698412697\n",
      "Val accuracy: 89.97142857142858\n",
      "Iteration: 187\n",
      "Train accuracy: 91.55079365079365\n",
      "Val accuracy: 90.14285714285715\n",
      "Iteration: 188\n",
      "Train accuracy: 91.54285714285714\n",
      "Val accuracy: 90.10000000000001\n",
      "Iteration: 189\n",
      "Train accuracy: 91.68412698412698\n",
      "Val accuracy: 90.02857142857142\n",
      "Iteration: 190\n",
      "Train accuracy: 91.72063492063492\n",
      "Val accuracy: 90.21428571428571\n",
      "Iteration: 191\n",
      "Train accuracy: 91.73015873015873\n",
      "Val accuracy: 90.15714285714286\n",
      "Iteration: 192\n",
      "Train accuracy: 91.75555555555556\n",
      "Val accuracy: 90.10000000000001\n",
      "Iteration: 193\n",
      "Train accuracy: 91.82222222222222\n",
      "Val accuracy: 90.12857142857142\n",
      "Iteration: 194\n",
      "Train accuracy: 91.8031746031746\n",
      "Val accuracy: 90.15714285714286\n",
      "Iteration: 195\n",
      "Train accuracy: 91.77619047619048\n",
      "Val accuracy: 90.11428571428571\n",
      "Iteration: 196\n",
      "Train accuracy: 91.7984126984127\n",
      "Val accuracy: 90.18571428571428\n",
      "Iteration: 197\n",
      "Train accuracy: 91.85238095238095\n",
      "Val accuracy: 90.14285714285715\n",
      "Iteration: 198\n",
      "Train accuracy: 91.87460317460318\n",
      "Val accuracy: 90.08571428571429\n",
      "Iteration: 199\n",
      "Train accuracy: 91.86349206349206\n",
      "Val accuracy: 90.11428571428571\n",
      "Iteration: 200\n",
      "Train accuracy: 91.84285714285714\n",
      "Val accuracy: 90.08571428571429\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights=stocastic_batch_grad_descent(x_train,y_train,200, 0.05, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs Iterations for Back Propagation')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_op=1\n",
    "#iters = [print_op*i for i in range(1,(iter//print_op)+1)]\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['Training accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim(80,100)\n",
    "plt.title(\"Accuracy vs Iterations for Back Propagation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs Iterations for Back Propagation')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_op=1\n",
    "#iters = [print_op*i for i in range(1,(iter//print_op)+1)]\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['Training accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim(80,100)\n",
    "plt.title(\"Accuracy vs Iterations for Back Propagation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 9.08095238095238\n",
      "Val accuracy: 9.685714285714287\n",
      "Iteration: 2\n",
      "Train accuracy: 17.814285714285713\n",
      "Val accuracy: 17.742857142857144\n",
      "Iteration: 3\n",
      "Train accuracy: 22.733333333333334\n",
      "Val accuracy: 23.085714285714285\n",
      "Iteration: 4\n",
      "Train accuracy: 27.480952380952385\n",
      "Val accuracy: 27.74285714285714\n",
      "Iteration: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-24d2ba967483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#have to change with different number of layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-5c7fab4ef800>\u001b[0m in \u001b[0;36mgrad_descent\u001b[1;34m(X, Y, iter, lr, print_op, decay_factor)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;31m#obtain training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA3_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;31m#for i in range(0, Y.shape[0]):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m        \u001b[1;31m# train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-5c7fab4ef800>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(x_train, W1, b1, W2, b2, W3, b3)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;31m#print(\"Entered FP\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m   \u001b[0mZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;31m#W1 is 50*784, x_train is 748*m, Z1 is 50*m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m   \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#have to change with different number of layers\n",
    "\n",
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = grad_descent(x_train, y_train, iter = 400, lr =  0.01, print_op = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x192684c0488>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 17.582539682539682\n",
      "Val accuracy: 17.8\n",
      "Iteration: 2\n",
      "Train accuracy: 32.63174603174603\n",
      "Val accuracy: 33.31428571428571\n",
      "Iteration: 3\n",
      "Train accuracy: 31.244444444444447\n",
      "Val accuracy: 31.485714285714284\n",
      "Iteration: 4\n",
      "Train accuracy: 34.68571428571428\n",
      "Val accuracy: 33.42857142857143\n",
      "Iteration: 5\n",
      "Train accuracy: 49.3\n",
      "Val accuracy: 50.07142857142857\n",
      "Iteration: 6\n",
      "Train accuracy: 62.661904761904765\n",
      "Val accuracy: 62.142857142857146\n",
      "Iteration: 7\n",
      "Train accuracy: 71.35714285714285\n",
      "Val accuracy: 71.54285714285714\n",
      "Iteration: 8\n",
      "Train accuracy: 73.4015873015873\n",
      "Val accuracy: 73.4\n",
      "Iteration: 9\n",
      "Train accuracy: 74.4888888888889\n",
      "Val accuracy: 74.5\n",
      "Iteration: 10\n",
      "Train accuracy: 75.32222222222222\n",
      "Val accuracy: 75.57142857142857\n",
      "Iteration: 11\n",
      "Train accuracy: 76.04920634920634\n",
      "Val accuracy: 76.14285714285714\n",
      "Iteration: 12\n",
      "Train accuracy: 76.67936507936508\n",
      "Val accuracy: 76.65714285714286\n",
      "Iteration: 13\n",
      "Train accuracy: 77.2968253968254\n",
      "Val accuracy: 77.08571428571429\n",
      "Iteration: 14\n",
      "Train accuracy: 77.84603174603174\n",
      "Val accuracy: 77.65714285714286\n",
      "Iteration: 15\n",
      "Train accuracy: 78.35238095238095\n",
      "Val accuracy: 78.07142857142857\n",
      "Iteration: 16\n",
      "Train accuracy: 78.71904761904761\n",
      "Val accuracy: 78.47142857142858\n",
      "Iteration: 17\n",
      "Train accuracy: 79.1126984126984\n",
      "Val accuracy: 78.8\n",
      "Iteration: 18\n",
      "Train accuracy: 79.49047619047619\n",
      "Val accuracy: 79.22857142857143\n",
      "Iteration: 19\n",
      "Train accuracy: 79.84444444444443\n",
      "Val accuracy: 79.55714285714286\n",
      "Iteration: 20\n",
      "Train accuracy: 80.18253968253968\n",
      "Val accuracy: 80.04285714285714\n",
      "Iteration: 21\n",
      "Train accuracy: 80.4952380952381\n",
      "Val accuracy: 80.37142857142857\n",
      "Iteration: 22\n",
      "Train accuracy: 80.78095238095237\n",
      "Val accuracy: 80.57142857142857\n",
      "Iteration: 23\n",
      "Train accuracy: 81.04920634920634\n",
      "Val accuracy: 80.87142857142857\n",
      "Iteration: 24\n",
      "Train accuracy: 81.3047619047619\n",
      "Val accuracy: 81.11428571428571\n",
      "Iteration: 25\n",
      "Train accuracy: 81.55555555555556\n",
      "Val accuracy: 81.44285714285714\n",
      "Iteration: 26\n",
      "Train accuracy: 81.7936507936508\n",
      "Val accuracy: 81.69999999999999\n",
      "Iteration: 27\n",
      "Train accuracy: 82.04920634920634\n",
      "Val accuracy: 81.94285714285714\n",
      "Iteration: 28\n",
      "Train accuracy: 82.27142857142857\n",
      "Val accuracy: 82.07142857142857\n",
      "Iteration: 29\n",
      "Train accuracy: 82.46349206349205\n",
      "Val accuracy: 82.28571428571428\n",
      "Iteration: 30\n",
      "Train accuracy: 82.66984126984127\n",
      "Val accuracy: 82.5\n",
      "Iteration: 31\n",
      "Train accuracy: 82.86825396825397\n",
      "Val accuracy: 82.65714285714286\n",
      "Iteration: 32\n",
      "Train accuracy: 83.04285714285714\n",
      "Val accuracy: 82.85714285714286\n",
      "Iteration: 33\n",
      "Train accuracy: 83.21428571428572\n",
      "Val accuracy: 83.0\n",
      "Iteration: 34\n",
      "Train accuracy: 83.35555555555555\n",
      "Val accuracy: 83.11428571428571\n",
      "Iteration: 35\n",
      "Train accuracy: 83.54444444444444\n",
      "Val accuracy: 83.25714285714285\n",
      "Iteration: 36\n",
      "Train accuracy: 83.6936507936508\n",
      "Val accuracy: 83.37142857142858\n",
      "Iteration: 37\n",
      "Train accuracy: 83.84761904761905\n",
      "Val accuracy: 83.42857142857143\n",
      "Iteration: 38\n",
      "Train accuracy: 84.02063492063492\n",
      "Val accuracy: 83.57142857142857\n",
      "Iteration: 39\n",
      "Train accuracy: 84.17142857142858\n",
      "Val accuracy: 83.72857142857143\n",
      "Iteration: 40\n",
      "Train accuracy: 84.31904761904761\n",
      "Val accuracy: 83.89999999999999\n",
      "Iteration: 41\n",
      "Train accuracy: 84.45238095238096\n",
      "Val accuracy: 83.97142857142858\n",
      "Iteration: 42\n",
      "Train accuracy: 84.55396825396826\n",
      "Val accuracy: 84.07142857142857\n",
      "Iteration: 43\n",
      "Train accuracy: 84.67777777777778\n",
      "Val accuracy: 84.11428571428571\n",
      "Iteration: 44\n",
      "Train accuracy: 84.8047619047619\n",
      "Val accuracy: 84.18571428571428\n",
      "Iteration: 45\n",
      "Train accuracy: 84.90793650793651\n",
      "Val accuracy: 84.27142857142857\n",
      "Iteration: 46\n",
      "Train accuracy: 85.02222222222223\n",
      "Val accuracy: 84.34285714285714\n",
      "Iteration: 47\n",
      "Train accuracy: 85.11269841269842\n",
      "Val accuracy: 84.47142857142858\n",
      "Iteration: 48\n",
      "Train accuracy: 85.22857142857143\n",
      "Val accuracy: 84.55714285714285\n",
      "Iteration: 49\n",
      "Train accuracy: 85.33809523809524\n",
      "Val accuracy: 84.65714285714286\n",
      "Iteration: 50\n",
      "Train accuracy: 85.45079365079366\n",
      "Val accuracy: 84.72857142857143\n",
      "Iteration: 51\n",
      "Train accuracy: 85.57142857142857\n",
      "Val accuracy: 84.87142857142858\n",
      "Iteration: 52\n",
      "Train accuracy: 85.66507936507936\n",
      "Val accuracy: 84.91428571428571\n",
      "Iteration: 53\n",
      "Train accuracy: 85.78730158730158\n",
      "Val accuracy: 84.98571428571428\n",
      "Iteration: 54\n",
      "Train accuracy: 85.85555555555555\n",
      "Val accuracy: 85.04285714285714\n",
      "Iteration: 55\n",
      "Train accuracy: 85.94761904761906\n",
      "Val accuracy: 85.1\n",
      "Iteration: 56\n",
      "Train accuracy: 86.04126984126984\n",
      "Val accuracy: 85.17142857142858\n",
      "Iteration: 57\n",
      "Train accuracy: 86.11746031746031\n",
      "Val accuracy: 85.34285714285714\n",
      "Iteration: 58\n",
      "Train accuracy: 86.21746031746031\n",
      "Val accuracy: 85.41428571428571\n",
      "Iteration: 59\n",
      "Train accuracy: 86.3015873015873\n",
      "Val accuracy: 85.45714285714286\n",
      "Iteration: 60\n",
      "Train accuracy: 86.37460317460317\n",
      "Val accuracy: 85.58571428571429\n",
      "Iteration: 61\n",
      "Train accuracy: 86.46190476190476\n",
      "Val accuracy: 85.67142857142858\n",
      "Iteration: 62\n",
      "Train accuracy: 86.53650793650793\n",
      "Val accuracy: 85.7\n",
      "Iteration: 63\n",
      "Train accuracy: 86.63333333333333\n",
      "Val accuracy: 85.78571428571429\n",
      "Iteration: 64\n",
      "Train accuracy: 86.72222222222223\n",
      "Val accuracy: 85.84285714285714\n",
      "Iteration: 65\n",
      "Train accuracy: 86.77936507936508\n",
      "Val accuracy: 85.9\n",
      "Iteration: 66\n",
      "Train accuracy: 86.84285714285714\n",
      "Val accuracy: 85.97142857142858\n",
      "Iteration: 67\n",
      "Train accuracy: 86.9015873015873\n",
      "Val accuracy: 86.05714285714285\n",
      "Iteration: 68\n",
      "Train accuracy: 86.97142857142856\n",
      "Val accuracy: 86.12857142857143\n",
      "Iteration: 69\n",
      "Train accuracy: 87.03650793650793\n",
      "Val accuracy: 86.17142857142858\n",
      "Iteration: 70\n",
      "Train accuracy: 87.0968253968254\n",
      "Val accuracy: 86.21428571428571\n",
      "Iteration: 71\n",
      "Train accuracy: 87.13968253968254\n",
      "Val accuracy: 86.32857142857144\n",
      "Iteration: 72\n",
      "Train accuracy: 87.18412698412699\n",
      "Val accuracy: 86.4\n",
      "Iteration: 73\n",
      "Train accuracy: 87.25238095238095\n",
      "Val accuracy: 86.47142857142858\n",
      "Iteration: 74\n",
      "Train accuracy: 87.31904761904762\n",
      "Val accuracy: 86.5142857142857\n",
      "Iteration: 75\n",
      "Train accuracy: 87.37619047619047\n",
      "Val accuracy: 86.57142857142858\n",
      "Iteration: 76\n",
      "Train accuracy: 87.44920634920635\n",
      "Val accuracy: 86.64285714285714\n",
      "Iteration: 77\n",
      "Train accuracy: 87.5\n",
      "Val accuracy: 86.68571428571428\n",
      "Iteration: 78\n",
      "Train accuracy: 87.55396825396825\n",
      "Val accuracy: 86.75714285714285\n",
      "Iteration: 79\n",
      "Train accuracy: 87.60793650793651\n",
      "Val accuracy: 86.84285714285714\n",
      "Iteration: 80\n",
      "Train accuracy: 87.67301587301587\n",
      "Val accuracy: 86.94285714285715\n",
      "Iteration: 81\n",
      "Train accuracy: 87.71904761904761\n",
      "Val accuracy: 86.95714285714286\n",
      "Iteration: 82\n",
      "Train accuracy: 87.76984126984127\n",
      "Val accuracy: 86.9857142857143\n",
      "Iteration: 83\n",
      "Train accuracy: 87.82222222222222\n",
      "Val accuracy: 87.02857142857144\n",
      "Iteration: 84\n",
      "Train accuracy: 87.87460317460317\n",
      "Val accuracy: 87.12857142857143\n",
      "Iteration: 85\n",
      "Train accuracy: 87.91746031746031\n",
      "Val accuracy: 87.12857142857143\n",
      "Iteration: 86\n",
      "Train accuracy: 87.96825396825398\n",
      "Val accuracy: 87.18571428571428\n",
      "Iteration: 87\n",
      "Train accuracy: 88.0111111111111\n",
      "Val accuracy: 87.2\n",
      "Iteration: 88\n",
      "Train accuracy: 88.05079365079365\n",
      "Val accuracy: 87.27142857142857\n",
      "Iteration: 89\n",
      "Train accuracy: 88.11587301587302\n",
      "Val accuracy: 87.31428571428572\n",
      "Iteration: 90\n",
      "Train accuracy: 88.15555555555555\n",
      "Val accuracy: 87.32857142857144\n",
      "Iteration: 91\n",
      "Train accuracy: 88.21111111111111\n",
      "Val accuracy: 87.4\n",
      "Iteration: 92\n",
      "Train accuracy: 88.25079365079364\n",
      "Val accuracy: 87.4857142857143\n",
      "Iteration: 93\n",
      "Train accuracy: 88.2984126984127\n",
      "Val accuracy: 87.5142857142857\n",
      "Iteration: 94\n",
      "Train accuracy: 88.34761904761905\n",
      "Val accuracy: 87.57142857142857\n",
      "Iteration: 95\n",
      "Train accuracy: 88.384126984127\n",
      "Val accuracy: 87.58571428571429\n",
      "Iteration: 96\n",
      "Train accuracy: 88.44761904761906\n",
      "Val accuracy: 87.62857142857143\n",
      "Iteration: 97\n",
      "Train accuracy: 88.48253968253968\n",
      "Val accuracy: 87.64285714285714\n",
      "Iteration: 98\n",
      "Train accuracy: 88.52063492063492\n",
      "Val accuracy: 87.68571428571428\n",
      "Iteration: 99\n",
      "Train accuracy: 88.56507936507937\n",
      "Val accuracy: 87.74285714285715\n",
      "Iteration: 100\n",
      "Train accuracy: 88.5936507936508\n",
      "Val accuracy: 87.74285714285715\n",
      "Iteration: 101\n",
      "Train accuracy: 88.64126984126985\n",
      "Val accuracy: 87.8\n",
      "Iteration: 102\n",
      "Train accuracy: 88.68730158730159\n",
      "Val accuracy: 87.84285714285714\n",
      "Iteration: 103\n",
      "Train accuracy: 88.72222222222223\n",
      "Val accuracy: 87.82857142857144\n",
      "Iteration: 104\n",
      "Train accuracy: 88.76190476190476\n",
      "Val accuracy: 87.85714285714286\n",
      "Iteration: 105\n",
      "Train accuracy: 88.80952380952381\n",
      "Val accuracy: 87.9\n",
      "Iteration: 106\n",
      "Train accuracy: 88.84126984126985\n",
      "Val accuracy: 87.95714285714286\n",
      "Iteration: 107\n",
      "Train accuracy: 88.88888888888889\n",
      "Val accuracy: 87.97142857142856\n",
      "Iteration: 108\n",
      "Train accuracy: 88.92539682539683\n",
      "Val accuracy: 88.04285714285714\n",
      "Iteration: 109\n",
      "Train accuracy: 88.97142857142856\n",
      "Val accuracy: 88.04285714285714\n",
      "Iteration: 110\n",
      "Train accuracy: 89.0095238095238\n",
      "Val accuracy: 88.07142857142857\n",
      "Iteration: 111\n",
      "Train accuracy: 89.05238095238094\n",
      "Val accuracy: 88.08571428571429\n",
      "Iteration: 112\n",
      "Train accuracy: 89.06825396825397\n",
      "Val accuracy: 88.1\n",
      "Iteration: 113\n",
      "Train accuracy: 89.10634920634921\n",
      "Val accuracy: 88.1\n",
      "Iteration: 114\n",
      "Train accuracy: 89.13174603174603\n",
      "Val accuracy: 88.12857142857143\n",
      "Iteration: 115\n",
      "Train accuracy: 89.15714285714286\n",
      "Val accuracy: 88.14285714285714\n",
      "Iteration: 116\n",
      "Train accuracy: 89.18571428571428\n",
      "Val accuracy: 88.15714285714286\n",
      "Iteration: 117\n",
      "Train accuracy: 89.21428571428571\n",
      "Val accuracy: 88.18571428571428\n",
      "Iteration: 118\n",
      "Train accuracy: 89.24126984126984\n",
      "Val accuracy: 88.21428571428571\n",
      "Iteration: 119\n",
      "Train accuracy: 89.28412698412698\n",
      "Val accuracy: 88.25714285714285\n",
      "Iteration: 120\n",
      "Train accuracy: 89.31428571428572\n",
      "Val accuracy: 88.31428571428572\n",
      "Iteration: 121\n",
      "Train accuracy: 89.35079365079365\n",
      "Val accuracy: 88.34285714285714\n",
      "Iteration: 122\n",
      "Train accuracy: 89.38095238095238\n",
      "Val accuracy: 88.4\n",
      "Iteration: 123\n",
      "Train accuracy: 89.44603174603175\n",
      "Val accuracy: 88.47142857142856\n",
      "Iteration: 124\n",
      "Train accuracy: 89.48730158730159\n",
      "Val accuracy: 88.5142857142857\n",
      "Iteration: 125\n",
      "Train accuracy: 89.51587301587301\n",
      "Val accuracy: 88.5\n",
      "Iteration: 126\n",
      "Train accuracy: 89.55079365079365\n",
      "Val accuracy: 88.5142857142857\n",
      "Iteration: 127\n",
      "Train accuracy: 89.58730158730158\n",
      "Val accuracy: 88.5142857142857\n",
      "Iteration: 128\n",
      "Train accuracy: 89.62380952380953\n",
      "Val accuracy: 88.55714285714285\n",
      "Iteration: 129\n",
      "Train accuracy: 89.65079365079364\n",
      "Val accuracy: 88.58571428571429\n",
      "Iteration: 130\n",
      "Train accuracy: 89.69047619047619\n",
      "Val accuracy: 88.58571428571429\n",
      "Iteration: 131\n",
      "Train accuracy: 89.73492063492063\n",
      "Val accuracy: 88.58571428571429\n",
      "Iteration: 132\n",
      "Train accuracy: 89.76507936507937\n",
      "Val accuracy: 88.6\n",
      "Iteration: 133\n",
      "Train accuracy: 89.78730158730158\n",
      "Val accuracy: 88.6\n",
      "Iteration: 134\n",
      "Train accuracy: 89.81587301587301\n",
      "Val accuracy: 88.62857142857142\n",
      "Iteration: 135\n",
      "Train accuracy: 89.84603174603176\n",
      "Val accuracy: 88.65714285714286\n",
      "Iteration: 136\n",
      "Train accuracy: 89.87777777777778\n",
      "Val accuracy: 88.68571428571428\n",
      "Iteration: 137\n",
      "Train accuracy: 89.9\n",
      "Val accuracy: 88.72857142857143\n",
      "Iteration: 138\n",
      "Train accuracy: 89.93015873015872\n",
      "Val accuracy: 88.75714285714285\n",
      "Iteration: 139\n",
      "Train accuracy: 89.95555555555555\n",
      "Val accuracy: 88.8\n",
      "Iteration: 140\n",
      "Train accuracy: 89.98253968253968\n",
      "Val accuracy: 88.8\n",
      "Iteration: 141\n",
      "Train accuracy: 90.0063492063492\n",
      "Val accuracy: 88.85714285714286\n",
      "Iteration: 142\n",
      "Train accuracy: 90.02539682539683\n",
      "Val accuracy: 88.91428571428571\n",
      "Iteration: 143\n",
      "Train accuracy: 90.05555555555556\n",
      "Val accuracy: 88.97142857142856\n",
      "Iteration: 144\n",
      "Train accuracy: 90.08888888888889\n",
      "Val accuracy: 88.97142857142856\n",
      "Iteration: 145\n",
      "Train accuracy: 90.11111111111111\n",
      "Val accuracy: 88.9857142857143\n",
      "Iteration: 146\n",
      "Train accuracy: 90.13492063492063\n",
      "Val accuracy: 89.0\n",
      "Iteration: 147\n",
      "Train accuracy: 90.16349206349207\n",
      "Val accuracy: 89.0142857142857\n",
      "Iteration: 148\n",
      "Train accuracy: 90.17936507936508\n",
      "Val accuracy: 89.04285714285714\n",
      "Iteration: 149\n",
      "Train accuracy: 90.1984126984127\n",
      "Val accuracy: 89.04285714285714\n",
      "Iteration: 150\n",
      "Train accuracy: 90.23174603174603\n",
      "Val accuracy: 89.08571428571429\n",
      "Iteration: 151\n",
      "Train accuracy: 90.25714285714285\n",
      "Val accuracy: 89.1\n",
      "Iteration: 152\n",
      "Train accuracy: 90.29047619047618\n",
      "Val accuracy: 89.1\n",
      "Iteration: 153\n",
      "Train accuracy: 90.31587301587301\n",
      "Val accuracy: 89.08571428571429\n",
      "Iteration: 154\n",
      "Train accuracy: 90.36190476190477\n",
      "Val accuracy: 89.1\n",
      "Iteration: 155\n",
      "Train accuracy: 90.39365079365079\n",
      "Val accuracy: 89.1\n",
      "Iteration: 156\n",
      "Train accuracy: 90.42063492063492\n",
      "Val accuracy: 89.11428571428571\n",
      "Iteration: 157\n",
      "Train accuracy: 90.44444444444444\n",
      "Val accuracy: 89.12857142857142\n",
      "Iteration: 158\n",
      "Train accuracy: 90.46984126984127\n",
      "Val accuracy: 89.15714285714286\n",
      "Iteration: 159\n",
      "Train accuracy: 90.48730158730159\n",
      "Val accuracy: 89.15714285714286\n",
      "Iteration: 160\n",
      "Train accuracy: 90.5015873015873\n",
      "Val accuracy: 89.17142857142856\n",
      "Iteration: 161\n",
      "Train accuracy: 90.53015873015873\n",
      "Val accuracy: 89.17142857142856\n",
      "Iteration: 162\n",
      "Train accuracy: 90.54920634920634\n",
      "Val accuracy: 89.17142857142856\n",
      "Iteration: 163\n",
      "Train accuracy: 90.56507936507937\n",
      "Val accuracy: 89.22857142857143\n",
      "Iteration: 164\n",
      "Train accuracy: 90.5936507936508\n",
      "Val accuracy: 89.24285714285715\n",
      "Iteration: 165\n",
      "Train accuracy: 90.6126984126984\n",
      "Val accuracy: 89.27142857142857\n",
      "Iteration: 166\n",
      "Train accuracy: 90.63015873015873\n",
      "Val accuracy: 89.3\n",
      "Iteration: 167\n",
      "Train accuracy: 90.66190476190476\n",
      "Val accuracy: 89.3\n",
      "Iteration: 168\n",
      "Train accuracy: 90.67777777777778\n",
      "Val accuracy: 89.32857142857142\n",
      "Iteration: 169\n",
      "Train accuracy: 90.7063492063492\n",
      "Val accuracy: 89.35714285714286\n",
      "Iteration: 170\n",
      "Train accuracy: 90.73809523809524\n",
      "Val accuracy: 89.37142857142857\n",
      "Iteration: 171\n",
      "Train accuracy: 90.75238095238095\n",
      "Val accuracy: 89.37142857142857\n",
      "Iteration: 172\n",
      "Train accuracy: 90.78730158730158\n",
      "Val accuracy: 89.38571428571429\n",
      "Iteration: 173\n",
      "Train accuracy: 90.81587301587302\n",
      "Val accuracy: 89.38571428571429\n",
      "Iteration: 174\n",
      "Train accuracy: 90.82698412698413\n",
      "Val accuracy: 89.41428571428571\n",
      "Iteration: 175\n",
      "Train accuracy: 90.85238095238095\n",
      "Val accuracy: 89.44285714285715\n",
      "Iteration: 176\n",
      "Train accuracy: 90.87619047619047\n",
      "Val accuracy: 89.44285714285715\n",
      "Iteration: 177\n",
      "Train accuracy: 90.88888888888889\n",
      "Val accuracy: 89.5\n",
      "Iteration: 178\n",
      "Train accuracy: 90.9079365079365\n",
      "Val accuracy: 89.51428571428572\n",
      "Iteration: 179\n",
      "Train accuracy: 90.93174603174603\n",
      "Val accuracy: 89.55714285714286\n",
      "Iteration: 180\n",
      "Train accuracy: 90.96190476190476\n",
      "Val accuracy: 89.57142857142857\n",
      "Iteration: 181\n",
      "Train accuracy: 90.98571428571428\n",
      "Val accuracy: 89.57142857142857\n",
      "Iteration: 182\n",
      "Train accuracy: 91.01587301587301\n",
      "Val accuracy: 89.60000000000001\n",
      "Iteration: 183\n",
      "Train accuracy: 91.03492063492064\n",
      "Val accuracy: 89.60000000000001\n",
      "Iteration: 184\n",
      "Train accuracy: 91.05238095238096\n",
      "Val accuracy: 89.62857142857142\n",
      "Iteration: 185\n",
      "Train accuracy: 91.08095238095238\n",
      "Val accuracy: 89.62857142857142\n",
      "Iteration: 186\n",
      "Train accuracy: 91.1126984126984\n",
      "Val accuracy: 89.64285714285715\n",
      "Iteration: 187\n",
      "Train accuracy: 91.13015873015873\n",
      "Val accuracy: 89.67142857142856\n",
      "Iteration: 188\n",
      "Train accuracy: 91.15079365079364\n",
      "Val accuracy: 89.67142857142856\n",
      "Iteration: 189\n",
      "Train accuracy: 91.16825396825396\n",
      "Val accuracy: 89.6857142857143\n",
      "Iteration: 190\n",
      "Train accuracy: 91.17460317460318\n",
      "Val accuracy: 89.6857142857143\n",
      "Iteration: 191\n",
      "Train accuracy: 91.1984126984127\n",
      "Val accuracy: 89.71428571428571\n",
      "Iteration: 192\n",
      "Train accuracy: 91.21587301587302\n",
      "Val accuracy: 89.74285714285715\n",
      "Iteration: 193\n",
      "Train accuracy: 91.23333333333333\n",
      "Val accuracy: 89.75714285714285\n",
      "Iteration: 194\n",
      "Train accuracy: 91.25079365079365\n",
      "Val accuracy: 89.8\n",
      "Iteration: 195\n",
      "Train accuracy: 91.27142857142857\n",
      "Val accuracy: 89.78571428571429\n",
      "Iteration: 196\n",
      "Train accuracy: 91.2968253968254\n",
      "Val accuracy: 89.81428571428572\n",
      "Iteration: 197\n",
      "Train accuracy: 91.30952380952381\n",
      "Val accuracy: 89.84285714285714\n",
      "Iteration: 198\n",
      "Train accuracy: 91.33809523809524\n",
      "Val accuracy: 89.9\n",
      "Iteration: 199\n",
      "Train accuracy: 91.36190476190477\n",
      "Val accuracy: 89.92857142857143\n",
      "Iteration: 200\n",
      "Train accuracy: 91.37936507936509\n",
      "Val accuracy: 89.92857142857143\n"
     ]
    }
   ],
   "source": [
    "#have to change with different number of layers\n",
    "\n",
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = grad_descent(x_train, y_train, iter = 200, lr =  0.05, print_op = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs Iterations for Back Propagation')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_op=1\n",
    "#iters = [print_op*i for i in range(1,(iter//print_op)+1)]\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['Training accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim(80,100)\n",
    "plt.title(\"Accuracy vs Iterations for Back Propagation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final MNIST CODE with variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_init(mu, sigma):\n",
    "  np.random.seed(2)\n",
    "\n",
    "  gauss_w1 = np.random.normal(mu, sigma, (500, 784))\n",
    "  gauss_b1 = np.random.normal(mu, sigma, (500, 1))\n",
    "  gauss_w2 = np.random.normal(mu, sigma, (500, 500))\n",
    "  gauss_b2 = np.random.normal(mu, sigma, (500, 1))\n",
    "  gauss_w3 = np.random.normal(mu, sigma, (10,500))\n",
    "  gauss_b3 = np.random.normal(mu, sigma, (10, 1))\n",
    "  #gauss_w4 = np.random.normal(mu, sigma, (50, 200))\n",
    "  #gauss_b4 = np.random.normal(mu, sigma, (50, 1))\n",
    "  #gauss_w5 = np.random.normal(mu, sigma, (10, 50))\n",
    "  #gauss_b5 = np.random.normal(mu, sigma, (10, 1)) \n",
    "\n",
    "  gauss_w1[gauss_w1 < 0.1] = 0.1\n",
    "  gauss_b1[gauss_b1 < 0.1] = 0.1\n",
    "  gauss_w2[gauss_w2 < 0.1] = 0.1\n",
    "  gauss_b2[gauss_b2 < 0.1] = 0.1  \n",
    "  gauss_w3[gauss_w3 < 0.1] = 0.1\n",
    "  gauss_b3[gauss_b3 < 0.1] = 0.1 \n",
    "  #gauss_w4[gauss_w4 < 0.1] = 0.1\n",
    "  #gauss_b4[gauss_b4 < 0.1] = 0.1 \n",
    "  #gauss_w5[gauss_w5 < 0.1] = 0.1\n",
    "  #gauss_b5[gauss_b5 < 0.1] = 0.1 \n",
    "\n",
    "\n",
    "  return (gauss_w1, gauss_b1, gauss_w2, gauss_b2, gauss_w3, gauss_b3)\n",
    "  \n",
    "#have to change with different number of layers\n",
    "def params_init():\n",
    "\n",
    "  #np.random.seed(2)\n",
    "  W1 = np.random.rand(500,784) - 0.5\n",
    "  b1 = np.random.rand(500,1) - 0.5\n",
    "  W2 = np.random.rand(500,500) - 0.5\n",
    "  b2 = np.random.rand(500,1) - 0.5\n",
    "  W3 = np.random.rand(10,500) - 0.5 \n",
    "  b3 = np.random.rand(10,1) - 0.5\n",
    "  #W4 = np.random.rand(50,200) - 0.5   \n",
    "  #b4 = np.random.rand(50,1) - 0.5    \n",
    "  #W5 = np.random.rand(10,50) - 0.5  \n",
    "  #b5 = np.random.rand(10,1) - 0.5    \n",
    "  print(\"Params Initialised\")\n",
    "\n",
    "  return (W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def forward(x_train, W1, b1, W2, b2, W3, b3):\n",
    "  #print(\"Entered FP\")\n",
    "  Z1 = np.matmul(W1,x_train) + b1 #W1 is 50*784, x_train is 748*m, Z1 is 50*m\n",
    "  A1 = relu(Z1)\n",
    "\n",
    "  Z2 = np.matmul(W2,A1) + b2 \n",
    "  A2 = relu(Z2)\n",
    "\n",
    "  Z3 = np.matmul(W3,A2) + b3\n",
    "  A3 = softmax(Z3)\n",
    "  \n",
    "  #Z4 = np.matmul(W4,A3) + b4\n",
    "  #A4 = relu(Z4)\n",
    "\n",
    "  #Z5 = np.matmul(W5,A4) + b5\n",
    "  #A5 = softmax(Z5)\n",
    "\n",
    "  #W2 is 10*50, A1 is 50*m\n",
    "  # print(np.exp(Z2))\n",
    "  # print(np.sum(np.exp(Z2)))\n",
    "\n",
    "  #A2 is 10*m, final predictions\n",
    "  # print(\"Fp Done\")\n",
    "\n",
    "  return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "   return np.maximum(x,0)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "  return np.exp(Z) / np.sum(np.exp(Z),0)\n",
    "\n",
    "\n",
    "def relu_d(x):\n",
    "  return x>0\n",
    "\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "  shape = (y.shape[0], 10)\n",
    "  one_hot = np.zeros(shape)\n",
    "  rows = np.arange(y.size)\n",
    "  one_hot[rows, y] = 1\n",
    "  return one_hot.T\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, y):\n",
    "  # print(\"Entered Backprop\")\n",
    "  m = y.shape[0] #m is the number of training examples\n",
    "  Y = one_hot_encoding(y)\n",
    "\n",
    "  dZ3 = (A3 - Y)\n",
    "  \n",
    "  dW3 = 1/m*np.matmul(dZ3,A2.T)\n",
    "\n",
    "  db3 = 1/m*np.sum(dZ3, axis=1)\n",
    "\n",
    "  dZ2 = np.matmul(W3.T, dZ3)*relu_d(Z2) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db2 = 1/m*np.sum(dZ2, axis=1) #db1 is 50*1\n",
    "\n",
    "  dZ1 = np.matmul(W2.T, dZ2)*relu_d(Z1) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW1 = 1/m*np.matmul(dZ1,X.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db1 = 1/m*np.sum(dZ1, axis = 1) #db1 is 50*1\n",
    "\n",
    "\n",
    "  return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr, factor=0):\n",
    "\n",
    "  #updates the parameters based on backpropogation and decay rate\n",
    "  #decay = np.exp(factor)\n",
    "\n",
    "  #W1 = W1*np.exp(-5*factor) - lr*dW1\n",
    "  #b1 = b1*np.exp(-5*factor) - lr*db1\n",
    "  #W2 = W2*np.exp(-4*factor) - lr*dW2\n",
    "  #b2 = b2*np.exp(-4*factor) - lr*db2\n",
    "  #W3 = W3*np.exp(-3*factor) - lr*dW3\n",
    "  #b3 = b3*np.exp(-3*factor) - lr*db3\n",
    "  #W4 = W4*np.exp(-2*factor) - lr*dW4\n",
    "  #b4 = b4*np.exp(-2*factor) - lr*db4\n",
    "  #W5 = W5*np.exp(-1*factor) - lr*dW5\n",
    "  #b5 = b5*np.exp(-1*factor) - lr*db5\n",
    "\n",
    "  W1 = W1 - lr*dW1\n",
    "  b1 = b1 - lr*(db1.reshape(b1.shape))\n",
    "  W2 = W2 - lr*dW2\n",
    "  b2 = b2 - lr*(db2.reshape(b2.shape))\n",
    "  W3 = W3 - lr*dW3\n",
    "  b3 = b3 - lr*(db3.reshape(b3.shape))\n",
    "  #W4 = W4 - lr*dW4\n",
    "  #b4 = b4 - lr*db4\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "def param_update_with_variability(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, gW1, gb1, gW2, gb2, gW3, gb3, lr):\n",
    "\n",
    "  #updates the parameters based on backpropogation and decay rate\n",
    "  #decay = np.exp(factor) #calculate the decay factor\n",
    "  \n",
    "  #alpha = t/t_ret, alpha around 5e-4, t_ret around 10ms, thus t_forw aorund 5e-6\n",
    "  t_forw = 5e-6\n",
    "  decay_w1 = np.exp(-3*t_forw/gW1)\n",
    "  decay_b1 = np.exp(-3*t_forw/gb1)\n",
    "  decay_w2 = np.exp(-2*t_forw/gW2)\n",
    "  decay_b2 = np.exp(-2*t_forw/gb2)\n",
    "  decay_w3 = np.exp(-1*t_forw/gW3)\n",
    "  decay_b3 = np.exp(-1*t_forw/gb3)\n",
    "\n",
    "  W1 = W1*decay_w1 - lr*dW1\n",
    "  b1 = b1*decay_b1 - lr*(db1.reshape(b1.shape))\n",
    "  W2 = W2*decay_w2 - lr*dW2\n",
    "  b2 = b2*decay_b2 - lr*(db2.reshape(b2.shape))\n",
    "  W3 = W3*decay_w3 - lr*dW3\n",
    "  b3 = b3*decay_b3 - lr*(db3.reshape(b3.shape))\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def batch_grad_descent(X,Y,iter, lr, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "  W1Weight = []\n",
    "  W2Weight = []\n",
    "  W3Weight = []\n",
    "  b1Weight = []\n",
    "  b2Weight = []\n",
    "  b3Weight = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      W1Weight.append(W1)\n",
    "      W2Weight.append(W2)\n",
    "      W3Weight.append(W3)\n",
    "      b1Weight.append(b1)\n",
    "      b2Weight.append(b2)\n",
    "      b3Weight.append(b3)\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1Weight, b1Weight, W2Weight, b2Weight, W3Weight, b3Weight, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "def batch_grad_descentwith_var(X,Y,iter, lr, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3,lr)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stocastic_batch_grad_descent(X,Y,iter, lr, batchsize, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    max_value_j = 63000//batchsize\n",
    "    j = np.random.randint(0, max_value_j) #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "    X1, Y1 = shuffle(X[:, j*batchsize: (j+1)*batchsize].T,Y[j*batchsize: (j+1)*batchsize]) #shuffle each batch\n",
    "    X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "    Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "    dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "    #W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = param_update_with_variability(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3,lr)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grad_descent(X,Y,iter, lr, print_op, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    X1, Y1 = X.T, Y\n",
    "    X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "    Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "    dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "def predictions(A):\n",
    "  #argmax returns the index of maximum value, we will feed the sigmoid output to this function \n",
    "  return np.argmax(A,0)\n",
    "\n",
    "\n",
    "def accuracy(A,Y):\n",
    "  #this will compare the predicted output to the ground truth\n",
    "  return np.sum(A == Y)/Y.shape[0]*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = batch_grad_descent(x_train,y_train,100, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to change with different number of layers\n",
    "def params_init():\n",
    "\n",
    "  #np.random.seed(2)\n",
    "  W1 = np.random.rand(500,784) - 0.5\n",
    "  b1 = np.random.rand(500,1) - 0.5\n",
    "  W2 = np.random.rand(500,500) - 0.5\n",
    "  b2 = np.random.rand(500,1) - 0.5\n",
    "  W3 = np.random.rand(10,500) - 0.5 \n",
    "  b3 = np.random.rand(10,1) - 0.5\n",
    "  #W4 = np.random.rand(50,200) - 0.5   \n",
    "  #b4 = np.random.rand(50,1) - 0.5    \n",
    "  #W5 = np.random.rand(10,50) - 0.5  \n",
    "  #b5 = np.random.rand(10,1) - 0.5    \n",
    "  print(\"Params Initialised\")\n",
    "\n",
    "  return (W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def forward(x_train, W1, b1, W2, b2, W3, b3):\n",
    "  #print(\"Entered FP\")\n",
    "  Z1 = np.matmul(W1,x_train) + b1 #W1 is 50*784, x_train is 748*m, Z1 is 50*m\n",
    "  A1 = relu(Z1)\n",
    "\n",
    "  Z2 = np.matmul(W2,A1) + b2 \n",
    "  A2 = relu(Z2)\n",
    "\n",
    "  Z3 = np.matmul(W3,A2) + b3\n",
    "  A3 = softmax(Z3)\n",
    "\n",
    "  return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "def predictions(A):\n",
    "  #argmax returns the index of maximum value, we will feed the sigmoid output to this function \n",
    "  return np.argmax(A,0)\n",
    "\n",
    "\n",
    "def accuracy(A,Y):\n",
    "  #this will compare the predicted output to the ground truth\n",
    "  return np.sum(A == Y)/Y.shape[0]*100\n",
    "\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "  shape = (y.shape[0], 10)\n",
    "  one_hot = np.zeros(shape)\n",
    "  rows = np.arange(y.size)\n",
    "  one_hot[rows, y] = 1\n",
    "  return one_hot.T\n",
    "\n",
    "def mse_loss(Y, predictions):\n",
    "  return np.sum((Y-predictions)**2)\n",
    "\n",
    "def forward_pass_for_Z1(pert, Z1):\n",
    "  _, features = Z1.shape()\n",
    "  for i in range(features):\n",
    "    Z1_copy = Z1.copy()\n",
    "    Z1_copy[i, :] += pert\n",
    "    Z1_perturbed = Z1_copy\n",
    "\n",
    "\n",
    "def node_perturbation(X, y, Z1, A1, Z2, A2, Z3, A3, W1, b1, W2, b2, W3, b3):\n",
    "  m = y.shape[0] #m is the number of training examples\n",
    "  Y = one_hot_encoding(y)\n",
    "  Z1_copy = Z1.copy()\n",
    "  Z2_copy = Z2.copy()\n",
    "  Z3_copy = Z3.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if not None:\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
