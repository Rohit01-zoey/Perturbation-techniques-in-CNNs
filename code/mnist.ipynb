{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running standard bp on mnist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer to this site - https://mlfromscratch.com/neural-network-tutorial/#/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALso this site : https://jonathanweisberg.org/post/A%20Neural%20Network%20from%20Scratch%20-%20Part%201/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "x = (x/255).astype('float32')\n",
    "y = to_categorical(y)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork():\n",
    "    def __init__(self, sizes, epochs=10, l_rate=0.001):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.l_rate = l_rate\n",
    "        self.accuracy_over_epochs = []\n",
    "\n",
    "        # we save all parameters in the neural network in this dictionary\n",
    "        self.params = self.initialization()\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        # Numerically stable with large exponentials\n",
    "        exps = np.exp(x - x.max())\n",
    "        if derivative:\n",
    "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "\n",
    "    def initialization(self):\n",
    "        # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        params = self.params\n",
    "        #print(params)\n",
    "\n",
    "        # input layer activations becomes sample\n",
    "        params['A0'] = x_train\n",
    "\n",
    "        # input layer to hidden layer 1\n",
    "        params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "        params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "        # hidden layer 1 to hidden layer 2\n",
    "        params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "        params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "        # hidden layer 2 to output layer\n",
    "        params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "        params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "        return params['A3']\n",
    "\n",
    "    def backward_pass(self, y_train, output):\n",
    "        '''\n",
    "            This is the backpropagation algorithm, for calculating the updates\n",
    "            of the neural network's parameters.\n",
    "\n",
    "            Note: There is a stability issue that causes warnings. This is \n",
    "                  caused  by the dot and multiply operations on the huge arrays.\n",
    "                  \n",
    "                  RuntimeWarning: invalid value encountered in true_divide\n",
    "                  RuntimeWarning: overflow encountered in exp\n",
    "                  RuntimeWarning: overflow encountered in square\n",
    "        '''\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "\n",
    "        training_samples = y_train.shape[1]\n",
    "        #print(training_samples)\n",
    "        # Calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "        #change_w['W3'] = np.outer(error, params['A2'])#we use np.outer since we have only training sample!\n",
    "        change_w['W3'] = np.matmul(error, params['A2'].T)\n",
    "\n",
    "        # Calculate W2 update\n",
    "        error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "        #change_w['W2'] = np.outer(error, params['A1'])\n",
    "        change_w['W2'] = np.matmul(error, params['A1'].T)\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "        #change_w['W1'] = np.outer(error, params['A0'])\n",
    "        change_w['W1'] = np.matmul(error, params['A0'].T)\n",
    "\n",
    "        #print(change_w['W2'])\n",
    "\n",
    "        return change_w\n",
    "\n",
    "    def update_network_parameters(self, changes_to_w):\n",
    "        '''\n",
    "            Update network parameters according to update rule from\n",
    "            Stochastic Gradient Descent.\n",
    "\n",
    "            θ = θ - η * ∇J(x, y), \n",
    "                theta θ:            a network parameter (e.g. a weight w)\n",
    "                eta η:              the learning rate\n",
    "                gradient ∇J(x, y):  the gradient of the objective function,\n",
    "                                    i.e. the change for a specific theta θ\n",
    "        '''\n",
    "        \n",
    "        for key, value in changes_to_w.items():\n",
    "            self.params[key] -= self.l_rate * value\n",
    "\n",
    "    def compute_accuracy(self, x_val, y_val):\n",
    "        '''\n",
    "            This function does a forward pass of x, then checks if the indices\n",
    "            of the maximum value in the output equals the indices in the label\n",
    "            y. Then it sums over each prediction and calculates the accuracy.\n",
    "        '''\n",
    "        predictions = []\n",
    "\n",
    "        for x, y in zip(x_val, y_val):\n",
    "            output = self.forward_pass(x)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(y))\n",
    "        \n",
    "        return np.mean(predictions)\n",
    "    \n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        start_time = time.time()\n",
    "        for iteration in range(self.epochs):\n",
    "            for x,y in zip(x_train, y_train):\n",
    "                output = self.forward_pass(x)\n",
    "                changes_to_w = self.backward_pass(y, output)\n",
    "                self.update_network_parameters(changes_to_w)\n",
    "            \n",
    "            accuracy = self.compute_accuracy(x_val, y_val)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, accuracy * 100\n",
    "            ))\n",
    "            self.accuracy_over_epochs.append(accuracy)\n",
    "    \n",
    "    def train_arr(self, x_train, y_train, x_val, y_val):\n",
    "        x_train_cat = np.column_stack((x_train))\n",
    "        y_train_cat = y_train.T\n",
    "        start_time = time.time()\n",
    "        for iteration in range(self.epochs):\n",
    "            output = self.forward_pass(x_train_cat)\n",
    "            changes_to_w = self.backward_pass(y_train_cat, output)\n",
    "            #print(changes_to_w)\n",
    "            self.update_network_parameters(changes_to_w)\n",
    "            \n",
    "            val_accuracy = self.compute_accuracy(x_val, y_val)\n",
    "            training_accuracy = self.compute_accuracy(x_train, y_train)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Training Accuracy: {2:.2f}%, Valdiation Accuracy: {3:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, 1000, val_accuracy * 100\n",
    "            ))\n",
    "            self.accuracy_over_epochs.append(training_accuracy)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 7.31s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.86%\n",
      "Epoch: 2, Time Spent: 12.61s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 3, Time Spent: 17.76s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.24%\n",
      "Epoch: 4, Time Spent: 23.08s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.22%\n",
      "Epoch: 5, Time Spent: 28.07s, Training Accuracy: 1000.00%, Valdiation Accuracy: 11.48%\n",
      "Epoch: 6, Time Spent: 33.28s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 7, Time Spent: 38.33s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.68%\n",
      "Epoch: 8, Time Spent: 43.27s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.70%\n",
      "Epoch: 9, Time Spent: 48.31s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.57%\n",
      "Epoch: 10, Time Spent: 53.26s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.24%\n",
      "Epoch: 11, Time Spent: 58.35s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 12, Time Spent: 64.09s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.70%\n",
      "Epoch: 13, Time Spent: 69.68s, Training Accuracy: 1000.00%, Valdiation Accuracy: 11.48%\n",
      "Epoch: 14, Time Spent: 75.20s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.86%\n",
      "Epoch: 15, Time Spent: 80.58s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.30%\n",
      "Epoch: 16, Time Spent: 85.60s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.61%\n",
      "Epoch: 17, Time Spent: 91.15s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.61%\n",
      "Epoch: 18, Time Spent: 96.42s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.61%\n",
      "Epoch: 19, Time Spent: 102.17s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.92%\n",
      "Epoch: 20, Time Spent: 107.75s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.86%\n",
      "Epoch: 21, Time Spent: 113.28s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.86%\n",
      "Epoch: 22, Time Spent: 118.95s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.22%\n",
      "Epoch: 23, Time Spent: 124.94s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.86%\n",
      "Epoch: 24, Time Spent: 130.35s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.70%\n",
      "Epoch: 25, Time Spent: 136.67s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.22%\n",
      "Epoch: 26, Time Spent: 144.54s, Training Accuracy: 1000.00%, Valdiation Accuracy: 11.48%\n",
      "Epoch: 27, Time Spent: 151.01s, Training Accuracy: 1000.00%, Valdiation Accuracy: 11.48%\n",
      "Epoch: 28, Time Spent: 156.77s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 29, Time Spent: 162.46s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.57%\n",
      "Epoch: 30, Time Spent: 168.54s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.57%\n",
      "Epoch: 31, Time Spent: 174.83s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.30%\n",
      "Epoch: 32, Time Spent: 180.30s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.30%\n",
      "Epoch: 33, Time Spent: 186.26s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.24%\n",
      "Epoch: 34, Time Spent: 192.64s, Training Accuracy: 1000.00%, Valdiation Accuracy: 9.61%\n",
      "Epoch: 35, Time Spent: 199.51s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.57%\n",
      "Epoch: 36, Time Spent: 218.08s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 37, Time Spent: 224.61s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 38, Time Spent: 230.53s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 39, Time Spent: 236.33s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 40, Time Spent: 242.34s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 41, Time Spent: 248.30s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 42, Time Spent: 254.33s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 43, Time Spent: 260.25s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 44, Time Spent: 266.03s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 45, Time Spent: 271.35s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 46, Time Spent: 276.56s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 47, Time Spent: 281.97s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 48, Time Spent: 287.83s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 49, Time Spent: 295.39s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 50, Time Spent: 302.11s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 51, Time Spent: 308.18s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 52, Time Spent: 314.21s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 53, Time Spent: 319.62s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 54, Time Spent: 325.40s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 55, Time Spent: 331.41s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 56, Time Spent: 337.73s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 57, Time Spent: 344.61s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 58, Time Spent: 350.78s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 59, Time Spent: 356.82s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 60, Time Spent: 363.43s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 61, Time Spent: 369.27s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 62, Time Spent: 375.43s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 63, Time Spent: 381.97s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 64, Time Spent: 388.27s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 65, Time Spent: 394.02s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 66, Time Spent: 400.91s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 67, Time Spent: 406.92s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 68, Time Spent: 412.80s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 69, Time Spent: 418.97s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 70, Time Spent: 425.41s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 71, Time Spent: 431.58s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 72, Time Spent: 437.35s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 73, Time Spent: 443.35s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 74, Time Spent: 449.18s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 75, Time Spent: 454.91s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 76, Time Spent: 461.32s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 77, Time Spent: 467.09s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 78, Time Spent: 472.94s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 79, Time Spent: 478.53s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 80, Time Spent: 483.92s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 81, Time Spent: 489.61s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 82, Time Spent: 495.07s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 83, Time Spent: 500.52s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 84, Time Spent: 506.31s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 85, Time Spent: 512.22s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 86, Time Spent: 518.61s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 87, Time Spent: 524.56s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 88, Time Spent: 531.48s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 89, Time Spent: 537.86s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 90, Time Spent: 543.38s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 91, Time Spent: 548.91s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 92, Time Spent: 554.70s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 93, Time Spent: 560.31s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 94, Time Spent: 565.91s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 95, Time Spent: 571.20s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 96, Time Spent: 576.60s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 97, Time Spent: 582.97s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 98, Time Spent: 591.85s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 99, Time Spent: 599.77s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n",
      "Epoch: 100, Time Spent: 608.64s, Training Accuracy: 1000.00%, Valdiation Accuracy: 10.35%\n"
     ]
    }
   ],
   "source": [
    "dnn = DeepNeuralNetwork(sizes=[784, 128, 64, 10], epochs=100, l_rate=0.001)\n",
    "dnn.train_arr(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 30.09s, Accuracy: 20.50%\n",
      "Epoch: 2, Time Spent: 57.45s, Accuracy: 27.49%\n",
      "Epoch: 3, Time Spent: 90.08s, Accuracy: 34.39%\n",
      "Epoch: 4, Time Spent: 123.35s, Accuracy: 41.07%\n",
      "Epoch: 5, Time Spent: 151.11s, Accuracy: 46.43%\n",
      "Epoch: 6, Time Spent: 178.18s, Accuracy: 50.50%\n",
      "Epoch: 7, Time Spent: 208.80s, Accuracy: 52.81%\n",
      "Epoch: 8, Time Spent: 239.97s, Accuracy: 54.68%\n",
      "Epoch: 9, Time Spent: 270.92s, Accuracy: 56.56%\n",
      "Epoch: 10, Time Spent: 304.37s, Accuracy: 59.30%\n",
      "Epoch: 11, Time Spent: 341.60s, Accuracy: 62.79%\n",
      "Epoch: 12, Time Spent: 374.20s, Accuracy: 65.42%\n",
      "Epoch: 13, Time Spent: 411.01s, Accuracy: 67.19%\n",
      "Epoch: 14, Time Spent: 448.91s, Accuracy: 68.45%\n",
      "Epoch: 15, Time Spent: 480.82s, Accuracy: 69.23%\n",
      "Epoch: 16, Time Spent: 509.25s, Accuracy: 70.05%\n",
      "Epoch: 17, Time Spent: 545.47s, Accuracy: 70.56%\n",
      "Epoch: 18, Time Spent: 579.98s, Accuracy: 70.98%\n",
      "Epoch: 19, Time Spent: 612.24s, Accuracy: 71.30%\n",
      "Epoch: 20, Time Spent: 646.37s, Accuracy: 71.58%\n",
      "Epoch: 21, Time Spent: 681.81s, Accuracy: 71.93%\n",
      "Epoch: 22, Time Spent: 714.10s, Accuracy: 72.24%\n",
      "Epoch: 23, Time Spent: 749.62s, Accuracy: 72.49%\n",
      "Epoch: 24, Time Spent: 786.50s, Accuracy: 73.90%\n",
      "Epoch: 25, Time Spent: 815.86s, Accuracy: 76.83%\n",
      "Epoch: 26, Time Spent: 842.89s, Accuracy: 77.42%\n",
      "Epoch: 27, Time Spent: 872.10s, Accuracy: 77.93%\n",
      "Epoch: 28, Time Spent: 903.92s, Accuracy: 78.10%\n",
      "Epoch: 29, Time Spent: 932.80s, Accuracy: 78.37%\n",
      "Epoch: 30, Time Spent: 964.20s, Accuracy: 78.74%\n",
      "Epoch: 31, Time Spent: 995.21s, Accuracy: 78.96%\n",
      "Epoch: 32, Time Spent: 1026.87s, Accuracy: 79.25%\n",
      "Epoch: 33, Time Spent: 1057.80s, Accuracy: 79.42%\n",
      "Epoch: 34, Time Spent: 1092.80s, Accuracy: 79.65%\n",
      "Epoch: 35, Time Spent: 1127.12s, Accuracy: 79.81%\n",
      "Epoch: 36, Time Spent: 1156.75s, Accuracy: 80.03%\n",
      "Epoch: 37, Time Spent: 1184.25s, Accuracy: 80.29%\n",
      "Epoch: 38, Time Spent: 1213.95s, Accuracy: 80.41%\n",
      "Epoch: 39, Time Spent: 1246.18s, Accuracy: 80.56%\n",
      "Epoch: 40, Time Spent: 1275.47s, Accuracy: 80.65%\n",
      "Epoch: 41, Time Spent: 1304.33s, Accuracy: 80.79%\n",
      "Epoch: 42, Time Spent: 1336.24s, Accuracy: 80.88%\n",
      "Epoch: 43, Time Spent: 1368.96s, Accuracy: 81.01%\n",
      "Epoch: 44, Time Spent: 1399.35s, Accuracy: 81.12%\n",
      "Epoch: 45, Time Spent: 1428.17s, Accuracy: 81.15%\n",
      "Epoch: 46, Time Spent: 1460.29s, Accuracy: 81.20%\n",
      "Epoch: 47, Time Spent: 1491.91s, Accuracy: 81.25%\n",
      "Epoch: 48, Time Spent: 1519.79s, Accuracy: 81.30%\n",
      "Epoch: 49, Time Spent: 1549.97s, Accuracy: 81.35%\n",
      "Epoch: 50, Time Spent: 1583.52s, Accuracy: 81.43%\n",
      "Epoch: 51, Time Spent: 1612.28s, Accuracy: 81.51%\n",
      "Epoch: 52, Time Spent: 1640.63s, Accuracy: 81.51%\n",
      "Epoch: 53, Time Spent: 1673.65s, Accuracy: 81.56%\n",
      "Epoch: 54, Time Spent: 1710.26s, Accuracy: 81.57%\n",
      "Epoch: 55, Time Spent: 1743.77s, Accuracy: 81.60%\n",
      "Epoch: 56, Time Spent: 1788.14s, Accuracy: 81.65%\n",
      "Epoch: 57, Time Spent: 1817.69s, Accuracy: 81.69%\n",
      "Epoch: 58, Time Spent: 1848.13s, Accuracy: 81.73%\n",
      "Epoch: 59, Time Spent: 1879.64s, Accuracy: 81.77%\n",
      "Epoch: 60, Time Spent: 1914.80s, Accuracy: 81.77%\n",
      "Epoch: 61, Time Spent: 1943.57s, Accuracy: 81.81%\n",
      "Epoch: 62, Time Spent: 1971.60s, Accuracy: 81.84%\n",
      "Epoch: 63, Time Spent: 2003.89s, Accuracy: 81.90%\n",
      "Epoch: 64, Time Spent: 2033.34s, Accuracy: 81.94%\n",
      "Epoch: 65, Time Spent: 2061.75s, Accuracy: 81.96%\n",
      "Epoch: 66, Time Spent: 2091.08s, Accuracy: 81.98%\n",
      "Epoch: 67, Time Spent: 2127.10s, Accuracy: 82.04%\n",
      "Epoch: 68, Time Spent: 2156.37s, Accuracy: 82.07%\n",
      "Epoch: 69, Time Spent: 2186.65s, Accuracy: 82.10%\n",
      "Epoch: 70, Time Spent: 2219.75s, Accuracy: 82.10%\n",
      "Epoch: 71, Time Spent: 2253.06s, Accuracy: 82.10%\n",
      "Epoch: 72, Time Spent: 2280.97s, Accuracy: 82.13%\n",
      "Epoch: 73, Time Spent: 2311.19s, Accuracy: 82.11%\n",
      "Epoch: 74, Time Spent: 2344.93s, Accuracy: 82.22%\n",
      "Epoch: 75, Time Spent: 2375.06s, Accuracy: 82.97%\n",
      "Epoch: 76, Time Spent: 2403.45s, Accuracy: 84.33%\n",
      "Epoch: 77, Time Spent: 2434.36s, Accuracy: 85.63%\n",
      "Epoch: 78, Time Spent: 2467.10s, Accuracy: 86.84%\n",
      "Epoch: 79, Time Spent: 2495.42s, Accuracy: 87.83%\n",
      "Epoch: 80, Time Spent: 2524.13s, Accuracy: 88.39%\n",
      "Epoch: 81, Time Spent: 2556.90s, Accuracy: 88.57%\n",
      "Epoch: 82, Time Spent: 2588.48s, Accuracy: 88.70%\n",
      "Epoch: 83, Time Spent: 2616.17s, Accuracy: 88.79%\n",
      "Epoch: 84, Time Spent: 2645.88s, Accuracy: 88.87%\n",
      "Epoch: 85, Time Spent: 2678.37s, Accuracy: 88.99%\n",
      "Epoch: 86, Time Spent: 2708.56s, Accuracy: 89.00%\n",
      "Epoch: 87, Time Spent: 2737.51s, Accuracy: 89.01%\n",
      "Epoch: 88, Time Spent: 2769.65s, Accuracy: 89.03%\n",
      "Epoch: 89, Time Spent: 2802.19s, Accuracy: 89.10%\n",
      "Epoch: 90, Time Spent: 2830.88s, Accuracy: 89.17%\n",
      "Epoch: 91, Time Spent: 2860.23s, Accuracy: 89.25%\n",
      "Epoch: 92, Time Spent: 2892.96s, Accuracy: 89.30%\n",
      "Epoch: 93, Time Spent: 2924.95s, Accuracy: 89.32%\n",
      "Epoch: 94, Time Spent: 2953.49s, Accuracy: 89.39%\n",
      "Epoch: 95, Time Spent: 2983.23s, Accuracy: 89.43%\n",
      "Epoch: 96, Time Spent: 3017.40s, Accuracy: 89.50%\n",
      "Epoch: 97, Time Spent: 3047.91s, Accuracy: 89.54%\n",
      "Epoch: 98, Time Spent: 3076.27s, Accuracy: 89.58%\n",
      "Epoch: 99, Time Spent: 3108.01s, Accuracy: 89.62%\n",
      "Epoch: 100, Time Spent: 3140.94s, Accuracy: 89.66%\n"
     ]
    }
   ],
   "source": [
    "dnn = DeepNeuralNetwork(sizes=[784, 128, 64, 10], epochs=100)\n",
    "dnn.train(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(range(1, 101), dnn.accuracy_over_epochs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim(80,100)\n",
    "plt.title(\"Accuracy\")\n",
    "#dnn.accuracy_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3229af03f1aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdnn_my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdnn_my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-565d8b9f1b83>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mchanges_to_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_network_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchanges_to_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-565d8b9f1b83>\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(self, y_train, output)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# Calculate W1 update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderivative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mchange_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dnn_my = DeepNeuralNetwork(sizes=[784, 500, 500, 10], epochs=20)\n",
    "dnn_my.train(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Weight perturbation with the above structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-d5dae4cb5c07>, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-d5dae4cb5c07>\"\u001b[1;36m, line \u001b[1;32m63\u001b[0m\n\u001b[1;33m    len_x, len_y = weight_array.shape\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class DeepNeuralNetwork_withWeighPert():\n",
    "    def __init__(self, sizes, perturbation, epochs=10, l_rate=0.001):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.perturbation = perturbation\n",
    "        self.l_rate = l_rate\n",
    "        self.accuracy_over_epochs = []\n",
    "\n",
    "        # we save all parameters in the neural network in this dictionary\n",
    "        self.params = self.initialization()\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        # Numerically stable with large exponentials\n",
    "        exps = np.exp(x - x.max())\n",
    "        if derivative:\n",
    "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "\n",
    "    def initialization(self):\n",
    "        # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        params = self.params\n",
    "\n",
    "        # input layer activations becomes sample\n",
    "        params['A0'] = x_train\n",
    "\n",
    "        # input layer to hidden layer 1\n",
    "        params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "        params['A1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "        # hidden layer 1 to hidden layer 2\n",
    "        params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "        params['A2'] = self.sigmoid(params['Z2'])\n",
    "\n",
    "        # hidden layer 2 to output layer\n",
    "        params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "        params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "        return params['A3']\n",
    "    \n",
    "    def perturbweightarray(self, weight_array):\n",
    "        '''\n",
    "            Perturbs each weight of the passed weight array and retur\n",
    "        '''\n",
    "            len_x, len_y = weight_array.shape\n",
    "            weight_array_copy = weight_array.copy()\n",
    "            for i in range(len_x):\n",
    "                for j in range(len_y):\n",
    "                    perturbed_\n",
    "\n",
    "\n",
    "    def backward_pass(self, y_train, output):\n",
    "        '''\n",
    "            This is the backpropagation algorithm, for calculating the updates\n",
    "            of the neural network's parameters.\n",
    "\n",
    "            Note: There is a stability issue that causes warnings. This is \n",
    "                  caused  by the dot and multiply operations on the huge arrays.\n",
    "                  \n",
    "                  RuntimeWarning: invalid value encountered in true_divide\n",
    "                  RuntimeWarning: overflow encountered in exp\n",
    "                  RuntimeWarning: overflow encountered in square\n",
    "        '''\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "\n",
    "        # Calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "        change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "        # Calculate W2 update\n",
    "        error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
    "        change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "        change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return change_w\n",
    "\n",
    "    def update_network_parameters(self, changes_to_w):\n",
    "        '''\n",
    "            Update network parameters according to update rule from\n",
    "            Stochastic Gradient Descent.\n",
    "\n",
    "            θ = θ - η * ∇J(x, y), \n",
    "                theta θ:            a network parameter (e.g. a weight w)\n",
    "                eta η:              the learning rate\n",
    "                gradient ∇J(x, y):  the gradient of the objective function,\n",
    "                                    i.e. the change for a specific theta θ\n",
    "        '''\n",
    "        \n",
    "        for key, value in changes_to_w.items():\n",
    "            self.params[key] -= self.l_rate * value\n",
    "\n",
    "    def compute_accuracy(self, x_val, y_val):\n",
    "        '''\n",
    "            This function does a forward pass of x, then checks if the indices\n",
    "            of the maximum value in the output equals the indices in the label\n",
    "            y. Then it sums over each prediction and calculates the accuracy.\n",
    "        '''\n",
    "        predictions = []\n",
    "\n",
    "        for x, y in zip(x_val, y_val):\n",
    "            output = self.forward_pass(x)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(y))\n",
    "        \n",
    "        return np.mean(predictions)\n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        start_time = time.time()\n",
    "        for iteration in range(self.epochs):\n",
    "            for x,y in zip(x_train, y_train):\n",
    "                output = self.forward_pass(x)\n",
    "                changes_to_w = self.backward_pass(y, output)\n",
    "                self.update_network_parameters(changes_to_w)\n",
    "            \n",
    "            accuracy = self.compute_accuracy(x_val, y_val)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, accuracy * 100\n",
    "            ))\n",
    "            self.accuracy_over_epochs.append(accuracy)\n",
    "    \n",
    "    def train_arr(self, x_train, y_train, x_val, y_val):\n",
    "        x_train_cat = np.column_stack((x_train))\n",
    "        y_train_cat = y_train.T\n",
    "        start_time = time.time()\n",
    "        for iteration in range(self.epochs):\n",
    "            output = self.forward_pass(x_train_cat)\n",
    "            changes_to_w = self.backward_pass(y_train_cat, output)\n",
    "            self.update_network_parameters(changes_to_w)\n",
    "            \n",
    "            accuracy = self.compute_accuracy(x_val, y_val)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, accuracy * 100\n",
    "            ))\n",
    "            self.accuracy_over_epochs.append(accuracy)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial and error -*PLEASE IGNORE*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3],\n",
       "       [24, 25]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[2,3]]) + np.array([1,22]).reshape((2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, derivative=False):\n",
    "    # Numerically stable with large exponentials\n",
    "    exps = np.exp(x - x.max())\n",
    "    if derivative:\n",
    "        return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "    return exps / np.sum(exps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 =np.random.randn(128, 784) \n",
    "W2 = np.random.randn(64, 128)\n",
    "W3 = np.random.randn(10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.column_stack((x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.976112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(softmax(xxx)[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 59500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx1 = np.dot(W1, xxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx1 = sigmoid(xxx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 59500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx1[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx2 = np.dot(W2, xxx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx2 = sigmoid(xxx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx3 = np.dot(W3, xxx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = softmax(xxx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 59500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 59500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 59500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(op-y_train.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (op-y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 59500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99997738e-01, -1.15259528e-05,  9.99999951e-01, ...,\n",
       "         9.99999454e-01, -1.78880452e-05, -9.12978830e-07],\n",
       "       [ 1.18155049e-10,  1.84406120e-10,  1.05692581e-11, ...,\n",
       "        -1.00000000e+00,  4.60615081e-10,  2.84104853e-12],\n",
       "       [ 7.15402525e-07,  4.35019231e-08,  1.98905361e-10, ...,\n",
       "         1.62681808e-09,  9.28006045e-09,  7.08661409e-10],\n",
       "       ...,\n",
       "       [ 4.19616005e-07,  8.71115051e-08,  2.94712388e-08, ...,\n",
       "         5.28984853e-07,  1.58859484e-05,  3.88861459e-07],\n",
       "       [ 2.34542289e-08,  1.07701098e-05, -9.99999984e-01, ...,\n",
       "         1.41512330e-08,  1.36489211e-06,  5.14609140e-07],\n",
       "       [ 5.54774886e-11,  2.20511950e-12,  2.01047579e-13, ...,\n",
       "         4.23790066e-12,  1.82545263e-11,  6.93741588e-14]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "axes = axes.flatten()\n",
    "idx = np.random.randint(0,42000,size=10)\n",
    "for i in range(10):\n",
    "    axes[i].imshow(x_train[idx[i],:].reshape(28,28), cmap='gray')\n",
    "    axes[i].axis('off') # hide the axes ticks\n",
    "    #axes[i].set_title(str(int(y_train[idx[i]])), color= 'black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2735b6444468c516a41b960c6c64c2085ccf1a81bbe6050c33fcc7c53bc45de"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
