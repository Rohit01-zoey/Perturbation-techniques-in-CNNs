{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "#fetch the mnist dataset\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_n = x.to_numpy()\n",
    "x_n = x\n",
    "#y_n = y.to_numpy()\n",
    "y_n = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 784) (7000, 784) (63000,) (7000,)\n",
      "(784, 63000) (784, 7000)\n"
     ]
    }
   ],
   "source": [
    "y_n = y_n.astype('int') #convert output to integers 0-9\n",
    "x_norm = x_n/255.0 #normalise input data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_norm, y_n, test_size=0.1, random_state=42) #split the data into train and validation\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "x_train = x_train.T #take the transpose of the training data m*784 -> 784*m\n",
    "x_val = x_val.T #take the transpose of the test data m*784 -> 784*m\n",
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveText(fPath, arr):\n",
    "    #dim1, dim2 = arr.shape\n",
    "    f = open(fPath, 'a')\n",
    "    np.savetxt(f, arr.flatten(), newline = ', ')\n",
    "    f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to change with different number of layers\n",
    "def params_init():\n",
    "\n",
    "  #np.random.seed(2)\n",
    "  W1 = np.random.rand(500,784) - 0.5\n",
    "  b1 = np.random.rand(500,1) - 0.5\n",
    "  W2 = np.random.rand(500,500) - 0.5\n",
    "  b2 = np.random.rand(500,1) - 0.5\n",
    "  W3 = np.random.rand(10,500) - 0.5 \n",
    "  b3 = np.random.rand(10,1) - 0.5\n",
    "  #W4 = np.random.rand(50,200) - 0.5   \n",
    "  #b4 = np.random.rand(50,1) - 0.5    \n",
    "  #W5 = np.random.rand(10,50) - 0.5  \n",
    "  #b5 = np.random.rand(10,1) - 0.5    \n",
    "  print(\"Params Initialised\")\n",
    "\n",
    "  return (W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def forward(x_train, W1, b1, W2, b2, W3, b3):\n",
    "  #print(\"Entered FP\")\n",
    "  Z1 = np.matmul(W1,x_train) + b1 #W1 is 50*784, x_train is 748*m, Z1 is 50*m\n",
    "  A1 = relu(Z1)\n",
    "\n",
    "  Z2 = np.matmul(W2,A1) + b2 \n",
    "  A2 = relu(Z2)\n",
    "\n",
    "  Z3 = np.matmul(W3,A2) + b3\n",
    "  A3 = softmax(Z3)\n",
    "  \n",
    "  #Z4 = np.matmul(W4,A3) + b4\n",
    "  #A4 = relu(Z4)\n",
    "\n",
    "  #Z5 = np.matmul(W5,A4) + b5\n",
    "  #A5 = softmax(Z5)\n",
    "\n",
    "  #W2 is 10*50, A1 is 50*m\n",
    "  # print(np.exp(Z2))\n",
    "  # print(np.sum(np.exp(Z2)))\n",
    "\n",
    "  #A2 is 10*m, final predictions\n",
    "  # print(\"Fp Done\")\n",
    "\n",
    "  return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "   return np.maximum(x,0)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "  return np.exp(Z) / np.sum(np.exp(Z),0)\n",
    "\n",
    "\n",
    "def relu_d(x):\n",
    "  return x>0\n",
    "\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "  shape = (y.shape[0], 10)\n",
    "  one_hot = np.zeros(shape)\n",
    "  rows = np.arange(y.size)\n",
    "  one_hot[rows, y] = 1\n",
    "  return one_hot.T\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, y):\n",
    "  # print(\"Entered Backprop\")\n",
    "  m = y.shape[0] #m is the number of training examples\n",
    "  Y = one_hot_encoding(y)\n",
    "\n",
    "  dZ3 = (A3 - Y)\n",
    "  \n",
    "  dW3 = 1/m*np.matmul(dZ3,A2.T)\n",
    "\n",
    "  db3 = 1/m*np.sum(dZ3, axis=1)\n",
    "\n",
    "  dZ2 = np.matmul(W3.T, dZ3)*relu_d(Z2) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db2 = 1/m*np.sum(dZ2, axis=1) #db1 is 50*1\n",
    "\n",
    "  dZ1 = np.matmul(W2.T, dZ2)*relu_d(Z1) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW1 = 1/m*np.matmul(dZ1,X.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db1 = 1/m*np.sum(dZ1, axis = 1) #db1 is 50*1\n",
    "\n",
    "\n",
    "  return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr, factor=0):\n",
    "\n",
    "  #updates the parameters based on backpropogation\n",
    "\n",
    "  W1 = W1 - lr*dW1\n",
    "  b1 = b1 - lr*(db1.reshape(b1.shape))\n",
    "  W2 = W2 - lr*dW2\n",
    "  b2 = b2 - lr*(db2.reshape(b2.shape))\n",
    "  W3 = W3 - lr*dW3\n",
    "  b3 = b3 - lr*(db3.reshape(b3.shape))\n",
    "  #W4 = W4 - lr*dW4\n",
    "  #b4 = b4 - lr*db4\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def batch_grad_descent(X,Y,iter, lr, print_op=1, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "\n",
    "\n",
    "    #storing the weights:\n",
    "    start = time.time()\n",
    "    basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "    saveText(basePath+\"W1.txt\", W1)\n",
    "    saveText(basePath+\"W2.txt\", W2)\n",
    "    saveText(basePath+\"W3.txt\", W3)\n",
    "    saveText(basePath+\"b1.txt\", b1)\n",
    "    saveText(basePath+\"b2.txt\", b2)\n",
    "    saveText(basePath+\"b3.txt\", b3)\n",
    "    end = time.time()\n",
    "    print(\"###Saving weights : {time}\".format(time = end - start))\n",
    "\n",
    "\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grad_descent(X,Y,iter, lr, print_op, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    X1, Y1 = X.T, Y\n",
    "    X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "    Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "    dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "def predictions(A):\n",
    "  #argmax returns the index of maximum value, we will feed the sigmoid output to this function \n",
    "  return np.argmax(A,0)\n",
    "\n",
    "\n",
    "def accuracy(A,Y):\n",
    "  #this will compare the predicted output to the ground truth\n",
    "  return np.sum(A == Y)/Y.shape[0]*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "###Saving weights : 1.6171112060546875\n",
      "Iteration: 1\n",
      "Train accuracy: 82.59206349206349\n",
      "Val accuracy: 82.51428571428572\n",
      "###Saving weights : 1.6395008563995361\n",
      "Iteration: 2\n",
      "Train accuracy: 86.95238095238095\n",
      "Val accuracy: 86.82857142857144\n",
      "###Saving weights : 1.7808353900909424\n",
      "Iteration: 3\n",
      "Train accuracy: 88.78253968253969\n",
      "Val accuracy: 87.95714285714286\n",
      "###Saving weights : 1.5638844966888428\n",
      "Iteration: 4\n",
      "Train accuracy: 90.0111111111111\n",
      "Val accuracy: 88.81428571428572\n",
      "###Saving weights : 2.6611318588256836\n",
      "Iteration: 5\n",
      "Train accuracy: 90.91269841269842\n",
      "Val accuracy: 89.52857142857142\n",
      "###Saving weights : 1.719118356704712\n",
      "Iteration: 6\n",
      "Train accuracy: 91.5984126984127\n",
      "Val accuracy: 89.91428571428571\n",
      "###Saving weights : 1.593339204788208\n",
      "Iteration: 7\n",
      "Train accuracy: 92.14920634920635\n",
      "Val accuracy: 90.44285714285715\n",
      "###Saving weights : 1.7113361358642578\n",
      "Iteration: 8\n",
      "Train accuracy: 92.61428571428571\n",
      "Val accuracy: 90.81428571428572\n",
      "###Saving weights : 1.5550007820129395\n",
      "Iteration: 9\n",
      "Train accuracy: 93.06349206349206\n",
      "Val accuracy: 91.02857142857142\n",
      "###Saving weights : 1.5412979125976562\n",
      "Iteration: 10\n",
      "Train accuracy: 93.34444444444443\n",
      "Val accuracy: 91.44285714285715\n",
      "###Saving weights : 1.537754774093628\n",
      "Iteration: 11\n",
      "Train accuracy: 93.5952380952381\n",
      "Val accuracy: 91.62857142857142\n",
      "###Saving weights : 1.5745396614074707\n",
      "Iteration: 12\n",
      "Train accuracy: 93.8\n",
      "Val accuracy: 91.97142857142858\n",
      "###Saving weights : 1.6100733280181885\n",
      "Iteration: 13\n",
      "Train accuracy: 94.02222222222221\n",
      "Val accuracy: 92.08571428571429\n",
      "###Saving weights : 1.5228829383850098\n",
      "Iteration: 14\n",
      "Train accuracy: 94.27619047619048\n",
      "Val accuracy: 92.21428571428572\n",
      "###Saving weights : 1.4951369762420654\n",
      "Iteration: 15\n",
      "Train accuracy: 94.4968253968254\n",
      "Val accuracy: 92.32857142857142\n",
      "###Saving weights : 1.5398447513580322\n",
      "Iteration: 16\n",
      "Train accuracy: 94.68730158730159\n",
      "Val accuracy: 92.35714285714286\n",
      "###Saving weights : 1.593984603881836\n",
      "Iteration: 17\n",
      "Train accuracy: 94.86507936507937\n",
      "Val accuracy: 92.5\n",
      "###Saving weights : 1.7957289218902588\n",
      "Iteration: 18\n",
      "Train accuracy: 94.97777777777779\n",
      "Val accuracy: 92.57142857142857\n",
      "###Saving weights : 1.5647602081298828\n",
      "Iteration: 19\n",
      "Train accuracy: 95.14285714285714\n",
      "Val accuracy: 92.74285714285713\n",
      "###Saving weights : 1.705171823501587\n",
      "Iteration: 20\n",
      "Train accuracy: 95.3015873015873\n",
      "Val accuracy: 92.82857142857142\n",
      "###Saving weights : 1.5453510284423828\n",
      "Iteration: 21\n",
      "Train accuracy: 95.44761904761904\n",
      "Val accuracy: 92.9\n",
      "###Saving weights : 1.516676425933838\n",
      "Iteration: 22\n",
      "Train accuracy: 95.55714285714285\n",
      "Val accuracy: 92.98571428571428\n",
      "###Saving weights : 1.636152744293213\n",
      "Iteration: 23\n",
      "Train accuracy: 95.68253968253968\n",
      "Val accuracy: 93.01428571428572\n",
      "###Saving weights : 1.5917649269104004\n",
      "Iteration: 24\n",
      "Train accuracy: 95.78412698412698\n",
      "Val accuracy: 93.05714285714286\n",
      "###Saving weights : 1.5811479091644287\n",
      "Iteration: 25\n",
      "Train accuracy: 95.91428571428573\n",
      "Val accuracy: 93.12857142857143\n",
      "###Saving weights : 1.5950124263763428\n",
      "Iteration: 26\n",
      "Train accuracy: 96.02380952380952\n",
      "Val accuracy: 93.12857142857143\n",
      "###Saving weights : 1.6121859550476074\n",
      "Iteration: 27\n",
      "Train accuracy: 96.12539682539682\n",
      "Val accuracy: 93.14285714285714\n",
      "###Saving weights : 1.5954875946044922\n",
      "Iteration: 28\n",
      "Train accuracy: 96.23650793650793\n",
      "Val accuracy: 93.14285714285714\n",
      "###Saving weights : 1.6649763584136963\n",
      "Iteration: 29\n",
      "Train accuracy: 96.31746031746032\n",
      "Val accuracy: 93.2\n",
      "###Saving weights : 1.5951306819915771\n",
      "Iteration: 30\n",
      "Train accuracy: 96.43333333333334\n",
      "Val accuracy: 93.18571428571428\n",
      "###Saving weights : 1.5828864574432373\n",
      "Iteration: 31\n",
      "Train accuracy: 96.50952380952381\n",
      "Val accuracy: 93.21428571428572\n",
      "###Saving weights : 1.5677554607391357\n",
      "Iteration: 32\n",
      "Train accuracy: 96.60634920634921\n",
      "Val accuracy: 93.24285714285713\n",
      "###Saving weights : 1.547532320022583\n",
      "Iteration: 33\n",
      "Train accuracy: 96.70793650793651\n",
      "Val accuracy: 93.27142857142857\n",
      "###Saving weights : 1.5969712734222412\n",
      "Iteration: 34\n",
      "Train accuracy: 96.78095238095239\n",
      "Val accuracy: 93.27142857142857\n",
      "###Saving weights : 1.5641059875488281\n",
      "Iteration: 35\n",
      "Train accuracy: 96.8920634920635\n",
      "Val accuracy: 93.25714285714287\n",
      "###Saving weights : 1.5529677867889404\n",
      "Iteration: 36\n",
      "Train accuracy: 96.95714285714286\n",
      "Val accuracy: 93.25714285714287\n",
      "###Saving weights : 1.4822759628295898\n",
      "Iteration: 37\n",
      "Train accuracy: 97.05873015873016\n",
      "Val accuracy: 93.31428571428572\n",
      "###Saving weights : 1.5281345844268799\n",
      "Iteration: 38\n",
      "Train accuracy: 97.12539682539682\n",
      "Val accuracy: 93.32857142857142\n",
      "###Saving weights : 1.5286307334899902\n",
      "Iteration: 39\n",
      "Train accuracy: 97.19682539682539\n",
      "Val accuracy: 93.37142857142857\n",
      "###Saving weights : 1.656545639038086\n",
      "Iteration: 40\n",
      "Train accuracy: 97.26984126984128\n",
      "Val accuracy: 93.4\n",
      "###Saving weights : 1.7384328842163086\n",
      "Iteration: 41\n",
      "Train accuracy: 97.33492063492064\n",
      "Val accuracy: 93.37142857142857\n",
      "###Saving weights : 1.5549647808074951\n",
      "Iteration: 42\n",
      "Train accuracy: 97.39682539682539\n",
      "Val accuracy: 93.42857142857143\n",
      "###Saving weights : 1.5372607707977295\n",
      "Iteration: 43\n",
      "Train accuracy: 97.46349206349207\n",
      "Val accuracy: 93.42857142857143\n",
      "###Saving weights : 1.596616506576538\n",
      "Iteration: 44\n",
      "Train accuracy: 97.51587301587301\n",
      "Val accuracy: 93.47142857142858\n",
      "###Saving weights : 1.5607664585113525\n",
      "Iteration: 45\n",
      "Train accuracy: 97.58412698412698\n",
      "Val accuracy: 93.47142857142858\n",
      "###Saving weights : 1.5196053981781006\n",
      "Iteration: 46\n",
      "Train accuracy: 97.63174603174603\n",
      "Val accuracy: 93.5\n",
      "###Saving weights : 1.5774993896484375\n",
      "Iteration: 47\n",
      "Train accuracy: 97.66984126984127\n",
      "Val accuracy: 93.55714285714286\n",
      "###Saving weights : 1.490372896194458\n",
      "Iteration: 48\n",
      "Train accuracy: 97.73492063492063\n",
      "Val accuracy: 93.48571428571428\n",
      "###Saving weights : 1.5379142761230469\n",
      "Iteration: 49\n",
      "Train accuracy: 97.78888888888889\n",
      "Val accuracy: 93.48571428571428\n",
      "###Saving weights : 1.5323641300201416\n",
      "Iteration: 50\n",
      "Train accuracy: 97.83492063492064\n",
      "Val accuracy: 93.45714285714286\n",
      "###Saving weights : 1.654905080795288\n",
      "Iteration: 51\n",
      "Train accuracy: 97.89682539682539\n",
      "Val accuracy: 93.44285714285714\n",
      "###Saving weights : 1.528961181640625\n",
      "Iteration: 52\n",
      "Train accuracy: 97.96190476190476\n",
      "Val accuracy: 93.44285714285714\n",
      "###Saving weights : 1.5420501232147217\n",
      "Iteration: 53\n",
      "Train accuracy: 98.03809523809524\n",
      "Val accuracy: 93.47142857142858\n",
      "###Saving weights : 1.5424034595489502\n",
      "Iteration: 54\n",
      "Train accuracy: 98.08253968253968\n",
      "Val accuracy: 93.48571428571428\n",
      "###Saving weights : 1.572460651397705\n",
      "Iteration: 55\n",
      "Train accuracy: 98.12698412698413\n",
      "Val accuracy: 93.45714285714286\n",
      "###Saving weights : 1.5459518432617188\n",
      "Iteration: 56\n",
      "Train accuracy: 98.17460317460316\n",
      "Val accuracy: 93.47142857142858\n",
      "###Saving weights : 1.5801653861999512\n",
      "Iteration: 57\n",
      "Train accuracy: 98.21587301587302\n",
      "Val accuracy: 93.45714285714286\n",
      "###Saving weights : 1.517176628112793\n",
      "Iteration: 58\n",
      "Train accuracy: 98.25714285714285\n",
      "Val accuracy: 93.48571428571428\n",
      "###Saving weights : 1.5191974639892578\n",
      "Iteration: 59\n",
      "Train accuracy: 98.28730158730158\n",
      "Val accuracy: 93.5\n",
      "###Saving weights : 1.522136926651001\n",
      "Iteration: 60\n",
      "Train accuracy: 98.31111111111112\n",
      "Val accuracy: 93.5\n",
      "###Saving weights : 1.5257625579833984\n",
      "Iteration: 61\n",
      "Train accuracy: 98.36031746031746\n",
      "Val accuracy: 93.55714285714286\n",
      "###Saving weights : 1.5179378986358643\n",
      "Iteration: 62\n",
      "Train accuracy: 98.4063492063492\n",
      "Val accuracy: 93.57142857142857\n",
      "###Saving weights : 1.545818567276001\n",
      "Iteration: 63\n",
      "Train accuracy: 98.44285714285715\n",
      "Val accuracy: 93.57142857142857\n",
      "###Saving weights : 1.5556840896606445\n",
      "Iteration: 64\n",
      "Train accuracy: 98.4904761904762\n",
      "Val accuracy: 93.60000000000001\n",
      "###Saving weights : 1.5507245063781738\n",
      "Iteration: 65\n",
      "Train accuracy: 98.51904761904761\n",
      "Val accuracy: 93.62857142857143\n",
      "###Saving weights : 1.5074727535247803\n",
      "Iteration: 66\n",
      "Train accuracy: 98.56349206349206\n",
      "Val accuracy: 93.62857142857143\n",
      "###Saving weights : 1.6394577026367188\n",
      "Iteration: 67\n",
      "Train accuracy: 98.60317460317461\n",
      "Val accuracy: 93.62857142857143\n",
      "###Saving weights : 1.5456938743591309\n",
      "Iteration: 68\n",
      "Train accuracy: 98.64126984126985\n",
      "Val accuracy: 93.62857142857143\n",
      "###Saving weights : 1.4805312156677246\n",
      "Iteration: 69\n",
      "Train accuracy: 98.66507936507936\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.540099859237671\n",
      "Iteration: 70\n",
      "Train accuracy: 98.71746031746031\n",
      "Val accuracy: 93.65714285714286\n",
      "###Saving weights : 1.594956636428833\n",
      "Iteration: 71\n",
      "Train accuracy: 98.75079365079365\n",
      "Val accuracy: 93.65714285714286\n",
      "###Saving weights : 1.4818804264068604\n",
      "Iteration: 72\n",
      "Train accuracy: 98.79206349206349\n",
      "Val accuracy: 93.62857142857143\n",
      "###Saving weights : 1.620025396347046\n",
      "Iteration: 73\n",
      "Train accuracy: 98.81587301587301\n",
      "Val accuracy: 93.64285714285714\n",
      "###Saving weights : 1.6099352836608887\n",
      "Iteration: 74\n",
      "Train accuracy: 98.85079365079366\n",
      "Val accuracy: 93.64285714285714\n",
      "###Saving weights : 1.5297694206237793\n",
      "Iteration: 75\n",
      "Train accuracy: 98.86349206349206\n",
      "Val accuracy: 93.64285714285714\n",
      "###Saving weights : 1.5876672267913818\n",
      "Iteration: 76\n",
      "Train accuracy: 98.88888888888889\n",
      "Val accuracy: 93.64285714285714\n",
      "###Saving weights : 1.6700191497802734\n",
      "Iteration: 77\n",
      "Train accuracy: 98.92698412698412\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.5638139247894287\n",
      "Iteration: 78\n",
      "Train accuracy: 98.94761904761906\n",
      "Val accuracy: 93.65714285714286\n",
      "###Saving weights : 1.5312623977661133\n",
      "Iteration: 79\n",
      "Train accuracy: 98.96825396825398\n",
      "Val accuracy: 93.64285714285714\n",
      "###Saving weights : 1.4793541431427002\n",
      "Iteration: 80\n",
      "Train accuracy: 99.00952380952381\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.5212438106536865\n",
      "Iteration: 81\n",
      "Train accuracy: 99.03968253968254\n",
      "Val accuracy: 93.7\n",
      "###Saving weights : 1.5198018550872803\n",
      "Iteration: 82\n",
      "Train accuracy: 99.06984126984128\n",
      "Val accuracy: 93.68571428571428\n",
      "###Saving weights : 1.5532312393188477\n",
      "Iteration: 83\n",
      "Train accuracy: 99.0904761904762\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.5229735374450684\n",
      "Iteration: 84\n",
      "Train accuracy: 99.12380952380953\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.529308557510376\n",
      "Iteration: 85\n",
      "Train accuracy: 99.15396825396824\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.592972993850708\n",
      "Iteration: 86\n",
      "Train accuracy: 99.17460317460318\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.6563804149627686\n",
      "Iteration: 87\n",
      "Train accuracy: 99.2031746031746\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.600510597229004\n",
      "Iteration: 88\n",
      "Train accuracy: 99.22222222222223\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.6076688766479492\n",
      "Iteration: 89\n",
      "Train accuracy: 99.24444444444444\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.5309159755706787\n",
      "Iteration: 90\n",
      "Train accuracy: 99.26666666666667\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.5411617755889893\n",
      "Iteration: 91\n",
      "Train accuracy: 99.28253968253968\n",
      "Val accuracy: 93.67142857142858\n",
      "###Saving weights : 1.4904544353485107\n",
      "Iteration: 92\n",
      "Train accuracy: 99.31746031746032\n",
      "Val accuracy: 93.71428571428572\n",
      "###Saving weights : 1.5249524116516113\n",
      "Iteration: 93\n",
      "Train accuracy: 99.33809523809524\n",
      "Val accuracy: 93.72857142857143\n",
      "###Saving weights : 1.6077055931091309\n",
      "Iteration: 94\n",
      "Train accuracy: 99.36984126984127\n",
      "Val accuracy: 93.75714285714287\n",
      "###Saving weights : 1.7658207416534424\n",
      "Iteration: 95\n",
      "Train accuracy: 99.3888888888889\n",
      "Val accuracy: 93.77142857142857\n",
      "###Saving weights : 1.52524995803833\n",
      "Iteration: 96\n",
      "Train accuracy: 99.40476190476191\n",
      "Val accuracy: 93.77142857142857\n",
      "###Saving weights : 1.5300037860870361\n",
      "Iteration: 97\n",
      "Train accuracy: 99.43333333333332\n",
      "Val accuracy: 93.75714285714287\n",
      "###Saving weights : 1.493210792541504\n",
      "Iteration: 98\n",
      "Train accuracy: 99.44603174603175\n",
      "Val accuracy: 93.75714285714287\n",
      "###Saving weights : 1.5594332218170166\n",
      "Iteration: 99\n",
      "Train accuracy: 99.47301587301587\n",
      "Val accuracy: 93.77142857142857\n",
      "###Saving weights : 1.5533640384674072\n",
      "Iteration: 100\n",
      "Train accuracy: 99.47936507936508\n",
      "Val accuracy: 93.75714285714287\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = batch_grad_descent(x_train,y_train,100, 0.01,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFromLine(line, shape):\n",
    "    #line = \"xx, xxx, x,....., \"\n",
    "    lineElements = np.array([float(x) for x in line.split(\", \")[:-1]]).reshape(shape)\n",
    "    return lineElements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVth(mu, sigma, shape):\n",
    "  #last dimension represents the binary rep for each weight\n",
    "  return np.random.normal(loc=mu, scale=sigma, size=shape) #each bit is represented by an sram so we need those many vth values for each mosfet in this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightTransformWithVariability(weightArray, precision, step, discreteSteps):\n",
    "  dim1, dim2 = weightArray.shape\n",
    "  sizeI = (dim1, dim2, precision)\n",
    "\n",
    "  clippedWeightIndexArray = np.digitize(np.abs(weightArray), discreteSteps) #finds the index value of the weights\n",
    "\n",
    "  vDD = 5\n",
    "  mu = 0.7#mean of the distribution\n",
    "  sigma = 1\n",
    "  #! work with sigma/mu\n",
    "  Vth = getVth(mu, sigma, sizeI)#get the array of Vth values \n",
    "\n",
    "  iOn = ((vDD - Vth)**2)*1e-06#scaling the current according to Ioff values arbitraryfor now!!\n",
    "\n",
    "  \n",
    "  iOnNominal = 1e-06*(vDD**2 - (2*vDD*mu) + (sigma**2  + mu**2))\n",
    "\n",
    "  \n",
    "  iOff = np.random.uniform(low=0, high=1e-10, size = sizeI)#no negative value\n",
    "\n",
    "  \n",
    "  analogWeightArray = np.zeros_like(weightArray, dtype=float)\n",
    "\n",
    "  for bitLevel in range(precision):\n",
    "    analogWeightArray += np.sign(weightArray) * np.where(np.bitwise_and(clippedWeightIndexArray, 2**bitLevel)>=1, iOn[:, :, bitLevel], iOff[:, :, bitLevel]) * (2**bitLevel)\n",
    "\n",
    "\n",
    "\n",
    "  weightWithVariability = (analogWeightArray/iOnNominal)*step\n",
    "  return weightWithVariability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readWriteTransform(readPath, writePath, shape, precision, step, discreteSteps):\n",
    "    #basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "    fileOpen = open(readPath, 'r')\n",
    "    iter = 0\n",
    "    for line in fileOpen:\n",
    "        start = time.time()\n",
    "        saveText(writePath, weightTransformWithVariability(loadFromLine(line, shape), precision, step, discreteSteps))\n",
    "        end = time.time()\n",
    "        print(\"#Finished reading and transforming Line {lineNo} with Time taken = {tTime}\".format(lineNo = iter, tTime = end-start))\n",
    "        iter += 1\n",
    "    fileOpen.close()\n",
    "    print(\"##Fin.##\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the variability conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 10#setting the precision value of the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wRange = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfLevels = 2**precision - 1 #no of levels of quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = round(wRange/noOfLevels, precision) #step size of each of the step after quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "discreteSteps = [round(step*i, precision) for i in range(0, noOfLevels)] #storing the values of the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished reading and transforming Line 0 with Time taken = 1.5330157279968262\n",
      "#Finished reading and transforming Line 1 with Time taken = 1.5164930820465088\n",
      "#Finished reading and transforming Line 2 with Time taken = 1.981163501739502\n",
      "#Finished reading and transforming Line 3 with Time taken = 2.741969108581543\n",
      "#Finished reading and transforming Line 4 with Time taken = 1.579768180847168\n",
      "#Finished reading and transforming Line 5 with Time taken = 1.4904804229736328\n",
      "#Finished reading and transforming Line 6 with Time taken = 1.5823612213134766\n",
      "#Finished reading and transforming Line 7 with Time taken = 1.5133306980133057\n",
      "#Finished reading and transforming Line 8 with Time taken = 1.5133943557739258\n",
      "#Finished reading and transforming Line 9 with Time taken = 1.4781494140625\n",
      "#Finished reading and transforming Line 10 with Time taken = 1.5140628814697266\n",
      "#Finished reading and transforming Line 11 with Time taken = 1.4624693393707275\n",
      "#Finished reading and transforming Line 12 with Time taken = 1.4754891395568848\n",
      "#Finished reading and transforming Line 13 with Time taken = 1.4881579875946045\n",
      "#Finished reading and transforming Line 14 with Time taken = 1.4959464073181152\n",
      "#Finished reading and transforming Line 15 with Time taken = 1.5151774883270264\n",
      "#Finished reading and transforming Line 16 with Time taken = 1.4656941890716553\n",
      "#Finished reading and transforming Line 17 with Time taken = 1.526984691619873\n",
      "#Finished reading and transforming Line 18 with Time taken = 1.5883610248565674\n",
      "#Finished reading and transforming Line 19 with Time taken = 1.4868769645690918\n",
      "#Finished reading and transforming Line 20 with Time taken = 1.5144402980804443\n",
      "#Finished reading and transforming Line 21 with Time taken = 1.4717576503753662\n",
      "#Finished reading and transforming Line 22 with Time taken = 1.4869065284729004\n",
      "#Finished reading and transforming Line 23 with Time taken = 1.5305559635162354\n",
      "#Finished reading and transforming Line 24 with Time taken = 1.471156358718872\n",
      "#Finished reading and transforming Line 25 with Time taken = 1.5019843578338623\n",
      "#Finished reading and transforming Line 26 with Time taken = 1.4523208141326904\n",
      "#Finished reading and transforming Line 27 with Time taken = 1.5217537879943848\n",
      "#Finished reading and transforming Line 28 with Time taken = 1.5105135440826416\n",
      "#Finished reading and transforming Line 29 with Time taken = 1.472149133682251\n",
      "#Finished reading and transforming Line 30 with Time taken = 1.5485875606536865\n",
      "#Finished reading and transforming Line 31 with Time taken = 1.4563982486724854\n",
      "#Finished reading and transforming Line 32 with Time taken = 1.4590647220611572\n",
      "#Finished reading and transforming Line 33 with Time taken = 1.5014657974243164\n",
      "#Finished reading and transforming Line 34 with Time taken = 1.4645442962646484\n",
      "#Finished reading and transforming Line 35 with Time taken = 1.6191620826721191\n",
      "#Finished reading and transforming Line 36 with Time taken = 1.4824235439300537\n",
      "#Finished reading and transforming Line 37 with Time taken = 1.5052399635314941\n",
      "#Finished reading and transforming Line 38 with Time taken = 1.4632179737091064\n",
      "#Finished reading and transforming Line 39 with Time taken = 1.463102102279663\n",
      "#Finished reading and transforming Line 40 with Time taken = 1.5336196422576904\n",
      "#Finished reading and transforming Line 41 with Time taken = 1.4699158668518066\n",
      "#Finished reading and transforming Line 42 with Time taken = 1.4721181392669678\n",
      "#Finished reading and transforming Line 43 with Time taken = 1.5352368354797363\n",
      "#Finished reading and transforming Line 44 with Time taken = 1.4836554527282715\n",
      "#Finished reading and transforming Line 45 with Time taken = 1.4761810302734375\n",
      "#Finished reading and transforming Line 46 with Time taken = 1.4966447353363037\n",
      "#Finished reading and transforming Line 47 with Time taken = 1.4814717769622803\n",
      "#Finished reading and transforming Line 48 with Time taken = 1.5192809104919434\n",
      "#Finished reading and transforming Line 49 with Time taken = 1.4581685066223145\n",
      "#Finished reading and transforming Line 50 with Time taken = 1.5504238605499268\n",
      "#Finished reading and transforming Line 51 with Time taken = 1.4767022132873535\n",
      "#Finished reading and transforming Line 52 with Time taken = 1.4719462394714355\n",
      "#Finished reading and transforming Line 53 with Time taken = 1.5190422534942627\n",
      "#Finished reading and transforming Line 54 with Time taken = 1.5142908096313477\n",
      "#Finished reading and transforming Line 55 with Time taken = 1.5312564373016357\n",
      "#Finished reading and transforming Line 56 with Time taken = 1.541992425918579\n",
      "#Finished reading and transforming Line 57 with Time taken = 1.490243673324585\n",
      "#Finished reading and transforming Line 58 with Time taken = 1.46413254737854\n",
      "#Finished reading and transforming Line 59 with Time taken = 1.5855374336242676\n",
      "#Finished reading and transforming Line 60 with Time taken = 1.670426607131958\n",
      "#Finished reading and transforming Line 61 with Time taken = 2.0680525302886963\n",
      "#Finished reading and transforming Line 62 with Time taken = 1.4661002159118652\n",
      "#Finished reading and transforming Line 63 with Time taken = 1.4778833389282227\n",
      "#Finished reading and transforming Line 64 with Time taken = 1.4759178161621094\n",
      "#Finished reading and transforming Line 65 with Time taken = 1.4547991752624512\n",
      "#Finished reading and transforming Line 66 with Time taken = 1.5078747272491455\n",
      "#Finished reading and transforming Line 67 with Time taken = 1.4899396896362305\n",
      "#Finished reading and transforming Line 68 with Time taken = 1.452899694442749\n",
      "#Finished reading and transforming Line 69 with Time taken = 1.4810693264007568\n",
      "#Finished reading and transforming Line 70 with Time taken = 1.486274003982544\n",
      "#Finished reading and transforming Line 71 with Time taken = 1.4589359760284424\n",
      "#Finished reading and transforming Line 72 with Time taken = 1.4721431732177734\n",
      "#Finished reading and transforming Line 73 with Time taken = 1.4780762195587158\n",
      "#Finished reading and transforming Line 74 with Time taken = 1.4812648296356201\n",
      "#Finished reading and transforming Line 75 with Time taken = 1.450881004333496\n",
      "#Finished reading and transforming Line 76 with Time taken = 1.6321074962615967\n",
      "#Finished reading and transforming Line 77 with Time taken = 1.4785606861114502\n",
      "#Finished reading and transforming Line 78 with Time taken = 1.4642314910888672\n",
      "#Finished reading and transforming Line 79 with Time taken = 1.5262928009033203\n",
      "#Finished reading and transforming Line 80 with Time taken = 1.5020239353179932\n",
      "#Finished reading and transforming Line 81 with Time taken = 1.5398290157318115\n",
      "#Finished reading and transforming Line 82 with Time taken = 1.4680366516113281\n",
      "#Finished reading and transforming Line 83 with Time taken = 1.489898681640625\n",
      "#Finished reading and transforming Line 84 with Time taken = 1.6179163455963135\n",
      "#Finished reading and transforming Line 85 with Time taken = 1.5353543758392334\n",
      "#Finished reading and transforming Line 86 with Time taken = 1.5491375923156738\n",
      "#Finished reading and transforming Line 87 with Time taken = 1.5420758724212646\n",
      "#Finished reading and transforming Line 88 with Time taken = 1.4640533924102783\n",
      "#Finished reading and transforming Line 89 with Time taken = 1.515293836593628\n",
      "#Finished reading and transforming Line 90 with Time taken = 1.5909945964813232\n",
      "#Finished reading and transforming Line 91 with Time taken = 1.4733002185821533\n",
      "#Finished reading and transforming Line 92 with Time taken = 1.5134835243225098\n",
      "#Finished reading and transforming Line 93 with Time taken = 1.4630837440490723\n",
      "#Finished reading and transforming Line 94 with Time taken = 1.461134672164917\n",
      "#Finished reading and transforming Line 95 with Time taken = 1.469510555267334\n",
      "#Finished reading and transforming Line 96 with Time taken = 1.4972262382507324\n",
      "#Finished reading and transforming Line 97 with Time taken = 1.4581687450408936\n",
      "#Finished reading and transforming Line 98 with Time taken = 1.4616034030914307\n",
      "#Finished reading and transforming Line 99 with Time taken = 1.5237467288970947\n",
      "##Fin.##\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "readWriteTransform(basePath+\"W1.txt\", basePath+\"W1var.txt\", (500, 784), precision, step, discreteSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished reading and transforming Line 0 with Time taken = 0.002029895782470703\n",
      "#Finished reading and transforming Line 1 with Time taken = 0.0039899349212646484\n",
      "#Finished reading and transforming Line 2 with Time taken = 0.0030241012573242188\n",
      "#Finished reading and transforming Line 3 with Time taken = 0.004987001419067383\n",
      "#Finished reading and transforming Line 4 with Time taken = 0.0039997100830078125\n",
      "#Finished reading and transforming Line 5 with Time taken = 0.0029833316802978516\n",
      "#Finished reading and transforming Line 6 with Time taken = 0.004029989242553711\n",
      "#Finished reading and transforming Line 7 with Time taken = 0.0019867420196533203\n",
      "#Finished reading and transforming Line 8 with Time taken = 0.0019927024841308594\n",
      "#Finished reading and transforming Line 9 with Time taken = 0.0030298233032226562\n",
      "#Finished reading and transforming Line 10 with Time taken = 0.0019922256469726562\n",
      "#Finished reading and transforming Line 11 with Time taken = 0.002989053726196289\n",
      "#Finished reading and transforming Line 12 with Time taken = 0.002003192901611328\n",
      "#Finished reading and transforming Line 13 with Time taken = 0.002969503402709961\n",
      "#Finished reading and transforming Line 14 with Time taken = 0.0029616355895996094\n",
      "#Finished reading and transforming Line 15 with Time taken = 0.00498199462890625\n",
      "#Finished reading and transforming Line 16 with Time taken = 0.0019960403442382812\n",
      "#Finished reading and transforming Line 17 with Time taken = 0.0039958953857421875\n",
      "#Finished reading and transforming Line 18 with Time taken = 0.0029840469360351562\n",
      "#Finished reading and transforming Line 19 with Time taken = 0.0039997100830078125\n",
      "#Finished reading and transforming Line 20 with Time taken = 0.002981901168823242\n",
      "#Finished reading and transforming Line 21 with Time taken = 0.0039975643157958984\n",
      "#Finished reading and transforming Line 22 with Time taken = 0.001987934112548828\n",
      "#Finished reading and transforming Line 23 with Time taken = 0.003988981246948242\n",
      "#Finished reading and transforming Line 24 with Time taken = 0.008059501647949219\n",
      "#Finished reading and transforming Line 25 with Time taken = 0.005927324295043945\n",
      "#Finished reading and transforming Line 26 with Time taken = 0.010977029800415039\n",
      "#Finished reading and transforming Line 27 with Time taken = 0.00598454475402832\n",
      "#Finished reading and transforming Line 28 with Time taken = 0.0029850006103515625\n",
      "#Finished reading and transforming Line 29 with Time taken = 0.009006261825561523\n",
      "#Finished reading and transforming Line 30 with Time taken = 0.003995180130004883\n",
      "#Finished reading and transforming Line 31 with Time taken = 0.003955841064453125\n",
      "#Finished reading and transforming Line 32 with Time taken = 0.00299072265625\n",
      "#Finished reading and transforming Line 33 with Time taken = 0.0050008296966552734\n",
      "#Finished reading and transforming Line 34 with Time taken = 0.004973411560058594\n",
      "#Finished reading and transforming Line 35 with Time taken = 0.006990194320678711\n",
      "#Finished reading and transforming Line 36 with Time taken = 0.0029821395874023438\n",
      "#Finished reading and transforming Line 37 with Time taken = 0.0043125152587890625\n",
      "#Finished reading and transforming Line 38 with Time taken = 0.0029921531677246094\n",
      "#Finished reading and transforming Line 39 with Time taken = 0.0039920806884765625\n",
      "#Finished reading and transforming Line 40 with Time taken = 0.0019960403442382812\n",
      "#Finished reading and transforming Line 41 with Time taken = 0.003987312316894531\n",
      "#Finished reading and transforming Line 42 with Time taken = 0.002992391586303711\n",
      "#Finished reading and transforming Line 43 with Time taken = 0.0039904117584228516\n",
      "#Finished reading and transforming Line 44 with Time taken = 0.0029909610748291016\n",
      "#Finished reading and transforming Line 45 with Time taken = 0.0029931068420410156\n",
      "#Finished reading and transforming Line 46 with Time taken = 0.00299072265625\n",
      "#Finished reading and transforming Line 47 with Time taken = 0.0019965171813964844\n",
      "#Finished reading and transforming Line 48 with Time taken = 0.0029764175415039062\n",
      "#Finished reading and transforming Line 49 with Time taken = 0.001993417739868164\n",
      "#Finished reading and transforming Line 50 with Time taken = 0.002988576889038086\n",
      "#Finished reading and transforming Line 51 with Time taken = 0.001995086669921875\n",
      "#Finished reading and transforming Line 52 with Time taken = 0.002332925796508789\n",
      "#Finished reading and transforming Line 53 with Time taken = 0.003021717071533203\n",
      "#Finished reading and transforming Line 54 with Time taken = 0.0019948482513427734\n",
      "#Finished reading and transforming Line 55 with Time taken = 0.002991914749145508\n",
      "#Finished reading and transforming Line 56 with Time taken = 0.0029914379119873047\n",
      "#Finished reading and transforming Line 57 with Time taken = 0.0019953250885009766\n",
      "#Finished reading and transforming Line 58 with Time taken = 0.001994609832763672\n",
      "#Finished reading and transforming Line 59 with Time taken = 0.0029938220977783203\n",
      "#Finished reading and transforming Line 60 with Time taken = 0.002990245819091797\n",
      "#Finished reading and transforming Line 61 with Time taken = 0.002992391586303711\n",
      "#Finished reading and transforming Line 62 with Time taken = 0.0029916763305664062\n",
      "#Finished reading and transforming Line 63 with Time taken = 0.0029921531677246094\n",
      "#Finished reading and transforming Line 64 with Time taken = 0.0029914379119873047\n",
      "#Finished reading and transforming Line 65 with Time taken = 0.0030281543731689453\n",
      "#Finished reading and transforming Line 66 with Time taken = 0.0029561519622802734\n",
      "#Finished reading and transforming Line 67 with Time taken = 0.003019094467163086\n",
      "#Finished reading and transforming Line 68 with Time taken = 0.0020008087158203125\n",
      "#Finished reading and transforming Line 69 with Time taken = 0.001961231231689453\n",
      "#Finished reading and transforming Line 70 with Time taken = 0.002027750015258789\n",
      "#Finished reading and transforming Line 71 with Time taken = 0.002992868423461914\n",
      "#Finished reading and transforming Line 72 with Time taken = 0.0016410350799560547\n",
      "#Finished reading and transforming Line 73 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 74 with Time taken = 0.005941629409790039\n",
      "#Finished reading and transforming Line 75 with Time taken = 0.00498652458190918\n",
      "#Finished reading and transforming Line 76 with Time taken = 0.0049860477447509766\n",
      "#Finished reading and transforming Line 77 with Time taken = 0.004746198654174805\n",
      "#Finished reading and transforming Line 78 with Time taken = 0.003991365432739258\n",
      "#Finished reading and transforming Line 79 with Time taken = 0.003762483596801758\n",
      "#Finished reading and transforming Line 80 with Time taken = 0.0029916763305664062\n",
      "#Finished reading and transforming Line 81 with Time taken = 0.0019948482513427734\n",
      "#Finished reading and transforming Line 82 with Time taken = 0.0029914379119873047\n",
      "#Finished reading and transforming Line 83 with Time taken = 0.002991914749145508\n",
      "#Finished reading and transforming Line 84 with Time taken = 0.00503230094909668\n",
      "#Finished reading and transforming Line 85 with Time taken = 0.0039484500885009766\n",
      "#Finished reading and transforming Line 86 with Time taken = 0.004021883010864258\n",
      "#Finished reading and transforming Line 87 with Time taken = 0.002999544143676758\n",
      "#Finished reading and transforming Line 88 with Time taken = 0.0029854774475097656\n",
      "#Finished reading and transforming Line 89 with Time taken = 0.002991914749145508\n",
      "#Finished reading and transforming Line 90 with Time taken = 0.0003991127014160156\n",
      "#Finished reading and transforming Line 91 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 92 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 93 with Time taken = 0.006989717483520508\n",
      "#Finished reading and transforming Line 94 with Time taken = 0.006980180740356445\n",
      "#Finished reading and transforming Line 95 with Time taken = 0.005976676940917969\n",
      "#Finished reading and transforming Line 96 with Time taken = 0.005748748779296875\n",
      "#Finished reading and transforming Line 97 with Time taken = 0.0040280818939208984\n",
      "#Finished reading and transforming Line 98 with Time taken = 0.003803253173828125\n",
      "#Finished reading and transforming Line 99 with Time taken = 0.003990650177001953\n",
      "##Fin.##\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "readWriteTransform(basePath+\"b1.txt\", basePath+\"b1var.txt\", (500, 1), precision, step, discreteSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished reading and transforming Line 0 with Time taken = 0.918778657913208\n",
      "#Finished reading and transforming Line 1 with Time taken = 0.9105308055877686\n",
      "#Finished reading and transforming Line 2 with Time taken = 1.4318904876708984\n",
      "#Finished reading and transforming Line 3 with Time taken = 1.28074049949646\n",
      "#Finished reading and transforming Line 4 with Time taken = 1.0136098861694336\n",
      "#Finished reading and transforming Line 5 with Time taken = 1.047804832458496\n",
      "#Finished reading and transforming Line 6 with Time taken = 0.961064338684082\n",
      "#Finished reading and transforming Line 7 with Time taken = 1.0083281993865967\n",
      "#Finished reading and transforming Line 8 with Time taken = 0.9599597454071045\n",
      "#Finished reading and transforming Line 9 with Time taken = 0.9499461650848389\n",
      "#Finished reading and transforming Line 10 with Time taken = 0.9453027248382568\n",
      "#Finished reading and transforming Line 11 with Time taken = 0.9864223003387451\n",
      "#Finished reading and transforming Line 12 with Time taken = 0.9370639324188232\n",
      "#Finished reading and transforming Line 13 with Time taken = 0.9361703395843506\n",
      "#Finished reading and transforming Line 14 with Time taken = 0.9343686103820801\n",
      "#Finished reading and transforming Line 15 with Time taken = 0.9529101848602295\n",
      "#Finished reading and transforming Line 16 with Time taken = 0.9341518878936768\n",
      "#Finished reading and transforming Line 17 with Time taken = 0.9733536243438721\n",
      "#Finished reading and transforming Line 18 with Time taken = 0.9344134330749512\n",
      "#Finished reading and transforming Line 19 with Time taken = 0.935429573059082\n",
      "#Finished reading and transforming Line 20 with Time taken = 1.039367437362671\n",
      "#Finished reading and transforming Line 21 with Time taken = 0.9698498249053955\n",
      "#Finished reading and transforming Line 22 with Time taken = 0.9596569538116455\n",
      "#Finished reading and transforming Line 23 with Time taken = 0.9524385929107666\n",
      "#Finished reading and transforming Line 24 with Time taken = 0.9511511325836182\n",
      "#Finished reading and transforming Line 25 with Time taken = 0.9334793090820312\n",
      "#Finished reading and transforming Line 26 with Time taken = 0.9285714626312256\n",
      "#Finished reading and transforming Line 27 with Time taken = 0.9587066173553467\n",
      "#Finished reading and transforming Line 28 with Time taken = 0.954277515411377\n",
      "#Finished reading and transforming Line 29 with Time taken = 0.9509756565093994\n",
      "#Finished reading and transforming Line 30 with Time taken = 0.9300253391265869\n",
      "#Finished reading and transforming Line 31 with Time taken = 0.9300663471221924\n",
      "#Finished reading and transforming Line 32 with Time taken = 1.004931926727295\n",
      "#Finished reading and transforming Line 33 with Time taken = 0.9404706954956055\n",
      "#Finished reading and transforming Line 34 with Time taken = 0.9377529621124268\n",
      "#Finished reading and transforming Line 35 with Time taken = 1.0044996738433838\n",
      "#Finished reading and transforming Line 36 with Time taken = 1.8105251789093018\n",
      "#Finished reading and transforming Line 37 with Time taken = 0.9564146995544434\n",
      "#Finished reading and transforming Line 38 with Time taken = 0.9464354515075684\n",
      "#Finished reading and transforming Line 39 with Time taken = 0.9487919807434082\n",
      "#Finished reading and transforming Line 40 with Time taken = 0.9159393310546875\n",
      "#Finished reading and transforming Line 41 with Time taken = 0.954796552658081\n",
      "#Finished reading and transforming Line 42 with Time taken = 0.9483728408813477\n",
      "#Finished reading and transforming Line 43 with Time taken = 0.9266982078552246\n",
      "#Finished reading and transforming Line 44 with Time taken = 0.9152014255523682\n",
      "#Finished reading and transforming Line 45 with Time taken = 0.9256868362426758\n",
      "#Finished reading and transforming Line 46 with Time taken = 0.9161376953125\n",
      "#Finished reading and transforming Line 47 with Time taken = 1.036996603012085\n",
      "#Finished reading and transforming Line 48 with Time taken = 0.9200944900512695\n",
      "#Finished reading and transforming Line 49 with Time taken = 0.9140758514404297\n",
      "#Finished reading and transforming Line 50 with Time taken = 0.9289605617523193\n",
      "#Finished reading and transforming Line 51 with Time taken = 0.9120156764984131\n",
      "#Finished reading and transforming Line 52 with Time taken = 1.0097508430480957\n",
      "#Finished reading and transforming Line 53 with Time taken = 0.9198071956634521\n",
      "#Finished reading and transforming Line 54 with Time taken = 0.9836869239807129\n",
      "#Finished reading and transforming Line 55 with Time taken = 0.9167139530181885\n",
      "#Finished reading and transforming Line 56 with Time taken = 0.9209568500518799\n",
      "#Finished reading and transforming Line 57 with Time taken = 0.949122428894043\n",
      "#Finished reading and transforming Line 58 with Time taken = 0.9115004539489746\n",
      "#Finished reading and transforming Line 59 with Time taken = 0.9193224906921387\n",
      "#Finished reading and transforming Line 60 with Time taken = 0.9334783554077148\n",
      "#Finished reading and transforming Line 61 with Time taken = 0.9222049713134766\n",
      "#Finished reading and transforming Line 62 with Time taken = 0.964421272277832\n",
      "#Finished reading and transforming Line 63 with Time taken = 0.9247055053710938\n",
      "#Finished reading and transforming Line 64 with Time taken = 0.9272956848144531\n",
      "#Finished reading and transforming Line 65 with Time taken = 0.923677921295166\n",
      "#Finished reading and transforming Line 66 with Time taken = 0.9252679347991943\n",
      "#Finished reading and transforming Line 67 with Time taken = 0.9806239604949951\n",
      "#Finished reading and transforming Line 68 with Time taken = 0.9272346496582031\n",
      "#Finished reading and transforming Line 69 with Time taken = 0.9306669235229492\n",
      "#Finished reading and transforming Line 70 with Time taken = 0.9348440170288086\n",
      "#Finished reading and transforming Line 71 with Time taken = 0.908649206161499\n",
      "#Finished reading and transforming Line 72 with Time taken = 0.9550797939300537\n",
      "#Finished reading and transforming Line 73 with Time taken = 0.9275901317596436\n",
      "#Finished reading and transforming Line 74 with Time taken = 0.932786226272583\n",
      "#Finished reading and transforming Line 75 with Time taken = 0.966731071472168\n",
      "#Finished reading and transforming Line 76 with Time taken = 1.0005629062652588\n",
      "#Finished reading and transforming Line 77 with Time taken = 0.9363689422607422\n",
      "#Finished reading and transforming Line 78 with Time taken = 0.9382994174957275\n",
      "#Finished reading and transforming Line 79 with Time taken = 0.9169921875\n",
      "#Finished reading and transforming Line 80 with Time taken = 0.9316732883453369\n",
      "#Finished reading and transforming Line 81 with Time taken = 0.9977037906646729\n",
      "#Finished reading and transforming Line 82 with Time taken = 0.9285988807678223\n",
      "#Finished reading and transforming Line 83 with Time taken = 0.9335193634033203\n",
      "#Finished reading and transforming Line 84 with Time taken = 0.9290235042572021\n",
      "#Finished reading and transforming Line 85 with Time taken = 0.9227335453033447\n",
      "#Finished reading and transforming Line 86 with Time taken = 0.9211087226867676\n",
      "#Finished reading and transforming Line 87 with Time taken = 0.9436666965484619\n",
      "#Finished reading and transforming Line 88 with Time taken = 0.9339084625244141\n",
      "#Finished reading and transforming Line 89 with Time taken = 0.9316940307617188\n",
      "#Finished reading and transforming Line 90 with Time taken = 0.9411826133728027\n",
      "#Finished reading and transforming Line 91 with Time taken = 0.9465799331665039\n",
      "#Finished reading and transforming Line 92 with Time taken = 1.0433201789855957\n",
      "#Finished reading and transforming Line 93 with Time taken = 0.9579548835754395\n",
      "#Finished reading and transforming Line 94 with Time taken = 0.9520237445831299\n",
      "#Finished reading and transforming Line 95 with Time taken = 0.9418032169342041\n",
      "#Finished reading and transforming Line 96 with Time taken = 0.9212160110473633\n",
      "#Finished reading and transforming Line 97 with Time taken = 0.9351272583007812\n",
      "#Finished reading and transforming Line 98 with Time taken = 0.918879508972168\n",
      "#Finished reading and transforming Line 99 with Time taken = 0.9189925193786621\n",
      "##Fin.##\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "readWriteTransform(basePath+\"W2.txt\", basePath+\"W2var.txt\", (500, 500), precision, step, discreteSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished reading and transforming Line 0 with Time taken = 0.004984617233276367\n",
      "#Finished reading and transforming Line 1 with Time taken = 0.005953311920166016\n",
      "#Finished reading and transforming Line 2 with Time taken = 0.005983114242553711\n",
      "#Finished reading and transforming Line 3 with Time taken = 0.003989219665527344\n",
      "#Finished reading and transforming Line 4 with Time taken = 0.0035610198974609375\n",
      "#Finished reading and transforming Line 5 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 6 with Time taken = 0.008120059967041016\n",
      "#Finished reading and transforming Line 7 with Time taken = 0.003985404968261719\n",
      "#Finished reading and transforming Line 8 with Time taken = 0.001995086669921875\n",
      "#Finished reading and transforming Line 9 with Time taken = 0.0019969940185546875\n",
      "#Finished reading and transforming Line 10 with Time taken = 0.002990245819091797\n",
      "#Finished reading and transforming Line 11 with Time taken = 0.0008041858673095703\n",
      "#Finished reading and transforming Line 12 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 13 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 14 with Time taken = 0.006333827972412109\n",
      "#Finished reading and transforming Line 15 with Time taken = 0.0029914379119873047\n",
      "#Finished reading and transforming Line 16 with Time taken = 0.002802133560180664\n",
      "#Finished reading and transforming Line 17 with Time taken = 0.001993417739868164\n",
      "#Finished reading and transforming Line 18 with Time taken = 0.001995086669921875\n",
      "#Finished reading and transforming Line 19 with Time taken = 0.002991914749145508\n",
      "#Finished reading and transforming Line 20 with Time taken = 0.0029921531677246094\n",
      "#Finished reading and transforming Line 21 with Time taken = 0.0029914379119873047\n",
      "#Finished reading and transforming Line 22 with Time taken = 0.001996278762817383\n",
      "#Finished reading and transforming Line 23 with Time taken = 0.002990245819091797\n",
      "#Finished reading and transforming Line 24 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 25 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 26 with Time taken = 0.014503717422485352\n",
      "#Finished reading and transforming Line 27 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 28 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 29 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 30 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 31 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 32 with Time taken = 0.01562643051147461\n",
      "#Finished reading and transforming Line 33 with Time taken = 0.002961874008178711\n",
      "#Finished reading and transforming Line 34 with Time taken = 0.004123687744140625\n",
      "#Finished reading and transforming Line 35 with Time taken = 0.0019936561584472656\n",
      "#Finished reading and transforming Line 36 with Time taken = 0.0019948482513427734\n",
      "#Finished reading and transforming Line 37 with Time taken = 0.0019881725311279297\n",
      "#Finished reading and transforming Line 38 with Time taken = 0.0019948482513427734\n",
      "#Finished reading and transforming Line 39 with Time taken = 0.0019943714141845703\n",
      "#Finished reading and transforming Line 40 with Time taken = 0.0019953250885009766\n",
      "#Finished reading and transforming Line 41 with Time taken = 0.0029916763305664062\n",
      "#Finished reading and transforming Line 42 with Time taken = 0.0017921924591064453\n",
      "#Finished reading and transforming Line 43 with Time taken = 0.0029916763305664062\n",
      "#Finished reading and transforming Line 44 with Time taken = 0.0029914379119873047\n",
      "#Finished reading and transforming Line 45 with Time taken = 0.002794981002807617\n",
      "#Finished reading and transforming Line 46 with Time taken = 0.0029916763305664062\n",
      "#Finished reading and transforming Line 47 with Time taken = 0.0019958019256591797\n",
      "#Finished reading and transforming Line 48 with Time taken = 0.001973867416381836\n",
      "#Finished reading and transforming Line 49 with Time taken = 0.001995086669921875\n",
      "#Finished reading and transforming Line 50 with Time taken = 0.0029916763305664062\n",
      "#Finished reading and transforming Line 51 with Time taken = 0.0029931068420410156\n",
      "#Finished reading and transforming Line 52 with Time taken = 0.001993894577026367\n",
      "#Finished reading and transforming Line 53 with Time taken = 0.0008871555328369141\n",
      "#Finished reading and transforming Line 54 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 55 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 56 with Time taken = 0.017690658569335938\n",
      "#Finished reading and transforming Line 57 with Time taken = 0.006126880645751953\n",
      "#Finished reading and transforming Line 58 with Time taken = 0.004987955093383789\n",
      "#Finished reading and transforming Line 59 with Time taken = 0.004990339279174805\n",
      "#Finished reading and transforming Line 60 with Time taken = 0.003987550735473633\n",
      "#Finished reading and transforming Line 61 with Time taken = 0.0029921531677246094\n",
      "#Finished reading and transforming Line 62 with Time taken = 0.0029909610748291016\n",
      "#Finished reading and transforming Line 63 with Time taken = 0.003988742828369141\n",
      "#Finished reading and transforming Line 64 with Time taken = 0.0049860477447509766\n",
      "#Finished reading and transforming Line 65 with Time taken = 0.003989696502685547\n",
      "#Finished reading and transforming Line 66 with Time taken = 0.003991365432739258\n",
      "#Finished reading and transforming Line 67 with Time taken = 0.002988576889038086\n",
      "#Finished reading and transforming Line 68 with Time taken = 0.0029926300048828125\n",
      "#Finished reading and transforming Line 69 with Time taken = 0.001993894577026367\n",
      "#Finished reading and transforming Line 70 with Time taken = 0.002991914749145508\n",
      "#Finished reading and transforming Line 71 with Time taken = 0.0019953250885009766\n",
      "#Finished reading and transforming Line 72 with Time taken = 0.0019941329956054688\n",
      "#Finished reading and transforming Line 73 with Time taken = 0.001994609832763672\n",
      "#Finished reading and transforming Line 74 with Time taken = 0.008970975875854492\n",
      "#Finished reading and transforming Line 75 with Time taken = 0.00701904296875\n",
      "#Finished reading and transforming Line 76 with Time taken = 0.0003452301025390625\n",
      "#Finished reading and transforming Line 77 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 78 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 79 with Time taken = 0.015655994415283203\n",
      "#Finished reading and transforming Line 80 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 81 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 82 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 83 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 84 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 85 with Time taken = 0.01558375358581543\n",
      "#Finished reading and transforming Line 86 with Time taken = 0.0033981800079345703\n",
      "#Finished reading and transforming Line 87 with Time taken = 0.002026796340942383\n",
      "#Finished reading and transforming Line 88 with Time taken = 0.001997232437133789\n",
      "#Finished reading and transforming Line 89 with Time taken = 0.001975536346435547\n",
      "#Finished reading and transforming Line 90 with Time taken = 0.0020296573638916016\n",
      "#Finished reading and transforming Line 91 with Time taken = 0.0019922256469726562\n",
      "#Finished reading and transforming Line 92 with Time taken = 0.0029935836791992188\n",
      "#Finished reading and transforming Line 93 with Time taken = 0.0019936561584472656\n",
      "#Finished reading and transforming Line 94 with Time taken = 0.001999378204345703\n",
      "#Finished reading and transforming Line 95 with Time taken = 0.0019915103912353516\n",
      "#Finished reading and transforming Line 96 with Time taken = 0.0008478164672851562\n",
      "#Finished reading and transforming Line 97 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 98 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 99 with Time taken = 0.0\n",
      "##Fin.##\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "readWriteTransform(basePath+\"b2.txt\", basePath+\"b2var.txt\", (500, 1), precision, step, discreteSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished reading and transforming Line 0 with Time taken = 0.00997471809387207\n",
      "#Finished reading and transforming Line 1 with Time taken = 0.023895263671875\n",
      "#Finished reading and transforming Line 2 with Time taken = 0.01795196533203125\n",
      "#Finished reading and transforming Line 3 with Time taken = 0.014564990997314453\n",
      "#Finished reading and transforming Line 4 with Time taken = 0.015988826751708984\n",
      "#Finished reading and transforming Line 5 with Time taken = 0.016988515853881836\n",
      "#Finished reading and transforming Line 6 with Time taken = 0.015996217727661133\n",
      "#Finished reading and transforming Line 7 with Time taken = 0.015988826751708984\n",
      "#Finished reading and transforming Line 8 with Time taken = 0.015990257263183594\n",
      "#Finished reading and transforming Line 9 with Time taken = 0.015990495681762695\n",
      "#Finished reading and transforming Line 10 with Time taken = 0.015990018844604492\n",
      "#Finished reading and transforming Line 11 with Time taken = 0.017111539840698242\n",
      "#Finished reading and transforming Line 12 with Time taken = 0.01698756217956543\n",
      "#Finished reading and transforming Line 13 with Time taken = 0.01695394515991211\n",
      "#Finished reading and transforming Line 14 with Time taken = 0.016953229904174805\n",
      "#Finished reading and transforming Line 15 with Time taken = 0.015923261642456055\n",
      "#Finished reading and transforming Line 16 with Time taken = 0.017990827560424805\n",
      "#Finished reading and transforming Line 17 with Time taken = 0.01676034927368164\n",
      "#Finished reading and transforming Line 18 with Time taken = 0.016324996948242188\n",
      "#Finished reading and transforming Line 19 with Time taken = 0.01695537567138672\n",
      "#Finished reading and transforming Line 20 with Time taken = 0.01595783233642578\n",
      "#Finished reading and transforming Line 21 with Time taken = 0.01598978042602539\n",
      "#Finished reading and transforming Line 22 with Time taken = 0.01598072052001953\n",
      "#Finished reading and transforming Line 23 with Time taken = 0.01697397232055664\n",
      "#Finished reading and transforming Line 24 with Time taken = 0.015990495681762695\n",
      "#Finished reading and transforming Line 25 with Time taken = 0.016954421997070312\n",
      "#Finished reading and transforming Line 26 with Time taken = 0.015988588333129883\n",
      "#Finished reading and transforming Line 27 with Time taken = 0.015990257263183594\n",
      "#Finished reading and transforming Line 28 with Time taken = 0.01695990562438965\n",
      "#Finished reading and transforming Line 29 with Time taken = 0.0169527530670166\n",
      "#Finished reading and transforming Line 30 with Time taken = 0.01598834991455078\n",
      "#Finished reading and transforming Line 31 with Time taken = 0.016985654830932617\n",
      "#Finished reading and transforming Line 32 with Time taken = 0.015924453735351562\n",
      "#Finished reading and transforming Line 33 with Time taken = 0.01595783233642578\n",
      "#Finished reading and transforming Line 34 with Time taken = 0.0159299373626709\n",
      "#Finished reading and transforming Line 35 with Time taken = 0.028915882110595703\n",
      "#Finished reading and transforming Line 36 with Time taken = 0.015964984893798828\n",
      "#Finished reading and transforming Line 37 with Time taken = 0.017951250076293945\n",
      "#Finished reading and transforming Line 38 with Time taken = 0.029889345169067383\n",
      "#Finished reading and transforming Line 39 with Time taken = 0.016951799392700195\n",
      "#Finished reading and transforming Line 40 with Time taken = 0.016922950744628906\n",
      "#Finished reading and transforming Line 41 with Time taken = 0.016954660415649414\n",
      "#Finished reading and transforming Line 42 with Time taken = 0.01596832275390625\n",
      "#Finished reading and transforming Line 43 with Time taken = 0.01596212387084961\n",
      "#Finished reading and transforming Line 44 with Time taken = 0.01695537567138672\n",
      "#Finished reading and transforming Line 45 with Time taken = 0.017951011657714844\n",
      "#Finished reading and transforming Line 46 with Time taken = 0.01795196533203125\n",
      "#Finished reading and transforming Line 47 with Time taken = 0.01894855499267578\n",
      "#Finished reading and transforming Line 48 with Time taken = 0.019945859909057617\n",
      "#Finished reading and transforming Line 49 with Time taken = 0.018950462341308594\n",
      "#Finished reading and transforming Line 50 with Time taken = 0.018967628479003906\n",
      "#Finished reading and transforming Line 51 with Time taken = 0.018078327178955078\n",
      "#Finished reading and transforming Line 52 with Time taken = 0.01595616340637207\n",
      "#Finished reading and transforming Line 53 with Time taken = 0.015957117080688477\n",
      "#Finished reading and transforming Line 54 with Time taken = 0.015957117080688477\n",
      "#Finished reading and transforming Line 55 with Time taken = 0.015957117080688477\n",
      "#Finished reading and transforming Line 56 with Time taken = 0.01946258544921875\n",
      "#Finished reading and transforming Line 57 with Time taken = 0.017630577087402344\n",
      "#Finished reading and transforming Line 58 with Time taken = 0.015989065170288086\n",
      "#Finished reading and transforming Line 59 with Time taken = 0.017062902450561523\n",
      "#Finished reading and transforming Line 60 with Time taken = 0.015982866287231445\n",
      "#Finished reading and transforming Line 61 with Time taken = 0.01596212387084961\n",
      "#Finished reading and transforming Line 62 with Time taken = 0.015958070755004883\n",
      "#Finished reading and transforming Line 63 with Time taken = 0.015957355499267578\n",
      "#Finished reading and transforming Line 64 with Time taken = 0.01596689224243164\n",
      "#Finished reading and transforming Line 65 with Time taken = 0.016988277435302734\n",
      "#Finished reading and transforming Line 66 with Time taken = 0.01695394515991211\n",
      "#Finished reading and transforming Line 67 with Time taken = 0.01596355438232422\n",
      "#Finished reading and transforming Line 68 with Time taken = 0.016931533813476562\n",
      "#Finished reading and transforming Line 69 with Time taken = 0.016989707946777344\n",
      "#Finished reading and transforming Line 70 with Time taken = 0.015957355499267578\n",
      "#Finished reading and transforming Line 71 with Time taken = 0.017130136489868164\n",
      "#Finished reading and transforming Line 72 with Time taken = 0.01711273193359375\n",
      "#Finished reading and transforming Line 73 with Time taken = 0.01695394515991211\n",
      "#Finished reading and transforming Line 74 with Time taken = 0.016957521438598633\n",
      "#Finished reading and transforming Line 75 with Time taken = 0.01695418357849121\n",
      "#Finished reading and transforming Line 76 with Time taken = 0.016988515853881836\n",
      "#Finished reading and transforming Line 77 with Time taken = 0.015990495681762695\n",
      "#Finished reading and transforming Line 78 with Time taken = 0.01595616340637207\n",
      "#Finished reading and transforming Line 79 with Time taken = 0.01696300506591797\n",
      "#Finished reading and transforming Line 80 with Time taken = 0.016945600509643555\n",
      "#Finished reading and transforming Line 81 with Time taken = 0.016987085342407227\n",
      "#Finished reading and transforming Line 82 with Time taken = 0.018917083740234375\n",
      "#Finished reading and transforming Line 83 with Time taken = 0.016987323760986328\n",
      "#Finished reading and transforming Line 84 with Time taken = 0.016958236694335938\n",
      "#Finished reading and transforming Line 85 with Time taken = 0.016986846923828125\n",
      "#Finished reading and transforming Line 86 with Time taken = 0.01595759391784668\n",
      "#Finished reading and transforming Line 87 with Time taken = 0.016986846923828125\n",
      "#Finished reading and transforming Line 88 with Time taken = 0.016955852508544922\n",
      "#Finished reading and transforming Line 89 with Time taken = 0.016954421997070312\n",
      "#Finished reading and transforming Line 90 with Time taken = 0.015924930572509766\n",
      "#Finished reading and transforming Line 91 with Time taken = 0.015990495681762695\n",
      "#Finished reading and transforming Line 92 with Time taken = 0.017939329147338867\n",
      "#Finished reading and transforming Line 93 with Time taken = 0.01596999168395996\n",
      "#Finished reading and transforming Line 94 with Time taken = 0.0159912109375\n",
      "#Finished reading and transforming Line 95 with Time taken = 0.016969919204711914\n",
      "#Finished reading and transforming Line 96 with Time taken = 0.01703810691833496\n",
      "#Finished reading and transforming Line 97 with Time taken = 0.016986608505249023\n",
      "#Finished reading and transforming Line 98 with Time taken = 0.0169217586517334\n",
      "#Finished reading and transforming Line 99 with Time taken = 0.01621389389038086\n",
      "##Fin.##\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "readWriteTransform(basePath+\"W3.txt\", basePath+\"W3var.txt\", (10, 500), precision, step, discreteSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished reading and transforming Line 0 with Time taken = 0.0030202865600585938\n",
      "#Finished reading and transforming Line 1 with Time taken = 0.000972747802734375\n",
      "#Finished reading and transforming Line 2 with Time taken = 0.0029821395874023438\n",
      "#Finished reading and transforming Line 3 with Time taken = 0.001007080078125\n",
      "#Finished reading and transforming Line 4 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 5 with Time taken = 0.0009875297546386719\n",
      "#Finished reading and transforming Line 6 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 7 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 8 with Time taken = 0.0009999275207519531\n",
      "#Finished reading and transforming Line 9 with Time taken = 0.002999544143676758\n",
      "#Finished reading and transforming Line 10 with Time taken = 0.000988006591796875\n",
      "#Finished reading and transforming Line 11 with Time taken = 0.0010001659393310547\n",
      "#Finished reading and transforming Line 12 with Time taken = 0.0010004043579101562\n",
      "#Finished reading and transforming Line 13 with Time taken = 0.0009887218475341797\n",
      "#Finished reading and transforming Line 14 with Time taken = 0.0010030269622802734\n",
      "#Finished reading and transforming Line 15 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 16 with Time taken = 0.0009946823120117188\n",
      "#Finished reading and transforming Line 17 with Time taken = 0.0010001659393310547\n",
      "#Finished reading and transforming Line 18 with Time taken = 0.0010051727294921875\n",
      "#Finished reading and transforming Line 19 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 20 with Time taken = 0.0009856224060058594\n",
      "#Finished reading and transforming Line 21 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 22 with Time taken = 0.0009965896606445312\n",
      "#Finished reading and transforming Line 23 with Time taken = 0.0009963512420654297\n",
      "#Finished reading and transforming Line 24 with Time taken = 0.0010018348693847656\n",
      "#Finished reading and transforming Line 25 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 26 with Time taken = 0.000993967056274414\n",
      "#Finished reading and transforming Line 27 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 28 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 29 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 30 with Time taken = 0.0009975433349609375\n",
      "#Finished reading and transforming Line 31 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 32 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 33 with Time taken = 0.0009975433349609375\n",
      "#Finished reading and transforming Line 34 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 35 with Time taken = 0.0009963512420654297\n",
      "#Finished reading and transforming Line 36 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 37 with Time taken = 0.0009753704071044922\n",
      "#Finished reading and transforming Line 38 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 39 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 40 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 41 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 42 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 43 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 44 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 45 with Time taken = 0.000997781753540039\n",
      "#Finished reading and transforming Line 46 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 47 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 48 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 49 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 50 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 51 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 52 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 53 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 54 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 55 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 56 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 57 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 58 with Time taken = 0.0009980201721191406\n",
      "#Finished reading and transforming Line 59 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 60 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 61 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 62 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 63 with Time taken = 0.000997781753540039\n",
      "#Finished reading and transforming Line 64 with Time taken = 0.0010004043579101562\n",
      "#Finished reading and transforming Line 65 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 66 with Time taken = 0.000993967056274414\n",
      "#Finished reading and transforming Line 67 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 68 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 69 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 70 with Time taken = 0.0010199546813964844\n",
      "#Finished reading and transforming Line 71 with Time taken = 0.0009751319885253906\n",
      "#Finished reading and transforming Line 72 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 73 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 74 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 75 with Time taken = 0.000997781753540039\n",
      "#Finished reading and transforming Line 76 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 77 with Time taken = 0.0009980201721191406\n",
      "#Finished reading and transforming Line 78 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 79 with Time taken = 0.0009963512420654297\n",
      "#Finished reading and transforming Line 80 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 81 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 82 with Time taken = 0.000978708267211914\n",
      "#Finished reading and transforming Line 83 with Time taken = 0.0009922981262207031\n",
      "#Finished reading and transforming Line 84 with Time taken = 0.0009963512420654297\n",
      "#Finished reading and transforming Line 85 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 86 with Time taken = 0.0009965896606445312\n",
      "#Finished reading and transforming Line 87 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 88 with Time taken = 0.0009963512420654297\n",
      "#Finished reading and transforming Line 89 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 90 with Time taken = 0.001001119613647461\n",
      "#Finished reading and transforming Line 91 with Time taken = 0.0009970664978027344\n",
      "#Finished reading and transforming Line 92 with Time taken = 0.0009968280792236328\n",
      "#Finished reading and transforming Line 93 with Time taken = 0.0009989738464355469\n",
      "#Finished reading and transforming Line 94 with Time taken = 0.0009951591491699219\n",
      "#Finished reading and transforming Line 95 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 96 with Time taken = 0.0009949207305908203\n",
      "#Finished reading and transforming Line 97 with Time taken = 0.0\n",
      "#Finished reading and transforming Line 98 with Time taken = 0.000997304916381836\n",
      "#Finished reading and transforming Line 99 with Time taken = 0.0010149478912353516\n",
      "##Fin.##\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "readWriteTransform(basePath+\"b3.txt\", basePath+\"b3var.txt\", (10, 1), precision, step, discreteSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On-chip Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Train accuracy: 8.542857142857143\n",
      "Val accuracy: 8.528571428571428\n",
      "Iteration 2\n",
      "Train accuracy: 53.29047619047619\n",
      "Val accuracy: 55.114285714285714\n",
      "Iteration 3\n",
      "Train accuracy: 54.549206349206344\n",
      "Val accuracy: 54.114285714285714\n",
      "Iteration 4\n",
      "Train accuracy: 53.333333333333336\n",
      "Val accuracy: 52.5\n",
      "Iteration 5\n",
      "Train accuracy: 64.12063492063493\n",
      "Val accuracy: 63.47142857142857\n",
      "Iteration 6\n",
      "Train accuracy: 67.57460317460317\n",
      "Val accuracy: 67.32857142857142\n",
      "Iteration 7\n",
      "Train accuracy: 67.78253968253968\n",
      "Val accuracy: 67.24285714285713\n",
      "Iteration 8\n",
      "Train accuracy: 62.26825396825397\n",
      "Val accuracy: 62.08571428571429\n",
      "Iteration 9\n",
      "Train accuracy: 66.60317460317461\n",
      "Val accuracy: 65.91428571428571\n",
      "Iteration 10\n",
      "Train accuracy: 61.58095238095238\n",
      "Val accuracy: 60.75714285714285\n",
      "Iteration 11\n",
      "Train accuracy: 61.7031746031746\n",
      "Val accuracy: 61.17142857142858\n",
      "Iteration 12\n",
      "Train accuracy: 58.8015873015873\n",
      "Val accuracy: 59.15714285714285\n",
      "Iteration 13\n",
      "Train accuracy: 59.12698412698413\n",
      "Val accuracy: 59.24285714285714\n",
      "Iteration 14\n",
      "Train accuracy: 50.680952380952384\n",
      "Val accuracy: 50.228571428571435\n",
      "Iteration 15\n",
      "Train accuracy: 58.51746031746031\n",
      "Val accuracy: 58.871428571428574\n",
      "Iteration 16\n",
      "Train accuracy: 66.65555555555555\n",
      "Val accuracy: 65.84285714285714\n",
      "Iteration 17\n",
      "Train accuracy: 69.9936507936508\n",
      "Val accuracy: 70.47142857142858\n",
      "Iteration 18\n",
      "Train accuracy: 61.412698412698404\n",
      "Val accuracy: 60.98571428571429\n",
      "Iteration 19\n",
      "Train accuracy: 66.5904761904762\n",
      "Val accuracy: 66.3\n",
      "Iteration 20\n",
      "Train accuracy: 60.17777777777778\n",
      "Val accuracy: 59.91428571428571\n",
      "Iteration 21\n",
      "Train accuracy: 65.83650793650794\n",
      "Val accuracy: 65.12857142857142\n",
      "Iteration 22\n",
      "Train accuracy: 69.54920634920634\n",
      "Val accuracy: 69.72857142857143\n",
      "Iteration 23\n",
      "Train accuracy: 66.57619047619048\n",
      "Val accuracy: 66.25714285714285\n",
      "Iteration 24\n",
      "Train accuracy: 54.547619047619044\n",
      "Val accuracy: 54.48571428571428\n",
      "Iteration 25\n",
      "Train accuracy: 54.91111111111111\n",
      "Val accuracy: 55.54285714285714\n",
      "Iteration 26\n",
      "Train accuracy: 56.304761904761904\n",
      "Val accuracy: 55.48571428571428\n",
      "Iteration 27\n",
      "Train accuracy: 68.61428571428571\n",
      "Val accuracy: 68.41428571428571\n",
      "Iteration 28\n",
      "Train accuracy: 52.92539682539682\n",
      "Val accuracy: 53.214285714285715\n",
      "Iteration 29\n",
      "Train accuracy: 64.5095238095238\n",
      "Val accuracy: 63.98571428571429\n",
      "Iteration 30\n",
      "Train accuracy: 66.84920634920634\n",
      "Val accuracy: 66.22857142857143\n",
      "Iteration 31\n",
      "Train accuracy: 61.142857142857146\n",
      "Val accuracy: 61.18571428571429\n",
      "Iteration 32\n",
      "Train accuracy: 61.512698412698406\n",
      "Val accuracy: 60.871428571428574\n",
      "Iteration 33\n",
      "Train accuracy: 73.06190476190476\n",
      "Val accuracy: 72.67142857142858\n",
      "Iteration 34\n",
      "Train accuracy: 59.87777777777777\n",
      "Val accuracy: 58.4\n",
      "Iteration 35\n",
      "Train accuracy: 59.41904761904762\n",
      "Val accuracy: 59.08571428571429\n",
      "Iteration 36\n",
      "Train accuracy: 64.83492063492064\n",
      "Val accuracy: 64.38571428571429\n",
      "Iteration 37\n",
      "Train accuracy: 58.903174603174605\n",
      "Val accuracy: 57.8\n",
      "Iteration 38\n",
      "Train accuracy: 62.669841269841264\n",
      "Val accuracy: 62.7\n",
      "Iteration 39\n",
      "Train accuracy: 56.006349206349206\n",
      "Val accuracy: 55.60000000000001\n",
      "Iteration 40\n",
      "Train accuracy: 62.717460317460315\n",
      "Val accuracy: 62.142857142857146\n",
      "Iteration 41\n",
      "Train accuracy: 72.55714285714285\n",
      "Val accuracy: 71.84285714285714\n",
      "Iteration 42\n",
      "Train accuracy: 54.77619047619048\n",
      "Val accuracy: 54.400000000000006\n",
      "Iteration 43\n",
      "Train accuracy: 65.95873015873016\n",
      "Val accuracy: 64.91428571428571\n",
      "Iteration 44\n",
      "Train accuracy: 64.12698412698413\n",
      "Val accuracy: 63.97142857142857\n",
      "Iteration 45\n",
      "Train accuracy: 63.82063492063492\n",
      "Val accuracy: 62.642857142857146\n",
      "Iteration 46\n",
      "Train accuracy: 70.6968253968254\n",
      "Val accuracy: 69.45714285714286\n",
      "Iteration 47\n",
      "Train accuracy: 64.14603174603175\n",
      "Val accuracy: 64.67142857142856\n",
      "Iteration 48\n",
      "Train accuracy: 57.815873015873024\n",
      "Val accuracy: 56.942857142857136\n",
      "Iteration 49\n",
      "Train accuracy: 58.30793650793651\n",
      "Val accuracy: 57.657142857142865\n",
      "Iteration 50\n",
      "Train accuracy: 61.05555555555555\n",
      "Val accuracy: 59.51428571428572\n",
      "Iteration 51\n",
      "Train accuracy: 61.59206349206349\n",
      "Val accuracy: 60.32857142857143\n",
      "Iteration 52\n",
      "Train accuracy: 65.93968253968254\n",
      "Val accuracy: 65.0\n",
      "Iteration 53\n",
      "Train accuracy: 62.84603174603175\n",
      "Val accuracy: 62.8\n",
      "Iteration 54\n",
      "Train accuracy: 51.05873015873016\n",
      "Val accuracy: 51.457142857142856\n",
      "Iteration 55\n",
      "Train accuracy: 49.37460317460317\n",
      "Val accuracy: 49.528571428571425\n",
      "Iteration 56\n",
      "Train accuracy: 52.714285714285715\n",
      "Val accuracy: 51.857142857142854\n",
      "Iteration 57\n",
      "Train accuracy: 45.51111111111111\n",
      "Val accuracy: 45.6\n",
      "Iteration 58\n",
      "Train accuracy: 50.38888888888889\n",
      "Val accuracy: 50.357142857142854\n",
      "Iteration 59\n",
      "Train accuracy: 74.32222222222222\n",
      "Val accuracy: 73.71428571428571\n",
      "Iteration 60\n",
      "Train accuracy: 65.17460317460318\n",
      "Val accuracy: 65.17142857142856\n",
      "Iteration 61\n",
      "Train accuracy: 67.57142857142857\n",
      "Val accuracy: 67.02857142857142\n",
      "Iteration 62\n",
      "Train accuracy: 51.409523809523805\n",
      "Val accuracy: 50.78571428571429\n",
      "Iteration 63\n",
      "Train accuracy: 54.52380952380952\n",
      "Val accuracy: 54.15714285714286\n",
      "Iteration 64\n",
      "Train accuracy: 57.87936507936507\n",
      "Val accuracy: 58.31428571428572\n",
      "Iteration 65\n",
      "Train accuracy: 40.85079365079365\n",
      "Val accuracy: 40.2\n",
      "Iteration 66\n",
      "Train accuracy: 64.81746031746032\n",
      "Val accuracy: 64.74285714285715\n",
      "Iteration 67\n",
      "Train accuracy: 62.771428571428565\n",
      "Val accuracy: 62.08571428571429\n",
      "Iteration 68\n",
      "Train accuracy: 64.66507936507936\n",
      "Val accuracy: 63.25714285714285\n",
      "Iteration 69\n",
      "Train accuracy: 61.08412698412698\n",
      "Val accuracy: 60.385714285714286\n",
      "Iteration 70\n",
      "Train accuracy: 58.198412698412696\n",
      "Val accuracy: 57.52857142857143\n",
      "Iteration 71\n",
      "Train accuracy: 64.52222222222223\n",
      "Val accuracy: 64.17142857142856\n",
      "Iteration 72\n",
      "Train accuracy: 55.06984126984127\n",
      "Val accuracy: 54.42857142857142\n",
      "Iteration 73\n",
      "Train accuracy: 60.04761904761905\n",
      "Val accuracy: 59.099999999999994\n",
      "Iteration 74\n",
      "Train accuracy: 60.8\n",
      "Val accuracy: 60.42857142857143\n",
      "Iteration 75\n",
      "Train accuracy: 68.16349206349206\n",
      "Val accuracy: 66.44285714285715\n",
      "Iteration 76\n",
      "Train accuracy: 68.48253968253968\n",
      "Val accuracy: 66.60000000000001\n",
      "Iteration 77\n",
      "Train accuracy: 63.29365079365079\n",
      "Val accuracy: 62.271428571428565\n",
      "Iteration 78\n",
      "Train accuracy: 64.95555555555555\n",
      "Val accuracy: 64.8\n",
      "Iteration 79\n",
      "Train accuracy: 67.48571428571428\n",
      "Val accuracy: 67.42857142857143\n",
      "Iteration 80\n",
      "Train accuracy: 50.596825396825395\n",
      "Val accuracy: 50.171428571428564\n",
      "Iteration 81\n",
      "Train accuracy: 58.219047619047615\n",
      "Val accuracy: 57.971428571428575\n",
      "Iteration 82\n",
      "Train accuracy: 59.58095238095238\n",
      "Val accuracy: 58.57142857142858\n",
      "Iteration 83\n",
      "Train accuracy: 67.32857142857142\n",
      "Val accuracy: 65.18571428571428\n",
      "Iteration 84\n",
      "Train accuracy: 69.56031746031745\n",
      "Val accuracy: 69.0\n",
      "Iteration 85\n",
      "Train accuracy: 53.27619047619048\n",
      "Val accuracy: 52.08571428571429\n",
      "Iteration 86\n",
      "Train accuracy: 41.614285714285714\n",
      "Val accuracy: 40.18571428571428\n",
      "Iteration 87\n",
      "Train accuracy: 61.28888888888889\n",
      "Val accuracy: 60.57142857142858\n",
      "Iteration 88\n",
      "Train accuracy: 54.55079365079365\n",
      "Val accuracy: 54.842857142857135\n",
      "Iteration 89\n",
      "Train accuracy: 49.15873015873016\n",
      "Val accuracy: 49.1\n",
      "Iteration 90\n",
      "Train accuracy: 51.234920634920634\n",
      "Val accuracy: 51.214285714285715\n",
      "Iteration 91\n",
      "Train accuracy: 61.65873015873016\n",
      "Val accuracy: 60.785714285714285\n",
      "Iteration 92\n",
      "Train accuracy: 64.71587301587302\n",
      "Val accuracy: 63.957142857142856\n",
      "Iteration 93\n",
      "Train accuracy: 65.85555555555555\n",
      "Val accuracy: 65.58571428571427\n",
      "Iteration 94\n",
      "Train accuracy: 62.955555555555556\n",
      "Val accuracy: 63.7\n",
      "Iteration 95\n",
      "Train accuracy: 67.93333333333334\n",
      "Val accuracy: 67.27142857142857\n",
      "Iteration 96\n",
      "Train accuracy: 65.7984126984127\n",
      "Val accuracy: 66.01428571428572\n",
      "Iteration 97\n",
      "Train accuracy: 64.55079365079365\n",
      "Val accuracy: 64.9857142857143\n",
      "Iteration 98\n",
      "Train accuracy: 61.43492063492063\n",
      "Val accuracy: 60.17142857142858\n",
      "Iteration 99\n",
      "Train accuracy: 58.38095238095238\n",
      "Val accuracy: 57.57142857142858\n",
      "Iteration 100\n",
      "Train accuracy: 60.14285714285714\n",
      "Val accuracy: 58.82857142857143\n"
     ]
    }
   ],
   "source": [
    "basePath = \"D:\\\\perturbation_on_chip_learning\\\\Perturbation-techniques-in-CNNs\\\\weights\\\\\"\n",
    "fileW1var = open(basePath+\"W1var.txt\", 'r')\n",
    "fileb1var = open(basePath+\"b1var.txt\", 'r')\n",
    "fileW2var = open(basePath+\"W2var.txt\", 'r')\n",
    "fileb2var = open(basePath+\"b2var.txt\", 'r')\n",
    "fileW3var = open(basePath+\"W3var.txt\", 'r')\n",
    "fileb3var = open(basePath+\"b3var.txt\", 'r')\n",
    "trainAccOnChip = []\n",
    "valAccOnChip = []\n",
    "iter = 1\n",
    "X, Y = x_train,y_train\n",
    "for line in zip(fileW1var, fileb1var, fileW2var, fileb2var, fileW3var, fileb3var):\n",
    "    W1, b1, W2, b2, W3, b3 = line\n",
    "    W1 = loadFromLine(W1, (500, 784))\n",
    "    b1 = loadFromLine(b1, (500,1))\n",
    "    W2 = loadFromLine(W2, (500, 500))\n",
    "    b2 = loadFromLine(b2, (500,1))\n",
    "    W3 = loadFromLine(W3, (10, 500))\n",
    "    b3 = loadFromLine(b3, (10, 1))\n",
    "    #obtain training loss\n",
    "    print(\"Iteration {no}\".format(no = iter))\n",
    "    _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "    #for i in range(0, Y.shape[0]):\n",
    "    # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "    #train_loss.append(train_loss_score)\n",
    "    #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "    #obtain training accuracy\n",
    "    trainScore = accuracy(predictions(A3_train), Y)\n",
    "    trainAccOnChip.append(trainScore)\n",
    "    print(f'Train accuracy: {trainScore}')\n",
    "\n",
    "    ##obtain validation loss\n",
    "    _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "    #for i in range(0, y_val.shape[0]):\n",
    "    # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "    #val_loss.append(val_loss_score)\n",
    "    #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "    ##obtain validation accuracy\n",
    "    val_score = accuracy(predictions(A3_val), y_val)\n",
    "    valAccOnChip.append(val_score)\n",
    "    print(f'Val accuracy: {val_score}')\n",
    "    iter +=1\n",
    "fileW1var.close()\n",
    "fileb1var.close()\n",
    "fileW2var.close()\n",
    "fileb2var.close()\n",
    "fileW3var.close()\n",
    "fileb3var.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cf40d52740>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_acc, 'rx')\n",
    "plt.plot(trainAccOnChip, 'bo')\n",
    "plt.legend([\"Training accuracy (software)\", \"Training accuracy (on chip)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4846366729231954"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
