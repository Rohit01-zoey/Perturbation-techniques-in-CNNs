{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "#fetch the mnist dataset\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_n = x.to_numpy()\n",
    "x_n = x\n",
    "#y_n = y.to_numpy()\n",
    "y_n = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 784) (7000, 784) (63000,) (7000,)\n",
      "(784, 63000) (784, 7000)\n"
     ]
    }
   ],
   "source": [
    "y_n = y_n.astype('int') #convert output to integers 0-9\n",
    "x_norm = x_n/255.0 #normalise input data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_norm, y_n, test_size=0.1, random_state=42) #split the data into train and validation\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "x_train = x_train.T #take the transpose of the training data m*784 -> 784*m\n",
    "x_val = x_val.T #take the transpose of the test data m*784 -> 784*m\n",
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to change with different number of layers\n",
    "def params_init():\n",
    "\n",
    "  #np.random.seed(2)\n",
    "  W1 = np.random.rand(200,784) - 0.5\n",
    "  b1 = np.random.rand(200,1) - 0.5\n",
    "  W2 = np.random.rand(50,200) - 0.5\n",
    "  b2 = np.random.rand(50,1) - 0.5\n",
    "  W3 = np.random.rand(10,50) - 0.5 \n",
    "  b3 = np.random.rand(10,1) - 0.5\n",
    "  #W4 = np.random.rand(50,200) - 0.5   \n",
    "  #b4 = np.random.rand(50,1) - 0.5    \n",
    "  #W5 = np.random.rand(10,50) - 0.5  \n",
    "  #b5 = np.random.rand(10,1) - 0.5    \n",
    "  print(\"Params Initialised\")\n",
    "\n",
    "  return (W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def forward(x_train, W1, b1, W2, b2, W3, b3):\n",
    "  #print(\"Entered FP\")\n",
    "  Z1 = np.matmul(W1,x_train) + b1 #W1 is 50*784, x_train is 748*m, Z1 is 50*m\n",
    "  A1 = relu(Z1)\n",
    "\n",
    "  Z2 = np.matmul(W2,A1) + b2 \n",
    "  A2 = relu(Z2)\n",
    "\n",
    "  Z3 = np.matmul(W3,A2) + b3\n",
    "  A3 = softmax(Z3)\n",
    "  \n",
    "  #Z4 = np.matmul(W4,A3) + b4\n",
    "  #A4 = relu(Z4)\n",
    "\n",
    "  #Z5 = np.matmul(W5,A4) + b5\n",
    "  #A5 = softmax(Z5)\n",
    "\n",
    "  #W2 is 10*50, A1 is 50*m\n",
    "  # print(np.exp(Z2))\n",
    "  # print(np.sum(np.exp(Z2)))\n",
    "\n",
    "  #A2 is 10*m, final predictions\n",
    "  # print(\"Fp Done\")\n",
    "\n",
    "  return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "   return np.maximum(x,0)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "  #return np.exp(Z) / np.sum(np.exp(Z),0)\n",
    "  Z = Z-np.max(Z, axis=0)\n",
    "  return np.exp(Z) / np.sum(np.exp(Z),0)\n",
    "\n",
    "\n",
    "def relu_d(x):\n",
    "  return x>0\n",
    "\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "  shape = (y.shape[0], 10)\n",
    "  one_hot = np.zeros(shape)\n",
    "  rows = np.arange(y.size)\n",
    "  one_hot[rows, y] = 1\n",
    "  return one_hot.T\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, y):\n",
    "  # print(\"Entered Backprop\")\n",
    "  m = y.shape[0] #m is the number of training examples\n",
    "  Y = one_hot_encoding(y)\n",
    "\n",
    "  dZ3 = (A3 - Y)\n",
    "  \n",
    "  dW3 = 1/m*np.matmul(dZ3,A2.T)\n",
    "\n",
    "  db3 = 1/m*np.sum(dZ3, axis=1)\n",
    "\n",
    "  dZ2 = np.matmul(W3.T, dZ3)*relu_d(Z2) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db2 = 1/m*np.sum(dZ2, axis=1) #db1 is 50*1\n",
    "\n",
    "  dZ1 = np.matmul(W2.T, dZ2)*relu_d(Z1) #W2 is 10*50, dZ2 = 10*m, dZ1 = 50*m\n",
    "\n",
    "  dW1 = 1/m*np.matmul(dZ1,X.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db1 = 1/m*np.sum(dZ1, axis = 1) #db1 is 50*1\n",
    "\n",
    "\n",
    "  return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr):\n",
    "\n",
    "  #updates the parameters based on backpropogation\n",
    "\n",
    "  W1 = W1 - lr*dW1\n",
    "  b1 = b1 - lr*(db1.reshape(b1.shape))\n",
    "  W2 = W2 - lr*dW2\n",
    "  b2 = b2 - lr*(db2.reshape(b2.shape))\n",
    "  W3 = W3 - lr*dW3\n",
    "  b3 = b3 - lr*(db3.reshape(b3.shape))\n",
    "  #W4 = W4 - lr*dW4\n",
    "  #b4 = b4 - lr*db4\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "#have to change with different number of layers\n",
    "def batch_grad_descent(X,Y,iter, lr, print_op=1):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  weightsDict = {}\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "\n",
    "  weightsDict[\"W1\"] = W1\n",
    "  weightsDict[\"b1\"] = b1\n",
    "  weightsDict[\"W2\"] = W2\n",
    "  weightsDict[\"b2\"] = b2\n",
    "  weightsDict[\"W3\"] = W3\n",
    "  weightsDict[\"b3\"] = b3\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "      dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "\n",
    "      W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grad_descent(X,Y,iter, lr, print_op, decay_factor=0):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  mu = 1\n",
    "  sigma = 0.4\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "    X1, Y1 = X.T, Y\n",
    "    X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "    Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "\n",
    "    dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr, factor = decay_factor)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'Iteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "def NP(pert, lossBeforePert, Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, b1, b2, b3, X1, Y1):\n",
    "  #calculating dw3 and db3\n",
    "  #first approximate dZ3\n",
    "  m = Z3.shape[1]\n",
    "  lossArrayAfterPertZ3 = np.zeros_like(Z3)\n",
    "  for i in range(Z3.shape[0]):\n",
    "    Z3pert = Z3.copy() #creates a local copy of the array since python arrays are sent by reference andnot copy!!\n",
    "    Z3pert[i] +=  pert\n",
    "    A3pert = softmax(Z3pert)\n",
    "    #print(\"Z3\")\n",
    "    lossArrayAfterPertZ3[i] = np.sum((A3pert-one_hot_encoding(Y1))**2, axis=0)\n",
    "\n",
    "  \n",
    "  dZ3 = (lossArrayAfterPertZ3 - lossBeforePert)/pert\n",
    "  \n",
    "  dW3 = 1/m*np.matmul(dZ3,A2.T)\n",
    "\n",
    "  db3 = 1/m*np.sum(dZ3, axis=1)\n",
    "\n",
    "\n",
    "  #calculating the dZ2 and db2\n",
    "\n",
    "  lossArrayAfterPertZ2 = np.zeros_like(Z2)\n",
    "\n",
    "  for i in range(Z2.shape[0]):\n",
    "    Z2pert = Z2.copy()\n",
    "    Z2pert[i] += pert\n",
    "\n",
    "    A2pert = relu(Z2pert)\n",
    "\n",
    "    Z3pert = np.matmul(W3,A2pert) + b3\n",
    "    A3pert = softmax(Z3pert)\n",
    "    #print(\"Z2\")\n",
    "    lossArrayAfterPertZ2[i] = np.sum((A3pert-one_hot_encoding(Y1))**2, axis=0)\n",
    "\n",
    "  \n",
    "  dZ2 = (lossArrayAfterPertZ2 - lossBeforePert)/pert\n",
    "\n",
    "  dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db2 = 1/m*np.sum(dZ2, axis=1) #db1 is 50*1\n",
    "\n",
    "  #calculating the dZ1 and db1\n",
    "  lossArrayAfterPertZ1 = np.zeros_like(Z1)\n",
    "  for i in range(Z1.shape[0]):\n",
    "    Z1pert = Z1.copy()\n",
    "    Z1pert[i] += pert\n",
    "\n",
    "    A1pert = relu(Z1pert)\n",
    "\n",
    "    Z2pert = np.matmul(W2,A1pert) + b2 \n",
    "    A2pert = relu(Z2pert)\n",
    "\n",
    "    Z3pert = np.matmul(W3,A2pert) + b3\n",
    "    A3pert = softmax(Z3pert)\n",
    "    #print(\"Z1\")\n",
    "    #print(f\"sub sub in iter{i}\")\n",
    "\n",
    "    lossArrayAfterPertZ1[i] = np.sum((A3pert-one_hot_encoding(Y1))**2, axis=0)\n",
    "\n",
    "  dZ1 = (lossArrayAfterPertZ1 - lossBeforePert)/pert\n",
    "\n",
    "  dW1 = 1/m*np.matmul(dZ1,X1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "  db1 = 1/m*np.sum(dZ1, axis = 1) #db1 is 50*1\n",
    "\n",
    "  return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "\n",
    "def batchGDNP(X,Y,iter, lr, pert, print_op=1):\n",
    "\n",
    "  # print(\"Entered Grad Descent\")\n",
    "  #performs minibatch grad descent for given iterations and learning rate\n",
    "  n = Y.shape[0]\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  sum_weights = []\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  weightsDict = {}\n",
    "\n",
    "  W1, b1, W2, b2, W3, b3 = params_init()\n",
    "  #print(W1)\n",
    "  #gaussian_W1, gaussian_b1, gaussian_W2, gaussian_b2, gaussian_W3, gaussian_b3, gaussian_W4, gaussian_b4, gaussian_W5, gaussian_b5 = Gaussian_init (mu, sigma)\n",
    "\n",
    "\n",
    "\n",
    "  weightsDict[\"W1\"] = W1\n",
    "  weightsDict[\"b1\"] = b1\n",
    "  weightsDict[\"W2\"] = W2\n",
    "  weightsDict[\"b2\"] = b2\n",
    "  weightsDict[\"W3\"] = W3\n",
    "  weightsDict[\"b3\"] = b3\n",
    "\n",
    "  for i in range(iter): #loop over \n",
    "    train_loss_score = 0\n",
    "    val_loss_score = 0\n",
    "\n",
    "\n",
    "    for j in range(100): #loop over batches\n",
    "      # print(\"Entered for loops in grad descent\")\n",
    "      #total training samples = 63000, batch size = 630\n",
    "      X1, Y1 = shuffle(X[:, j*630: (j+1)*630].T,Y[j*630: (j+1)*630]) #shuffle each batch\n",
    "      X1 = X1.T #take transpose to match the sizes\n",
    "\n",
    "      Z1, A1, Z2, A2, Z3, A3 = forward(X1, W1, b1, W2, b2, W3, b3) \n",
    "      print(f\"Iter {i} -> sub iter {j} : {accuracy(predictions(A3), Y1)}\", end = \"\\r\", flush = True)\n",
    "      lossBeforePert = np.sum((A3-one_hot_encoding(Y1))**2, axis=0)\n",
    "\n",
    "      #print(f\"Main iter: {i} Sub iter : {j}\\n\")\n",
    "      #dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\n",
    "      dW1, db1, dW2, db2, dW3, db3 = NP(pert, lossBeforePert, Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, b1, b2, b3, X1, Y1)\n",
    "      #print(f\"iter in iter{j}\")\n",
    "      W1, b1, W2, b2, W3, b3 = param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr = lr)\n",
    "      #print(W1)\n",
    "\n",
    "    if (i+1)%(print_op) == 0:\n",
    "      print(f'\\nIteration: {i + 1}')\n",
    "\n",
    "      #obtain training loss\n",
    "      _, _, _, _, _, A3_train = forward(X, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, Y.shape[0]):\n",
    "       # train_loss_score = train_loss_score + (-1*(np.log(A5_train[Y[i], i])))\n",
    "      #train_loss.append(train_loss_score)\n",
    "      #print(f'Train Loss: {train_loss_score}')\n",
    "\n",
    "      #obtain training accuracy\n",
    "      train_score = accuracy(predictions(A3_train), Y)\n",
    "      train_acc.append(train_score)\n",
    "      print(f'Train accuracy: {train_score}')\n",
    "\n",
    "      ##obtain validation loss\n",
    "      _, _, _, _, _,  A3_val = forward(x_val, W1, b1, W2, b2, W3, b3)\n",
    "      #for i in range(0, y_val.shape[0]):\n",
    "       # val_loss_score = val_loss_score + (-1*(np.log(A5_val[y_val[i], i]))) \n",
    "      #val_loss.append(val_loss_score)\n",
    "      #print(f'Validation Loss: {val_loss_score}')\n",
    "\n",
    "      ##obtain validation accuracy\n",
    "      val_score = accuracy(predictions(A3_val), y_val)\n",
    "      val_acc.append(val_score)\n",
    "      print(f'Val accuracy: {val_score}')\n",
    "\n",
    "      #obtain the sum of weights and append to the sum array\n",
    "      #sum_w = np.sum(abs(W1)) + np.sum(abs(W2)) + np.sum(abs(W3)) + np.sum(abs(W4)) + np.sum(abs(W5)) + np.sum(abs(b1)) + np.sum(abs(b2)) + np.sum(abs(b3))  + np.sum(abs(b4)) + np.sum(abs(b5))\n",
    "      #sum_weights.append(sum_w)\n",
    "      #print(f'Sum of weights: {sum_w}')\n",
    "\n",
    "  return W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predictions(A):\n",
    "  #argmax returns the index of maximum value, we will feed the sigmoid output to this function \n",
    "  return np.argmax(A,0)\n",
    "\n",
    "\n",
    "def accuracy(A,Y):\n",
    "  #this will compare the predicted output to the ground truth\n",
    "  return np.sum(A == Y)/(Y.shape[0])*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochsToTrain = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pertList = [1,0.1, 0.01, 0.001, 0.0001]\n",
    "trainAccPertList = []\n",
    "valAccPertList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iter 0 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 1\n",
      "Train accuracy: 56.5968253968254\n",
      "Val accuracy: 56.04285714285714\n",
      "Iter 1 -> sub iter 99 : 75.714285714285714\n",
      "Iteration: 2\n",
      "Train accuracy: 74.18730158730159\n",
      "Val accuracy: 73.8\n",
      "Iter 2 -> sub iter 99 : 80.47619047619048\n",
      "Iteration: 3\n",
      "Train accuracy: 79.83015873015873\n",
      "Val accuracy: 79.87142857142857\n",
      "Iter 3 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 4\n",
      "Train accuracy: 82.66984126984127\n",
      "Val accuracy: 82.72857142857143\n",
      "Iter 4 -> sub iter 99 : 85.23809523809524\n",
      "Iteration: 5\n",
      "Train accuracy: 84.46825396825398\n",
      "Val accuracy: 84.34285714285714\n",
      "Iter 5 -> sub iter 99 : 86.82539682539682\n",
      "Iteration: 6\n",
      "Train accuracy: 85.73015873015873\n",
      "Val accuracy: 85.62857142857143\n",
      "Iter 6 -> sub iter 99 : 86.98412698412699\n",
      "Iteration: 7\n",
      "Train accuracy: 86.78730158730158\n",
      "Val accuracy: 86.77142857142857\n",
      "Iter 7 -> sub iter 99 : 87.46031746031746\n",
      "Iteration: 8\n",
      "Train accuracy: 87.55714285714285\n",
      "Val accuracy: 87.61428571428571\n",
      "Iter 8 -> sub iter 99 : 88.41269841269843\n",
      "Iteration: 9\n",
      "Train accuracy: 88.27301587301586\n",
      "Val accuracy: 88.22857142857143\n",
      "Iter 9 -> sub iter 99 : 88.88888888888889\n",
      "Iteration: 10\n",
      "Train accuracy: 88.78412698412698\n",
      "Val accuracy: 88.85714285714286\n",
      "Iter 10 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 11\n",
      "Train accuracy: 89.15873015873017\n",
      "Val accuracy: 89.15714285714286\n",
      "Iter 11 -> sub iter 99 : 88.88888888888889\n",
      "Iteration: 12\n",
      "Train accuracy: 89.50317460317461\n",
      "Val accuracy: 89.25714285714285\n",
      "Iter 12 -> sub iter 99 : 89.20634920634922\n",
      "Iteration: 13\n",
      "Train accuracy: 89.83015873015873\n",
      "Val accuracy: 89.35714285714286\n",
      "Iter 13 -> sub iter 99 : 89.36507936507937\n",
      "Iteration: 14\n",
      "Train accuracy: 90.12222222222222\n",
      "Val accuracy: 89.71428571428571\n",
      "Iter 14 -> sub iter 99 : 89.68253968253968\n",
      "Iteration: 15\n",
      "Train accuracy: 90.38730158730158\n",
      "Val accuracy: 89.88571428571429\n",
      "Iter 15 -> sub iter 99 : 89.52380952380953\n",
      "Iteration: 16\n",
      "Train accuracy: 90.6015873015873\n",
      "Val accuracy: 90.10000000000001\n",
      "Iter 16 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 17\n",
      "Train accuracy: 90.83968253968254\n",
      "Val accuracy: 90.38571428571429\n",
      "Iter 17 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 18\n",
      "Train accuracy: 91.04444444444444\n",
      "Val accuracy: 90.44285714285715\n",
      "Iter 18 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 19\n",
      "Train accuracy: 91.1984126984127\n",
      "Val accuracy: 90.57142857142857\n",
      "Iter 19 -> sub iter 99 : 90.09206349206358\n",
      "Iteration: 20\n",
      "Train accuracy: 91.35714285714286\n",
      "Val accuracy: 90.67142857142856\n",
      "Iter 20 -> sub iter 99 : 90.05079365079364\n",
      "Iteration: 21\n",
      "Train accuracy: 91.5111111111111\n",
      "Val accuracy: 90.87142857142857\n",
      "Iter 21 -> sub iter 99 : 90.31746031746032\n",
      "Iteration: 22\n",
      "Train accuracy: 91.67460317460318\n",
      "Val accuracy: 90.92857142857143\n",
      "Iter 22 -> sub iter 99 : 90.63492063492063\n",
      "Iteration: 23\n",
      "Train accuracy: 91.8031746031746\n",
      "Val accuracy: 91.0\n",
      "Iter 23 -> sub iter 99 : 90.63492063492063\n",
      "Iteration: 24\n",
      "Train accuracy: 91.93174603174603\n",
      "Val accuracy: 91.05714285714286\n",
      "Iter 24 -> sub iter 99 : 91.11111111111111\n",
      "Iteration: 25\n",
      "Train accuracy: 92.03492063492064\n",
      "Val accuracy: 91.15714285714286\n",
      "Iter 25 -> sub iter 99 : 91.11111111111111\n",
      "Iteration: 26\n",
      "Train accuracy: 92.14761904761905\n",
      "Val accuracy: 91.22857142857143\n",
      "Iter 26 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 27\n",
      "Train accuracy: 92.30000000000001\n",
      "Val accuracy: 91.31428571428572\n",
      "Iter 27 -> sub iter 99 : 91.90476190476193\n",
      "Iteration: 28\n",
      "Train accuracy: 92.3984126984127\n",
      "Val accuracy: 91.52857142857142\n",
      "Iter 28 -> sub iter 99 : 92.06349206349206\n",
      "Iteration: 29\n",
      "Train accuracy: 92.52857142857142\n",
      "Val accuracy: 91.67142857142856\n",
      "Iter 29 -> sub iter 99 : 92.53968253968254\n",
      "Iteration: 30\n",
      "Train accuracy: 92.62539682539682\n",
      "Val accuracy: 91.82857142857142\n",
      "Iter 30 -> sub iter 99 : 92.69841269841274\n",
      "Iteration: 31\n",
      "Train accuracy: 92.68095238095239\n",
      "Val accuracy: 91.92857142857143\n",
      "Iter 31 -> sub iter 99 : 93.33333333333333\n",
      "Iteration: 32\n",
      "Train accuracy: 92.74444444444444\n",
      "Val accuracy: 92.0\n",
      "Iter 32 -> sub iter 99 : 93.33333333333333\n",
      "Iteration: 33\n",
      "Train accuracy: 92.83015873015873\n",
      "Val accuracy: 92.10000000000001\n",
      "Iter 33 -> sub iter 99 : 93.33333333333333\n",
      "Iteration: 34\n",
      "Train accuracy: 92.93809523809524\n",
      "Val accuracy: 92.18571428571428\n",
      "Iter 34 -> sub iter 99 : 93.65079365079364\n",
      "Iteration: 35\n",
      "Train accuracy: 93.03492063492064\n",
      "Val accuracy: 92.32857142857142\n",
      "Iter 35 -> sub iter 99 : 93.96825396825396\n",
      "Iteration: 36\n",
      "Train accuracy: 93.1047619047619\n",
      "Val accuracy: 92.44285714285714\n",
      "Iter 36 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 37\n",
      "Train accuracy: 93.19047619047619\n",
      "Val accuracy: 92.55714285714286\n",
      "Iter 37 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 38\n",
      "Train accuracy: 93.28253968253968\n",
      "Val accuracy: 92.64285714285714\n",
      "Iter 38 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 39\n",
      "Train accuracy: 93.35555555555555\n",
      "Val accuracy: 92.71428571428572\n",
      "Iter 39 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 40\n",
      "Train accuracy: 93.42063492063491\n",
      "Val accuracy: 92.82857142857142\n",
      "Iter 40 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 41\n",
      "Train accuracy: 93.48571428571428\n",
      "Val accuracy: 92.87142857142857\n",
      "Iter 41 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 42\n",
      "Train accuracy: 93.54920634920634\n",
      "Val accuracy: 92.88571428571429\n",
      "Iter 42 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 43\n",
      "Train accuracy: 93.5968253968254\n",
      "Val accuracy: 92.9\n",
      "Iter 43 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 44\n",
      "Train accuracy: 93.66984126984127\n",
      "Val accuracy: 93.0\n",
      "Iter 44 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 45\n",
      "Train accuracy: 93.72857142857143\n",
      "Val accuracy: 93.01428571428572\n",
      "Iter 45 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 46\n",
      "Train accuracy: 93.8031746031746\n",
      "Val accuracy: 93.07142857142857\n",
      "Iter 46 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 47\n",
      "Train accuracy: 93.85555555555555\n",
      "Val accuracy: 93.07142857142857\n",
      "Iter 47 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 48\n",
      "Train accuracy: 93.91269841269842\n",
      "Val accuracy: 93.12857142857143\n",
      "Iter 48 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 49\n",
      "Train accuracy: 93.97301587301587\n",
      "Val accuracy: 93.2\n",
      "Iter 49 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 50\n",
      "Train accuracy: 94.01428571428572\n",
      "Val accuracy: 93.22857142857143\n",
      "Iter 50 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 51\n",
      "Train accuracy: 94.06984126984128\n",
      "Val accuracy: 93.24285714285713\n",
      "Iter 51 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 52\n",
      "Train accuracy: 94.1015873015873\n",
      "Val accuracy: 93.31428571428572\n",
      "Iter 52 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 53\n",
      "Train accuracy: 94.15238095238095\n",
      "Val accuracy: 93.27142857142857\n",
      "Iter 53 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 54\n",
      "Train accuracy: 94.17777777777778\n",
      "Val accuracy: 93.32857142857142\n",
      "Iter 54 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 55\n",
      "Train accuracy: 94.23015873015873\n",
      "Val accuracy: 93.37142857142857\n",
      "Iter 55 -> sub iter 99 : 93.96825396825396\n",
      "Iteration: 56\n",
      "Train accuracy: 94.27301587301588\n",
      "Val accuracy: 93.4\n",
      "Iter 56 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 57\n",
      "Train accuracy: 94.31746031746032\n",
      "Val accuracy: 93.47142857142858\n",
      "Iter 57 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 58\n",
      "Train accuracy: 94.36825396825397\n",
      "Val accuracy: 93.48571428571428\n",
      "Iter 58 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 59\n",
      "Train accuracy: 94.42380952380952\n",
      "Val accuracy: 93.52857142857142\n",
      "Iter 59 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 60\n",
      "Train accuracy: 94.47142857142858\n",
      "Val accuracy: 93.58571428571429\n",
      "Iter 60 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 61\n",
      "Train accuracy: 94.51587301587303\n",
      "Val accuracy: 93.61428571428571\n",
      "Iter 61 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 62\n",
      "Train accuracy: 94.53809523809524\n",
      "Val accuracy: 93.61428571428571\n",
      "Iter 62 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 63\n",
      "Train accuracy: 94.57460317460318\n",
      "Val accuracy: 93.65714285714286\n",
      "Iter 63 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 64\n",
      "Train accuracy: 94.5968253968254\n",
      "Val accuracy: 93.68571428571428\n",
      "Iter 64 -> sub iter 99 : 94.28571428571428\n",
      "Iteration: 65\n",
      "Train accuracy: 94.64444444444445\n",
      "Val accuracy: 93.74285714285713\n",
      "Iter 65 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 66\n",
      "Train accuracy: 94.68571428571428\n",
      "Val accuracy: 93.8\n",
      "Iter 66 -> sub iter 99 : 94.12698412698413\n",
      "Iteration: 67\n",
      "Train accuracy: 94.7063492063492\n",
      "Val accuracy: 93.82857142857142\n",
      "Iter 67 -> sub iter 99 : 94.60317460317466\n",
      "Iteration: 68\n",
      "Train accuracy: 94.73174603174603\n",
      "Val accuracy: 93.85714285714286\n",
      "Iter 68 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 69\n",
      "Train accuracy: 94.77619047619048\n",
      "Val accuracy: 93.88571428571429\n",
      "Iter 69 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 70\n",
      "Train accuracy: 94.8079365079365\n",
      "Val accuracy: 93.84285714285714\n",
      "Iter 70 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 71\n",
      "Train accuracy: 94.85555555555555\n",
      "Val accuracy: 93.91428571428571\n",
      "Iter 71 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 72\n",
      "Train accuracy: 94.88095238095238\n",
      "Val accuracy: 93.97142857142858\n",
      "Iter 72 -> sub iter 99 : 94.44444444444444\n",
      "Iteration: 73\n",
      "Train accuracy: 94.90793650793651\n",
      "Val accuracy: 94.02857142857142\n",
      "Iter 73 -> sub iter 99 : 94.60317460317466\n",
      "Iteration: 74\n",
      "Train accuracy: 94.92698412698412\n",
      "Val accuracy: 94.02857142857142\n",
      "Iter 74 -> sub iter 99 : 94.60317460317466\n",
      "Iteration: 75\n",
      "Train accuracy: 94.94126984126984\n",
      "Val accuracy: 94.02857142857142\n",
      "Iter 75 -> sub iter 99 : 94.60317460317462\n",
      "Iteration: 76\n",
      "Train accuracy: 94.96825396825398\n",
      "Val accuracy: 94.07142857142857\n",
      "Iter 76 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 77\n",
      "Train accuracy: 94.9968253968254\n",
      "Val accuracy: 94.08571428571429\n",
      "Iter 77 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 78\n",
      "Train accuracy: 95.03333333333333\n",
      "Val accuracy: 94.12857142857143\n",
      "Iter 78 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 79\n",
      "Train accuracy: 95.06507936507937\n",
      "Val accuracy: 94.11428571428571\n",
      "Iter 79 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 80\n",
      "Train accuracy: 95.1\n",
      "Val accuracy: 94.17142857142858\n",
      "Iter 80 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 81\n",
      "Train accuracy: 95.13333333333334\n",
      "Val accuracy: 94.14285714285714\n",
      "Iter 81 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 82\n",
      "Train accuracy: 95.16666666666667\n",
      "Val accuracy: 94.15714285714286\n",
      "Iter 82 -> sub iter 99 : 94.76190476190476\n",
      "Iteration: 83\n",
      "Train accuracy: 95.1920634920635\n",
      "Val accuracy: 94.19999999999999\n",
      "Iter 83 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 84\n",
      "Train accuracy: 95.20793650793651\n",
      "Val accuracy: 94.25714285714287\n",
      "Iter 84 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 85\n",
      "Train accuracy: 95.23968253968253\n",
      "Val accuracy: 94.25714285714287\n",
      "Iter 85 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 86\n",
      "Train accuracy: 95.26031746031745\n",
      "Val accuracy: 94.28571428571428\n",
      "Iter 86 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 87\n",
      "Train accuracy: 95.29841269841269\n",
      "Val accuracy: 94.34285714285714\n",
      "Iter 87 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 88\n",
      "Train accuracy: 95.31904761904761\n",
      "Val accuracy: 94.37142857142857\n",
      "Iter 88 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 89\n",
      "Train accuracy: 95.34285714285714\n",
      "Val accuracy: 94.41428571428571\n",
      "Iter 89 -> sub iter 99 : 95.07936507936508\n",
      "Iteration: 90\n",
      "Train accuracy: 95.36349206349206\n",
      "Val accuracy: 94.39999999999999\n",
      "Iter 90 -> sub iter 99 : 95.23809523809523\n",
      "Iteration: 91\n",
      "Train accuracy: 95.39365079365079\n",
      "Val accuracy: 94.35714285714286\n",
      "Iter 91 -> sub iter 99 : 95.23809523809523\n",
      "Iteration: 92\n",
      "Train accuracy: 95.42222222222222\n",
      "Val accuracy: 94.38571428571429\n",
      "Iter 92 -> sub iter 99 : 95.23809523809523\n",
      "Iteration: 93\n",
      "Train accuracy: 95.44126984126984\n",
      "Val accuracy: 94.41428571428571\n",
      "Iter 93 -> sub iter 99 : 95.23809523809523\n",
      "Iteration: 94\n",
      "Train accuracy: 95.47301587301588\n",
      "Val accuracy: 94.45714285714286\n",
      "Iter 94 -> sub iter 99 : 95.23809523809523\n",
      "Iteration: 95\n",
      "Train accuracy: 95.4968253968254\n",
      "Val accuracy: 94.45714285714286\n",
      "Iter 95 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 96\n",
      "Train accuracy: 95.52222222222223\n",
      "Val accuracy: 94.47142857142858\n",
      "Iter 96 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 97\n",
      "Train accuracy: 95.54285714285714\n",
      "Val accuracy: 94.51428571428572\n",
      "Iter 97 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 98\n",
      "Train accuracy: 95.56031746031746\n",
      "Val accuracy: 94.51428571428572\n",
      "Iter 98 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 99\n",
      "Train accuracy: 95.57777777777777\n",
      "Val accuracy: 94.58571428571429\n",
      "Iter 99 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 100\n",
      "Train accuracy: 95.59841269841269\n",
      "Val accuracy: 94.61428571428571\n",
      "Iter 100 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 101\n",
      "Train accuracy: 95.62539682539682\n",
      "Val accuracy: 94.62857142857143\n",
      "Iter 101 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 102\n",
      "Train accuracy: 95.64761904761905\n",
      "Val accuracy: 94.62857142857143\n",
      "Iter 102 -> sub iter 99 : 95.39682539682542\n",
      "Iteration: 103\n",
      "Train accuracy: 95.67301587301587\n",
      "Val accuracy: 94.61428571428571\n",
      "Iter 103 -> sub iter 99 : 95.39682539682542\n",
      "Iteration: 104\n",
      "Train accuracy: 95.66984126984127\n",
      "Val accuracy: 94.64285714285714\n",
      "Iter 104 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 105\n",
      "Train accuracy: 95.69047619047619\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 105 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 106\n",
      "Train accuracy: 95.71587301587302\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 106 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 107\n",
      "Train accuracy: 95.73492063492064\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 107 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 108\n",
      "Train accuracy: 95.73174603174604\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 108 -> sub iter 99 : 95.39682539682542\n",
      "Iteration: 109\n",
      "Train accuracy: 95.73650793650795\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 109 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 110\n",
      "Train accuracy: 95.76666666666667\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 110 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 111\n",
      "Train accuracy: 95.77619047619048\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 111 -> sub iter 99 : 95.39682539682547\n",
      "Iteration: 112\n",
      "Train accuracy: 95.78730158730158\n",
      "Val accuracy: 94.62857142857143\n",
      "Iter 112 -> sub iter 99 : 95.55555555555556\n",
      "Iteration: 113\n",
      "Train accuracy: 95.8015873015873\n",
      "Val accuracy: 94.64285714285714\n",
      "Iter 113 -> sub iter 99 : 95.55555555555556\n",
      "Iteration: 114\n",
      "Train accuracy: 95.82539682539682\n",
      "Val accuracy: 94.61428571428571\n",
      "Iter 114 -> sub iter 99 : 95.55555555555556\n",
      "Iteration: 115\n",
      "Train accuracy: 95.83015873015873\n",
      "Val accuracy: 94.62857142857143\n",
      "Iter 115 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 116\n",
      "Train accuracy: 95.83174603174604\n",
      "Val accuracy: 94.65714285714286\n",
      "Iter 116 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 117\n",
      "Train accuracy: 95.83174603174604\n",
      "Val accuracy: 94.67142857142858\n",
      "Iter 117 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 118\n",
      "Train accuracy: 95.84761904761905\n",
      "Val accuracy: 94.68571428571428\n",
      "Iter 118 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 119\n",
      "Train accuracy: 95.85714285714285\n",
      "Val accuracy: 94.74285714285713\n",
      "Iter 119 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 120\n",
      "Train accuracy: 95.87142857142858\n",
      "Val accuracy: 94.74285714285713\n",
      "Iter 120 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 121\n",
      "Train accuracy: 95.88888888888889\n",
      "Val accuracy: 94.69999999999999\n",
      "Iter 121 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 122\n",
      "Train accuracy: 95.89999999999999\n",
      "Val accuracy: 94.77142857142857\n",
      "Iter 122 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 123\n",
      "Train accuracy: 95.92063492063491\n",
      "Val accuracy: 94.77142857142857\n",
      "Iter 123 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 124\n",
      "Train accuracy: 95.92698412698412\n",
      "Val accuracy: 94.8\n",
      "Iter 124 -> sub iter 99 : 95.71428571428572\n",
      "Iteration: 125\n",
      "Train accuracy: 95.95555555555556\n",
      "Val accuracy: 94.77142857142857\n",
      "Iter 125 -> sub iter 99 : 95.87301587301587\n",
      "Iteration: 126\n",
      "Train accuracy: 95.95873015873015\n",
      "Val accuracy: 94.82857142857142\n",
      "Iter 126 -> sub iter 99 : 95.87301587301587\n",
      "Iteration: 127\n",
      "Train accuracy: 95.97142857142858\n",
      "Val accuracy: 94.84285714285714\n",
      "Iter 127 -> sub iter 99 : 95.87301587301587\n",
      "Iteration: 128\n",
      "Train accuracy: 95.98095238095237\n",
      "Val accuracy: 94.82857142857142\n",
      "Iter 128 -> sub iter 99 : 95.87301587301587\n",
      "Iteration: 129\n",
      "Train accuracy: 95.9984126984127\n",
      "Val accuracy: 94.81428571428572\n",
      "Iter 129 -> sub iter 99 : 96.03174603174604\n",
      "Iteration: 130\n",
      "Train accuracy: 95.9952380952381\n",
      "Val accuracy: 94.8\n",
      "Iter 130 -> sub iter 99 : 96.03174603174604\n",
      "Iteration: 131\n",
      "Train accuracy: 96.0031746031746\n",
      "Val accuracy: 94.78571428571428\n",
      "Iter 131 -> sub iter 3 : 95.87301587301587\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000037?line=0'>1</a>\u001b[0m W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights \u001b[39m=\u001b[39m batchGDNP(x_train,y_train,epochsToTrain, \u001b[39m0.1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 5'\u001b[0m in \u001b[0;36mbatchGDNP\u001b[1;34m(X, Y, iter, lr, pert, print_op)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=375'>376</a>\u001b[0m lossBeforePert \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((A3\u001b[39m-\u001b[39mone_hot_encoding(Y1))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=377'>378</a>\u001b[0m \u001b[39m#print(f\"Main iter: {i} Sub iter : {j}\\n\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=378'>379</a>\u001b[0m \u001b[39m#dW1, db1, dW2, db2, dW3, db3 = backprop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X1, Y1)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=379'>380</a>\u001b[0m dW1, db1, dW2, db2, dW3, db3 \u001b[39m=\u001b[39m NP(pert, lossBeforePert, Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, b1, b2, b3, X1, Y1)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=380'>381</a>\u001b[0m \u001b[39m#print(f\"iter in iter{j}\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=381'>382</a>\u001b[0m W1, b1, W2, b2, W3, b3 \u001b[39m=\u001b[39m param_update(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr \u001b[39m=\u001b[39m lr)\n",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 5'\u001b[0m in \u001b[0;36mNP\u001b[1;34m(pert, lossBeforePert, Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, b1, b2, b3, X1, Y1)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=309'>310</a>\u001b[0m lossArrayAfterPertZ1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(Z1)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=310'>311</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(Z1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=311'>312</a>\u001b[0m   Z1pert \u001b[39m=\u001b[39m Z1\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=312'>313</a>\u001b[0m   Z1pert[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pert\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000004?line=314'>315</a>\u001b[0m   A1pert \u001b[39m=\u001b[39m relu(Z1pert)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = batchGDNP(x_train,y_train,epochsToTrain, 0.1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1\n",
      "Params Initialised\n",
      "Iter 0 -> sub iter 99 : 23.333333333333332\n",
      "Iteration: 1\n",
      "Train accuracy: 21.192063492063493\n",
      "Val accuracy: 21.185714285714287\n",
      "Iter 1 -> sub iter 99 : 32.380952380952387\n",
      "Iteration: 2\n",
      "Train accuracy: 30.338095238095235\n",
      "Val accuracy: 30.185714285714287\n",
      "Iter 2 -> sub iter 99 : 39.365079365079374\n",
      "Iteration: 3\n",
      "Train accuracy: 36.630158730158726\n",
      "Val accuracy: 35.885714285714286\n",
      "Iter 3 -> sub iter 99 : 43.333333333333336\n",
      "Iteration: 4\n",
      "Train accuracy: 40.7015873015873\n",
      "Val accuracy: 39.957142857142856\n",
      "Iter 4 -> sub iter 99 : 45.873015873015874\n",
      "Iteration: 5\n",
      "Train accuracy: 43.32222222222222\n",
      "Val accuracy: 43.042857142857144\n",
      "Iter 5 -> sub iter 99 : 47.777777777777786\n",
      "Iteration: 6\n",
      "Train accuracy: 45.303174603174604\n",
      "Val accuracy: 44.94285714285714\n",
      "Iter 6 -> sub iter 99 : 49.365079365079376\n",
      "Iteration: 7\n",
      "Train accuracy: 48.33174603174603\n",
      "Val accuracy: 47.3\n",
      "Iter 7 -> sub iter 99 : 55.079365079365084\n",
      "Iteration: 8\n",
      "Train accuracy: 53.77301587301587\n",
      "Val accuracy: 52.67142857142857\n",
      "Iter 8 -> sub iter 99 : 58.888888888888896\n",
      "Iteration: 9\n",
      "Train accuracy: 57.51904761904761\n",
      "Val accuracy: 56.471428571428575\n",
      "Iter 9 -> sub iter 99 : 61.587301587301596\n",
      "Iteration: 10\n",
      "Train accuracy: 60.73968253968254\n",
      "Val accuracy: 59.68571428571428\n",
      "Iter 10 -> sub iter 99 : 64.444444444444445\n",
      "Iteration: 11\n",
      "Train accuracy: 63.834920634920636\n",
      "Val accuracy: 62.97142857142857\n",
      "Iter 11 -> sub iter 99 : 64.444444444444445\n",
      "Iteration: 12\n",
      "Train accuracy: 66.26349206349207\n",
      "Val accuracy: 65.65714285714286\n",
      "Iter 12 -> sub iter 99 : 66.349206349206345\n",
      "Iteration: 13\n",
      "Train accuracy: 68.01904761904763\n",
      "Val accuracy: 67.37142857142857\n",
      "Iter 13 -> sub iter 99 : 67.619047619047625\n",
      "Iteration: 14\n",
      "Train accuracy: 69.34920634920636\n",
      "Val accuracy: 68.45714285714286\n",
      "Iter 14 -> sub iter 99 : 68.57142857142857\n",
      "Iteration: 15\n",
      "Train accuracy: 70.35714285714286\n",
      "Val accuracy: 69.27142857142857\n",
      "Iter 15 -> sub iter 99 : 69.68253968253968\n",
      "Iteration: 16\n",
      "Train accuracy: 71.15873015873015\n",
      "Val accuracy: 69.98571428571428\n",
      "Iter 16 -> sub iter 99 : 70.95238095238095\n",
      "Iteration: 17\n",
      "Train accuracy: 71.80952380952381\n",
      "Val accuracy: 70.6\n",
      "Iter 17 -> sub iter 99 : 71.90476190476196\n",
      "Iteration: 18\n",
      "Train accuracy: 72.47777777777777\n",
      "Val accuracy: 71.31428571428572\n",
      "Iter 18 -> sub iter 99 : 72.22222222222221\n",
      "Iteration: 19\n",
      "Train accuracy: 73.23015873015873\n",
      "Val accuracy: 72.17142857142858\n",
      "Iter 19 -> sub iter 99 : 73.49206349206354\n",
      "Iteration: 20\n",
      "Train accuracy: 74.12222222222222\n",
      "Val accuracy: 73.08571428571429\n",
      "Iter 20 -> sub iter 99 : 74.92063492063492\n",
      "Iteration: 21\n",
      "Train accuracy: 75.04603174603174\n",
      "Val accuracy: 73.75714285714285\n",
      "Iter 21 -> sub iter 99 : 76.19047619047619\n",
      "Iteration: 22\n",
      "Train accuracy: 75.86190476190477\n",
      "Val accuracy: 74.5142857142857\n",
      "Iter 22 -> sub iter 99 : 76.98412698412699\n",
      "Iteration: 23\n",
      "Train accuracy: 76.63809523809523\n",
      "Val accuracy: 74.9857142857143\n",
      "Iter 23 -> sub iter 99 : 76.82539682539684\n",
      "Iteration: 24\n",
      "Train accuracy: 77.25555555555556\n",
      "Val accuracy: 75.74285714285715\n",
      "Iter 24 -> sub iter 99 : 77.30158730158733\n",
      "Iteration: 25\n",
      "Train accuracy: 77.86031746031746\n",
      "Val accuracy: 76.25714285714285\n",
      "Iter 25 -> sub iter 99 : 77.77777777777779\n",
      "Iteration: 26\n",
      "Train accuracy: 78.41269841269842\n",
      "Val accuracy: 76.91428571428571\n",
      "Iter 26 -> sub iter 99 : 78.88888888888889\n",
      "Iteration: 27\n",
      "Train accuracy: 78.94285714285715\n",
      "Val accuracy: 77.58571428571429\n",
      "Iter 27 -> sub iter 99 : 78.73015873015873\n",
      "Iteration: 28\n",
      "Train accuracy: 79.43650793650794\n",
      "Val accuracy: 78.01428571428572\n",
      "Iter 28 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 29\n",
      "Train accuracy: 79.9\n",
      "Val accuracy: 78.65714285714286\n",
      "Iter 29 -> sub iter 99 : 79.36507936507937\n",
      "Iteration: 30\n",
      "Train accuracy: 80.32857142857142\n",
      "Val accuracy: 79.04285714285714\n",
      "Iter 30 -> sub iter 99 : 80.07460317460318\n",
      "Iteration: 31\n",
      "Train accuracy: 80.68095238095238\n",
      "Val accuracy: 79.31428571428572\n",
      "Iter 31 -> sub iter 99 : 80.31746031746032\n",
      "Iteration: 32\n",
      "Train accuracy: 81.01428571428572\n",
      "Val accuracy: 79.65714285714286\n",
      "Iter 32 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 33\n",
      "Train accuracy: 81.36984126984127\n",
      "Val accuracy: 79.94285714285714\n",
      "Iter 33 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 34\n",
      "Train accuracy: 81.67619047619048\n",
      "Val accuracy: 80.10000000000001\n",
      "Iter 34 -> sub iter 99 : 81.90476190476196\n",
      "Iteration: 35\n",
      "Train accuracy: 81.95396825396826\n",
      "Val accuracy: 80.4\n",
      "Iter 35 -> sub iter 99 : 81.74603174603175\n",
      "Iteration: 36\n",
      "Train accuracy: 82.28095238095237\n",
      "Val accuracy: 80.7\n",
      "Iter 36 -> sub iter 99 : 81.90476190476198\n",
      "Iteration: 37\n",
      "Train accuracy: 82.53809523809524\n",
      "Val accuracy: 81.10000000000001\n",
      "Iter 37 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 38\n",
      "Train accuracy: 82.73492063492064\n",
      "Val accuracy: 81.27142857142857\n",
      "Iter 38 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 39\n",
      "Train accuracy: 82.9968253968254\n",
      "Val accuracy: 81.52857142857142\n",
      "Iter 39 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 40\n",
      "Train accuracy: 83.2\n",
      "Val accuracy: 81.78571428571428\n",
      "Iter 40 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 41\n",
      "Train accuracy: 83.46507936507936\n",
      "Val accuracy: 81.98571428571428\n",
      "Iter 41 -> sub iter 99 : 84.12698412698413\n",
      "Iteration: 42\n",
      "Train accuracy: 83.66349206349206\n",
      "Val accuracy: 82.14285714285714\n",
      "Iter 42 -> sub iter 99 : 84.28571428571429\n",
      "Iteration: 43\n",
      "Train accuracy: 83.87142857142858\n",
      "Val accuracy: 82.47142857142858\n",
      "Iter 43 -> sub iter 99 : 84.60317460317461\n",
      "Iteration: 44\n",
      "Train accuracy: 84.04761904761905\n",
      "Val accuracy: 82.67142857142858\n",
      "Iter 44 -> sub iter 99 : 84.44444444444444\n",
      "Iteration: 45\n",
      "Train accuracy: 84.21111111111111\n",
      "Val accuracy: 82.95714285714286\n",
      "Iter 45 -> sub iter 99 : 84.60317460317461\n",
      "Iteration: 46\n",
      "Train accuracy: 84.38571428571429\n",
      "Val accuracy: 83.05714285714285\n",
      "Iter 46 -> sub iter 99 : 85.07936507936508\n",
      "Iteration: 47\n",
      "Train accuracy: 84.57301587301588\n",
      "Val accuracy: 83.12857142857143\n",
      "Iter 47 -> sub iter 99 : 85.39682539682539\n",
      "Iteration: 48\n",
      "Train accuracy: 84.74444444444444\n",
      "Val accuracy: 83.34285714285714\n",
      "Iter 48 -> sub iter 99 : 85.71428571428571\n",
      "Iteration: 49\n",
      "Train accuracy: 84.91746031746031\n",
      "Val accuracy: 83.5\n",
      "Iter 49 -> sub iter 99 : 85.87301587301587\n",
      "Iteration: 50\n",
      "Train accuracy: 85.06984126984128\n",
      "Val accuracy: 83.61428571428571\n",
      "Iter 50 -> sub iter 99 : 85.87301587301587\n",
      "Iteration: 51\n",
      "Train accuracy: 85.22222222222223\n",
      "Val accuracy: 83.78571428571429\n",
      "Iter 51 -> sub iter 99 : 85.71428571428571\n",
      "Iteration: 52\n",
      "Train accuracy: 85.39999999999999\n",
      "Val accuracy: 83.84285714285714\n",
      "Iter 52 -> sub iter 99 : 86.19047619047619\n",
      "Iteration: 53\n",
      "Train accuracy: 85.54603174603174\n",
      "Val accuracy: 83.92857142857143\n",
      "Iter 53 -> sub iter 99 : 86.34920634920636\n",
      "Iteration: 54\n",
      "Train accuracy: 85.66984126984127\n",
      "Val accuracy: 84.12857142857143\n",
      "Iter 54 -> sub iter 99 : 86.50793650793659\n",
      "Iteration: 55\n",
      "Train accuracy: 85.8\n",
      "Val accuracy: 84.2\n",
      "Iter 55 -> sub iter 99 : 86.03174603174604\n",
      "Iteration: 56\n",
      "Train accuracy: 85.91587301587302\n",
      "Val accuracy: 84.31428571428572\n",
      "Iter 56 -> sub iter 99 : 86.19047619047619\n",
      "Iteration: 57\n",
      "Train accuracy: 85.99365079365079\n",
      "Val accuracy: 84.41428571428573\n",
      "Iter 57 -> sub iter 99 : 86.19047619047619\n",
      "Iteration: 58\n",
      "Train accuracy: 86.1\n",
      "Val accuracy: 84.52857142857142\n",
      "Iter 58 -> sub iter 99 : 86.34920634920636\n",
      "Iteration: 59\n",
      "Train accuracy: 86.23015873015873\n",
      "Val accuracy: 84.61428571428571\n",
      "Iter 59 -> sub iter 99 : 86.34920634920636\n",
      "Iteration: 60\n",
      "Train accuracy: 86.34444444444445\n",
      "Val accuracy: 84.68571428571428\n",
      "Iter 60 -> sub iter 99 : 86.50793650793652\n",
      "Iteration: 61\n",
      "Train accuracy: 86.42857142857143\n",
      "Val accuracy: 84.72857142857143\n",
      "Iter 61 -> sub iter 99 : 86.82539682539682\n",
      "Iteration: 62\n",
      "Train accuracy: 86.53968253968254\n",
      "Val accuracy: 84.85714285714285\n",
      "Iter 62 -> sub iter 99 : 86.82539682539682\n",
      "Iteration: 63\n",
      "Train accuracy: 86.65555555555555\n",
      "Val accuracy: 85.02857142857142\n",
      "Iter 63 -> sub iter 99 : 86.98412698412699\n",
      "Iteration: 64\n",
      "Train accuracy: 86.76984126984128\n",
      "Val accuracy: 85.08571428571429\n",
      "Iter 64 -> sub iter 99 : 87.14285714285714\n",
      "Iteration: 65\n",
      "Train accuracy: 86.89206349206349\n",
      "Val accuracy: 85.21428571428571\n",
      "Iter 65 -> sub iter 99 : 87.30158730158735\n",
      "Iteration: 66\n",
      "Train accuracy: 86.9920634920635\n",
      "Val accuracy: 85.3\n",
      "Iter 66 -> sub iter 99 : 87.30158730158732\n",
      "Iteration: 67\n",
      "Train accuracy: 87.06349206349206\n",
      "Val accuracy: 85.45714285714286\n",
      "Iter 67 -> sub iter 99 : 87.46031746031746\n",
      "Iteration: 68\n",
      "Train accuracy: 87.14603174603175\n",
      "Val accuracy: 85.54285714285714\n",
      "Iter 68 -> sub iter 99 : 87.61904761904762\n",
      "Iteration: 69\n",
      "Train accuracy: 87.1984126984127\n",
      "Val accuracy: 85.58571428571429\n",
      "Iter 69 -> sub iter 99 : 87.93650793650794\n",
      "Iteration: 70\n",
      "Train accuracy: 87.27936507936508\n",
      "Val accuracy: 85.8\n",
      "Iter 70 -> sub iter 99 : 87.61904761904762\n",
      "Iteration: 71\n",
      "Train accuracy: 87.34603174603176\n",
      "Val accuracy: 85.91428571428571\n",
      "Iter 71 -> sub iter 99 : 87.61904761904762\n",
      "Iteration: 72\n",
      "Train accuracy: 87.44761904761906\n",
      "Val accuracy: 86.02857142857144\n",
      "Iter 72 -> sub iter 99 : 87.61904761904762\n",
      "Iteration: 73\n",
      "Train accuracy: 87.55238095238094\n",
      "Val accuracy: 86.11428571428571\n",
      "Iter 73 -> sub iter 99 : 87.77777777777777\n",
      "Iteration: 74\n",
      "Train accuracy: 87.61904761904762\n",
      "Val accuracy: 86.18571428571428\n",
      "Iter 74 -> sub iter 99 : 87.93650793650794\n",
      "Iteration: 75\n",
      "Train accuracy: 87.69206349206348\n",
      "Val accuracy: 86.25714285714285\n",
      "Iter 75 -> sub iter 99 : 87.93650793650794\n",
      "Iteration: 76\n",
      "Train accuracy: 87.7968253968254\n",
      "Val accuracy: 86.34285714285714\n",
      "Iter 76 -> sub iter 99 : 87.93650793650794\n",
      "Iteration: 77\n",
      "Train accuracy: 87.87460317460317\n",
      "Val accuracy: 86.37142857142858\n",
      "Iter 77 -> sub iter 99 : 88.25396825396825\n",
      "Iteration: 78\n",
      "Train accuracy: 87.96666666666667\n",
      "Val accuracy: 86.5142857142857\n",
      "Iter 78 -> sub iter 99 : 88.25396825396825\n",
      "Iteration: 79\n",
      "Train accuracy: 88.00634920634921\n",
      "Val accuracy: 86.61428571428571\n",
      "Iter 79 -> sub iter 99 : 88.09523809523809\n",
      "Iteration: 80\n",
      "Train accuracy: 88.07301587301588\n",
      "Val accuracy: 86.71428571428571\n",
      "Iter 80 -> sub iter 99 : 88.09523809523809\n",
      "Iteration: 81\n",
      "Train accuracy: 88.16190476190476\n",
      "Val accuracy: 86.81428571428572\n",
      "Iter 81 -> sub iter 99 : 88.41269841269843\n",
      "Iteration: 82\n",
      "Train accuracy: 88.22539682539683\n",
      "Val accuracy: 86.88571428571429\n",
      "Iter 82 -> sub iter 99 : 88.57142857142857\n",
      "Iteration: 83\n",
      "Train accuracy: 88.27301587301586\n",
      "Val accuracy: 87.02857142857144\n",
      "Iter 83 -> sub iter 99 : 88.57142857142857\n",
      "Iteration: 84\n",
      "Train accuracy: 88.33333333333333\n",
      "Val accuracy: 87.08571428571429\n",
      "Iter 84 -> sub iter 99 : 88.73015873015872\n",
      "Iteration: 85\n",
      "Train accuracy: 88.38571428571429\n",
      "Val accuracy: 87.1\n",
      "Iter 85 -> sub iter 99 : 88.73015873015872\n",
      "Iteration: 86\n",
      "Train accuracy: 88.43174603174603\n",
      "Val accuracy: 87.14285714285714\n",
      "Iter 86 -> sub iter 99 : 88.88888888888889\n",
      "Iteration: 87\n",
      "Train accuracy: 88.47301587301587\n",
      "Val accuracy: 87.25714285714285\n",
      "Iter 87 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 88\n",
      "Train accuracy: 88.50634920634921\n",
      "Val accuracy: 87.37142857142857\n",
      "Iter 88 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 89\n",
      "Train accuracy: 88.55079365079365\n",
      "Val accuracy: 87.34285714285714\n",
      "Iter 89 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 90\n",
      "Train accuracy: 88.60317460317461\n",
      "Val accuracy: 87.34285714285714\n",
      "Iter 90 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 91\n",
      "Train accuracy: 88.66349206349207\n",
      "Val accuracy: 87.42857142857143\n",
      "Iter 91 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 92\n",
      "Train accuracy: 88.70476190476191\n",
      "Val accuracy: 87.44285714285715\n",
      "Iter 92 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 93\n",
      "Train accuracy: 88.75714285714285\n",
      "Val accuracy: 87.5142857142857\n",
      "Iter 93 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 94\n",
      "Train accuracy: 88.81269841269841\n",
      "Val accuracy: 87.55714285714285\n",
      "Iter 94 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 95\n",
      "Train accuracy: 88.87142857142857\n",
      "Val accuracy: 87.6\n",
      "Iter 95 -> sub iter 99 : 89.20634920634922\n",
      "Iteration: 96\n",
      "Train accuracy: 88.93015873015872\n",
      "Val accuracy: 87.64285714285714\n",
      "Iter 96 -> sub iter 99 : 89.36507936507937\n",
      "Iteration: 97\n",
      "Train accuracy: 89.0047619047619\n",
      "Val accuracy: 87.71428571428571\n",
      "Iter 97 -> sub iter 99 : 89.68253968253968\n",
      "Iteration: 98\n",
      "Train accuracy: 89.04761904761904\n",
      "Val accuracy: 87.78571428571429\n",
      "Iter 98 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 99\n",
      "Train accuracy: 89.09206349206349\n",
      "Val accuracy: 87.81428571428572\n",
      "Iter 99 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 100\n",
      "Train accuracy: 89.13650793650794\n",
      "Val accuracy: 87.84285714285714\n",
      "Iter 100 -> sub iter 99 : 90.02222222222223\n",
      "Iteration: 101\n",
      "Train accuracy: 89.17142857142856\n",
      "Val accuracy: 87.92857142857143\n",
      "Iter 101 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 102\n",
      "Train accuracy: 89.23968253968255\n",
      "Val accuracy: 87.97142857142856\n",
      "Iter 102 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 103\n",
      "Train accuracy: 89.28888888888889\n",
      "Val accuracy: 88.07142857142857\n",
      "Iter 103 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 104\n",
      "Train accuracy: 89.33174603174604\n",
      "Val accuracy: 88.12857142857143\n",
      "Iter 104 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 105\n",
      "Train accuracy: 89.36666666666667\n",
      "Val accuracy: 88.2\n",
      "Iter 105 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 106\n",
      "Train accuracy: 89.4015873015873\n",
      "Val accuracy: 88.27142857142857\n",
      "Iter 106 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 107\n",
      "Train accuracy: 89.43968253968254\n",
      "Val accuracy: 88.34285714285714\n",
      "Iter 107 -> sub iter 99 : 90.15873015873017\n",
      "Iteration: 108\n",
      "Train accuracy: 89.46666666666667\n",
      "Val accuracy: 88.35714285714286\n",
      "Iter 108 -> sub iter 99 : 90.47619047619048\n",
      "Iteration: 109\n",
      "Train accuracy: 89.5047619047619\n",
      "Val accuracy: 88.38571428571429\n",
      "Iter 109 -> sub iter 99 : 90.79365079365083\n",
      "Iteration: 110\n",
      "Train accuracy: 89.55396825396825\n",
      "Val accuracy: 88.44285714285715\n",
      "Iter 110 -> sub iter 99 : 90.79365079365084\n",
      "Iteration: 111\n",
      "Train accuracy: 89.6015873015873\n",
      "Val accuracy: 88.54285714285714\n",
      "Iter 111 -> sub iter 99 : 90.79365079365084\n",
      "Iteration: 112\n",
      "Train accuracy: 89.64444444444445\n",
      "Val accuracy: 88.6\n",
      "Iter 112 -> sub iter 99 : 90.79365079365082\n",
      "Iteration: 113\n",
      "Train accuracy: 89.67936507936508\n",
      "Val accuracy: 88.62857142857142\n",
      "Iter 113 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 114\n",
      "Train accuracy: 89.72698412698412\n",
      "Val accuracy: 88.67142857142856\n",
      "Iter 114 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 115\n",
      "Train accuracy: 89.78095238095239\n",
      "Val accuracy: 88.68571428571428\n",
      "Iter 115 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 116\n",
      "Train accuracy: 89.8079365079365\n",
      "Val accuracy: 88.77142857142857\n",
      "Iter 116 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 117\n",
      "Train accuracy: 89.83968253968254\n",
      "Val accuracy: 88.81428571428572\n",
      "Iter 117 -> sub iter 99 : 90.79365079365088\n",
      "Iteration: 118\n",
      "Train accuracy: 89.88571428571429\n",
      "Val accuracy: 88.87142857142857\n",
      "Iter 118 -> sub iter 99 : 90.79365079365083\n",
      "Iteration: 119\n",
      "Train accuracy: 89.91428571428571\n",
      "Val accuracy: 88.88571428571429\n",
      "Iter 119 -> sub iter 99 : 90.79365079365082\n",
      "Iteration: 120\n",
      "Train accuracy: 89.95714285714286\n",
      "Val accuracy: 88.91428571428571\n",
      "Iter 120 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 121\n",
      "Train accuracy: 89.97777777777777\n",
      "Val accuracy: 88.97142857142856\n",
      "Iter 121 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 122\n",
      "Train accuracy: 90.0079365079365\n",
      "Val accuracy: 89.07142857142857\n",
      "Iter 122 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 123\n",
      "Train accuracy: 90.04126984126984\n",
      "Val accuracy: 89.12857142857142\n",
      "Iter 123 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 124\n",
      "Train accuracy: 90.07619047619048\n",
      "Val accuracy: 89.22857142857143\n",
      "Iter 124 -> sub iter 99 : 91.11111111111111\n",
      "Iteration: 125\n",
      "Train accuracy: 90.11587301587302\n",
      "Val accuracy: 89.24285714285715\n",
      "Iter 125 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 126\n",
      "Train accuracy: 90.14761904761905\n",
      "Val accuracy: 89.25714285714285\n",
      "Iter 126 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 127\n",
      "Train accuracy: 90.16507936507936\n",
      "Val accuracy: 89.25714285714285\n",
      "Iter 127 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 128\n",
      "Train accuracy: 90.1968253968254\n",
      "Val accuracy: 89.28571428571429\n",
      "Iter 128 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 129\n",
      "Train accuracy: 90.23492063492064\n",
      "Val accuracy: 89.31428571428572\n",
      "Iter 129 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 130\n",
      "Train accuracy: 90.26190476190476\n",
      "Val accuracy: 89.37142857142857\n",
      "Iter 130 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 131\n",
      "Train accuracy: 90.27936507936508\n",
      "Val accuracy: 89.34285714285714\n",
      "Iter 131 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 132\n",
      "Train accuracy: 90.32063492063493\n",
      "Val accuracy: 89.38571428571429\n",
      "Iter 132 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 133\n",
      "Train accuracy: 90.34920634920634\n",
      "Val accuracy: 89.41428571428571\n",
      "Iter 133 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 134\n",
      "Train accuracy: 90.36825396825397\n",
      "Val accuracy: 89.45714285714286\n",
      "Iter 134 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 135\n",
      "Train accuracy: 90.4\n",
      "Val accuracy: 89.54285714285714\n",
      "Iter 135 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 136\n",
      "Train accuracy: 90.42857142857143\n",
      "Val accuracy: 89.60000000000001\n",
      "Iter 136 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 137\n",
      "Train accuracy: 90.44761904761904\n",
      "Val accuracy: 89.62857142857142\n",
      "Iter 137 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 138\n",
      "Train accuracy: 90.46825396825396\n",
      "Val accuracy: 89.65714285714286\n",
      "Iter 138 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 139\n",
      "Train accuracy: 90.48412698412699\n",
      "Val accuracy: 89.62857142857142\n",
      "Iter 139 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 140\n",
      "Train accuracy: 90.4952380952381\n",
      "Val accuracy: 89.62857142857142\n",
      "Iter 140 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 141\n",
      "Train accuracy: 90.51269841269841\n",
      "Val accuracy: 89.65714285714286\n",
      "Iter 141 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 142\n",
      "Train accuracy: 90.52222222222223\n",
      "Val accuracy: 89.65714285714286\n",
      "Iter 142 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 143\n",
      "Train accuracy: 90.54603174603174\n",
      "Val accuracy: 89.6857142857143\n",
      "Iter 143 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 144\n",
      "Train accuracy: 90.57777777777778\n",
      "Val accuracy: 89.72857142857143\n",
      "Iter 144 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 145\n",
      "Train accuracy: 90.6079365079365\n",
      "Val accuracy: 89.72857142857143\n",
      "Iter 145 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 146\n",
      "Train accuracy: 90.62222222222222\n",
      "Val accuracy: 89.77142857142857\n",
      "Iter 146 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 147\n",
      "Train accuracy: 90.63015873015873\n",
      "Val accuracy: 89.77142857142857\n",
      "Iter 147 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 148\n",
      "Train accuracy: 90.65396825396826\n",
      "Val accuracy: 89.77142857142857\n",
      "Iter 148 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 149\n",
      "Train accuracy: 90.67936507936508\n",
      "Val accuracy: 89.8\n",
      "Iter 149 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 150\n",
      "Train accuracy: 90.6920634920635\n",
      "Val accuracy: 89.81428571428572\n",
      "Training for 0.1\n",
      "Params Initialised\n",
      "Iter 0 -> sub iter 99 : 13.650793650793653\n",
      "Iteration: 1\n",
      "Train accuracy: 13.998412698412698\n",
      "Val accuracy: 14.32857142857143\n",
      "Iter 1 -> sub iter 99 : 19.365079365079367\n",
      "Iteration: 2\n",
      "Train accuracy: 20.185714285714283\n",
      "Val accuracy: 20.314285714285717\n",
      "Iter 2 -> sub iter 99 : 22.380952380952383\n",
      "Iteration: 3\n",
      "Train accuracy: 23.184126984126983\n",
      "Val accuracy: 23.32857142857143\n",
      "Iter 3 -> sub iter 99 : 25.555555555555554\n",
      "Iteration: 4\n",
      "Train accuracy: 26.05396825396825\n",
      "Val accuracy: 26.285714285714285\n",
      "Iter 4 -> sub iter 99 : 29.682539682539684\n",
      "Iteration: 5\n",
      "Train accuracy: 29.965079365079365\n",
      "Val accuracy: 30.542857142857144\n",
      "Iter 5 -> sub iter 99 : 39.841269841269845\n",
      "Iteration: 6\n",
      "Train accuracy: 39.268253968253966\n",
      "Val accuracy: 39.628571428571426\n",
      "Iter 6 -> sub iter 99 : 45.714285714285715\n",
      "Iteration: 7\n",
      "Train accuracy: 44.371428571428574\n",
      "Val accuracy: 44.800000000000004\n",
      "Iter 7 -> sub iter 99 : 48.888888888888886\n",
      "Iteration: 8\n",
      "Train accuracy: 47.52222222222222\n",
      "Val accuracy: 47.92857142857142\n",
      "Iter 8 -> sub iter 99 : 51.587301587301596\n",
      "Iteration: 9\n",
      "Train accuracy: 49.804761904761904\n",
      "Val accuracy: 50.2\n",
      "Iter 9 -> sub iter 99 : 53.174603174603185\n",
      "Iteration: 10\n",
      "Train accuracy: 51.74126984126984\n",
      "Val accuracy: 51.72857142857142\n",
      "Iter 10 -> sub iter 99 : 54.444444444444444\n",
      "Iteration: 11\n",
      "Train accuracy: 53.179365079365084\n",
      "Val accuracy: 53.214285714285715\n",
      "Iter 11 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 12\n",
      "Train accuracy: 54.36984126984127\n",
      "Val accuracy: 54.38571428571428\n",
      "Iter 12 -> sub iter 99 : 57.301587301587396\n",
      "Iteration: 13\n",
      "Train accuracy: 55.74761904761905\n",
      "Val accuracy: 55.51428571428572\n",
      "Iter 13 -> sub iter 99 : 60.793650793650794\n",
      "Iteration: 14\n",
      "Train accuracy: 58.53174603174603\n",
      "Val accuracy: 58.08571428571428\n",
      "Iter 14 -> sub iter 99 : 65.079365079365085\n",
      "Iteration: 15\n",
      "Train accuracy: 61.68730158730159\n",
      "Val accuracy: 61.01428571428571\n",
      "Iter 15 -> sub iter 99 : 66.507936507936544\n",
      "Iteration: 16\n",
      "Train accuracy: 63.53809523809524\n",
      "Val accuracy: 63.15714285714286\n",
      "Iter 16 -> sub iter 99 : 67.619047619047626\n",
      "Iteration: 17\n",
      "Train accuracy: 64.57619047619048\n",
      "Val accuracy: 64.31428571428572\n",
      "Iter 17 -> sub iter 99 : 68.730158730158735\n",
      "Iteration: 18\n",
      "Train accuracy: 65.37777777777778\n",
      "Val accuracy: 65.11428571428571\n",
      "Iter 18 -> sub iter 99 : 68.888888888888895\n",
      "Iteration: 19\n",
      "Train accuracy: 66.02698412698412\n",
      "Val accuracy: 65.75714285714285\n",
      "Iter 19 -> sub iter 99 : 69.523809523809526\n",
      "Iteration: 20\n",
      "Train accuracy: 66.6126984126984\n",
      "Val accuracy: 66.4\n",
      "Iter 20 -> sub iter 99 : 71.111111111111116\n",
      "Iteration: 21\n",
      "Train accuracy: 67.1952380952381\n",
      "Val accuracy: 66.81428571428572\n",
      "Iter 21 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 22\n",
      "Train accuracy: 68.56507936507936\n",
      "Val accuracy: 68.37142857142857\n",
      "Iter 22 -> sub iter 99 : 73.33333333333333\n",
      "Iteration: 23\n",
      "Train accuracy: 70.21904761904761\n",
      "Val accuracy: 70.35714285714286\n",
      "Iter 23 -> sub iter 99 : 73.80952380952381\n",
      "Iteration: 24\n",
      "Train accuracy: 71.43174603174603\n",
      "Val accuracy: 71.8\n",
      "Iter 24 -> sub iter 99 : 75.39682539682539\n",
      "Iteration: 25\n",
      "Train accuracy: 72.41587301587302\n",
      "Val accuracy: 73.2\n",
      "Iter 25 -> sub iter 99 : 76.03174603174602\n",
      "Iteration: 26\n",
      "Train accuracy: 73.25714285714285\n",
      "Val accuracy: 73.87142857142858\n",
      "Iter 26 -> sub iter 99 : 76.98412698412699\n",
      "Iteration: 27\n",
      "Train accuracy: 73.98095238095237\n",
      "Val accuracy: 74.58571428571429\n",
      "Iter 27 -> sub iter 99 : 77.30158730158731\n",
      "Iteration: 28\n",
      "Train accuracy: 74.55555555555556\n",
      "Val accuracy: 75.17142857142856\n",
      "Iter 28 -> sub iter 99 : 77.77777777777779\n",
      "Iteration: 29\n",
      "Train accuracy: 75.05873015873016\n",
      "Val accuracy: 75.72857142857143\n",
      "Iter 29 -> sub iter 99 : 78.41269841269842\n",
      "Iteration: 30\n",
      "Train accuracy: 75.51904761904763\n",
      "Val accuracy: 76.25714285714285\n",
      "Iter 30 -> sub iter 99 : 78.41269841269842\n",
      "Iteration: 31\n",
      "Train accuracy: 75.84444444444445\n",
      "Val accuracy: 76.5142857142857\n",
      "Iter 31 -> sub iter 99 : 78.73015873015873\n",
      "Iteration: 32\n",
      "Train accuracy: 76.22698412698414\n",
      "Val accuracy: 76.84285714285714\n",
      "Iter 32 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 33\n",
      "Train accuracy: 76.47460317460317\n",
      "Val accuracy: 77.14285714285715\n",
      "Iter 33 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 34\n",
      "Train accuracy: 76.77777777777777\n",
      "Val accuracy: 77.4\n",
      "Iter 34 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 35\n",
      "Train accuracy: 77.0015873015873\n",
      "Val accuracy: 77.65714285714286\n",
      "Iter 35 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 36\n",
      "Train accuracy: 77.21904761904761\n",
      "Val accuracy: 77.81428571428572\n",
      "Iter 36 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 37\n",
      "Train accuracy: 77.44920634920635\n",
      "Val accuracy: 78.02857142857142\n",
      "Iter 37 -> sub iter 99 : 79.36507936507937\n",
      "Iteration: 38\n",
      "Train accuracy: 77.64603174603174\n",
      "Val accuracy: 78.18571428571428\n",
      "Iter 38 -> sub iter 99 : 79.52380952380952\n",
      "Iteration: 39\n",
      "Train accuracy: 77.83333333333333\n",
      "Val accuracy: 78.3\n",
      "Iter 39 -> sub iter 99 : 79.84126984126985\n",
      "Iteration: 40\n",
      "Train accuracy: 78.01904761904763\n",
      "Val accuracy: 78.54285714285714\n",
      "Iter 40 -> sub iter 99 : 79.84126984126985\n",
      "Iteration: 41\n",
      "Train accuracy: 78.1984126984127\n",
      "Val accuracy: 78.74285714285715\n",
      "Iter 41 -> sub iter 99 : 80.00634920634929\n",
      "Iteration: 42\n",
      "Train accuracy: 78.37936507936509\n",
      "Val accuracy: 78.85714285714286\n",
      "Iter 42 -> sub iter 99 : 80.31746031746032\n",
      "Iteration: 43\n",
      "Train accuracy: 78.54603174603174\n",
      "Val accuracy: 78.98571428571428\n",
      "Iter 43 -> sub iter 99 : 80.47619047619048\n",
      "Iteration: 44\n",
      "Train accuracy: 78.71904761904761\n",
      "Val accuracy: 79.21428571428571\n",
      "Iter 44 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 45\n",
      "Train accuracy: 78.84761904761905\n",
      "Val accuracy: 79.27142857142857\n",
      "Iter 45 -> sub iter 99 : 80.79365079365089\n",
      "Iteration: 46\n",
      "Train accuracy: 78.98730158730159\n",
      "Val accuracy: 79.47142857142858\n",
      "Iter 46 -> sub iter 99 : 80.79365079365087\n",
      "Iteration: 47\n",
      "Train accuracy: 79.11587301587302\n",
      "Val accuracy: 79.65714285714286\n",
      "Iter 47 -> sub iter 99 : 80.79365079365082\n",
      "Iteration: 48\n",
      "Train accuracy: 79.23492063492064\n",
      "Val accuracy: 79.74285714285713\n",
      "Iter 48 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 49\n",
      "Train accuracy: 79.34126984126985\n",
      "Val accuracy: 79.87142857142857\n",
      "Iter 49 -> sub iter 99 : 80.79365079365089\n",
      "Iteration: 50\n",
      "Train accuracy: 79.43015873015872\n",
      "Val accuracy: 79.88571428571429\n",
      "Iter 50 -> sub iter 99 : 81.11111111111111\n",
      "Iteration: 51\n",
      "Train accuracy: 79.53492063492064\n",
      "Val accuracy: 80.01428571428572\n",
      "Iter 51 -> sub iter 99 : 81.11111111111111\n",
      "Iteration: 52\n",
      "Train accuracy: 79.62857142857143\n",
      "Val accuracy: 80.10000000000001\n",
      "Iter 52 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 53\n",
      "Train accuracy: 79.74285714285713\n",
      "Val accuracy: 80.27142857142857\n",
      "Iter 53 -> sub iter 99 : 81.42857142857143\n",
      "Iteration: 54\n",
      "Train accuracy: 79.84126984126985\n",
      "Val accuracy: 80.34285714285714\n",
      "Iter 54 -> sub iter 99 : 81.74603174603175\n",
      "Iteration: 55\n",
      "Train accuracy: 79.94920634920635\n",
      "Val accuracy: 80.37142857142857\n",
      "Iter 55 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 56\n",
      "Train accuracy: 80.04603174603174\n",
      "Val accuracy: 80.44285714285714\n",
      "Iter 56 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 57\n",
      "Train accuracy: 80.12698412698413\n",
      "Val accuracy: 80.52857142857142\n",
      "Iter 57 -> sub iter 99 : 82.69841269841278\n",
      "Iteration: 58\n",
      "Train accuracy: 80.22857142857143\n",
      "Val accuracy: 80.57142857142857\n",
      "Iter 58 -> sub iter 99 : 82.69841269841273\n",
      "Iteration: 59\n",
      "Train accuracy: 80.32380952380952\n",
      "Val accuracy: 80.64285714285714\n",
      "Iter 59 -> sub iter 99 : 82.85714285714286\n",
      "Iteration: 60\n",
      "Train accuracy: 80.4047619047619\n",
      "Val accuracy: 80.71428571428572\n",
      "Iter 60 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 61\n",
      "Train accuracy: 80.51428571428572\n",
      "Val accuracy: 80.85714285714286\n",
      "Iter 61 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 62\n",
      "Train accuracy: 80.61111111111111\n",
      "Val accuracy: 80.91428571428571\n",
      "Iter 62 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 63\n",
      "Train accuracy: 80.72857142857143\n",
      "Val accuracy: 80.94285714285714\n",
      "Iter 63 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 64\n",
      "Train accuracy: 80.81428571428572\n",
      "Val accuracy: 81.01428571428572\n",
      "Iter 64 -> sub iter 99 : 83.49206349206351\n",
      "Iteration: 65\n",
      "Train accuracy: 80.95079365079366\n",
      "Val accuracy: 81.05714285714286\n",
      "Iter 65 -> sub iter 99 : 83.65079365079366\n",
      "Iteration: 66\n",
      "Train accuracy: 81.2047619047619\n",
      "Val accuracy: 81.21428571428572\n",
      "Iter 66 -> sub iter 99 : 84.44444444444444\n",
      "Iteration: 67\n",
      "Train accuracy: 81.55238095238096\n",
      "Val accuracy: 81.55714285714286\n",
      "Iter 67 -> sub iter 99 : 85.39682539682539\n",
      "Iteration: 68\n",
      "Train accuracy: 82.17142857142858\n",
      "Val accuracy: 81.98571428571428\n",
      "Iter 68 -> sub iter 99 : 85.87301587301587\n",
      "Iteration: 69\n",
      "Train accuracy: 82.97301587301588\n",
      "Val accuracy: 82.88571428571429\n",
      "Iter 69 -> sub iter 99 : 86.50793650793659\n",
      "Iteration: 70\n",
      "Train accuracy: 83.9015873015873\n",
      "Val accuracy: 83.6\n",
      "Iter 70 -> sub iter 99 : 87.30158730158731\n",
      "Iteration: 71\n",
      "Train accuracy: 84.74444444444444\n",
      "Val accuracy: 84.48571428571428\n",
      "Iter 71 -> sub iter 99 : 87.46031746031746\n",
      "Iteration: 72\n",
      "Train accuracy: 85.50952380952381\n",
      "Val accuracy: 85.28571428571429\n",
      "Iter 72 -> sub iter 99 : 87.61904761904762\n",
      "Iteration: 73\n",
      "Train accuracy: 86.03650793650793\n",
      "Val accuracy: 85.54285714285714\n",
      "Iter 73 -> sub iter 99 : 87.93650793650794\n",
      "Iteration: 74\n",
      "Train accuracy: 86.52063492063492\n",
      "Val accuracy: 85.94285714285715\n",
      "Iter 74 -> sub iter 99 : 88.09523809523809\n",
      "Iteration: 75\n",
      "Train accuracy: 86.90952380952382\n",
      "Val accuracy: 86.52857142857144\n",
      "Iter 75 -> sub iter 99 : 88.25396825396825\n",
      "Iteration: 76\n",
      "Train accuracy: 87.25714285714285\n",
      "Val accuracy: 86.92857142857143\n",
      "Iter 76 -> sub iter 99 : 88.25396825396825\n",
      "Iteration: 77\n",
      "Train accuracy: 87.59523809523809\n",
      "Val accuracy: 87.22857142857143\n",
      "Iter 77 -> sub iter 99 : 88.25396825396825\n",
      "Iteration: 78\n",
      "Train accuracy: 87.83492063492064\n",
      "Val accuracy: 87.4\n",
      "Iter 78 -> sub iter 99 : 88.09523809523809\n",
      "Iteration: 79\n",
      "Train accuracy: 88.07460317460317\n",
      "Val accuracy: 87.62857142857143\n",
      "Iter 79 -> sub iter 99 : 88.41269841269849\n",
      "Iteration: 80\n",
      "Train accuracy: 88.23968253968253\n",
      "Val accuracy: 87.8\n",
      "Iter 80 -> sub iter 99 : 88.41269841269842\n",
      "Iteration: 81\n",
      "Train accuracy: 88.4063492063492\n",
      "Val accuracy: 87.94285714285715\n",
      "Iter 81 -> sub iter 99 : 88.57142857142857\n",
      "Iteration: 82\n",
      "Train accuracy: 88.58095238095238\n",
      "Val accuracy: 88.07142857142857\n",
      "Iter 82 -> sub iter 99 : 88.57142857142857\n",
      "Iteration: 83\n",
      "Train accuracy: 88.73174603174603\n",
      "Val accuracy: 88.15714285714286\n",
      "Iter 83 -> sub iter 99 : 88.73015873015872\n",
      "Iteration: 84\n",
      "Train accuracy: 88.86349206349206\n",
      "Val accuracy: 88.3\n",
      "Iter 84 -> sub iter 99 : 88.73015873015872\n",
      "Iteration: 85\n",
      "Train accuracy: 88.97142857142856\n",
      "Val accuracy: 88.37142857142857\n",
      "Iter 85 -> sub iter 99 : 88.41269841269845\n",
      "Iteration: 86\n",
      "Train accuracy: 89.09206349206349\n",
      "Val accuracy: 88.45714285714286\n",
      "Iter 86 -> sub iter 99 : 88.41269841269844\n",
      "Iteration: 87\n",
      "Train accuracy: 89.19365079365079\n",
      "Val accuracy: 88.52857142857142\n",
      "Iter 87 -> sub iter 99 : 88.25396825396825\n",
      "Iteration: 88\n",
      "Train accuracy: 89.29206349206349\n",
      "Val accuracy: 88.65714285714286\n",
      "Iter 88 -> sub iter 99 : 88.41269841269848\n",
      "Iteration: 89\n",
      "Train accuracy: 89.40476190476191\n",
      "Val accuracy: 88.8\n",
      "Iter 89 -> sub iter 99 : 88.41269841269843\n",
      "Iteration: 90\n",
      "Train accuracy: 89.51269841269841\n",
      "Val accuracy: 88.9857142857143\n",
      "Iter 90 -> sub iter 99 : 88.73015873015872\n",
      "Iteration: 91\n",
      "Train accuracy: 89.63333333333333\n",
      "Val accuracy: 89.1\n",
      "Iter 91 -> sub iter 99 : 88.88888888888889\n",
      "Iteration: 92\n",
      "Train accuracy: 89.71746031746032\n",
      "Val accuracy: 89.17142857142856\n",
      "Iter 92 -> sub iter 99 : 89.04761904761904\n",
      "Iteration: 93\n",
      "Train accuracy: 89.80317460317461\n",
      "Val accuracy: 89.2\n",
      "Iter 93 -> sub iter 99 : 89.20634920634922\n",
      "Iteration: 94\n",
      "Train accuracy: 89.88571428571429\n",
      "Val accuracy: 89.28571428571429\n",
      "Iter 94 -> sub iter 99 : 89.36507936507937\n",
      "Iteration: 95\n",
      "Train accuracy: 89.94920634920635\n",
      "Val accuracy: 89.35714285714286\n",
      "Iter 95 -> sub iter 99 : 89.52380952380953\n",
      "Iteration: 96\n",
      "Train accuracy: 90.01904761904763\n",
      "Val accuracy: 89.38571428571429\n",
      "Iter 96 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 97\n",
      "Train accuracy: 90.09206349206349\n",
      "Val accuracy: 89.41428571428571\n",
      "Iter 97 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 98\n",
      "Train accuracy: 90.14126984126985\n",
      "Val accuracy: 89.47142857142858\n",
      "Iter 98 -> sub iter 99 : 89.84126984126985\n",
      "Iteration: 99\n",
      "Train accuracy: 90.2095238095238\n",
      "Val accuracy: 89.54285714285714\n",
      "Iter 99 -> sub iter 99 : 90.02857142857143\n",
      "Iteration: 100\n",
      "Train accuracy: 90.2936507936508\n",
      "Val accuracy: 89.58571428571429\n",
      "Iter 100 -> sub iter 99 : 90.31746031746032\n",
      "Iteration: 101\n",
      "Train accuracy: 90.36031746031746\n",
      "Val accuracy: 89.67142857142856\n",
      "Iter 101 -> sub iter 99 : 90.31746031746032\n",
      "Iteration: 102\n",
      "Train accuracy: 90.42539682539682\n",
      "Val accuracy: 89.75714285714285\n",
      "Iter 102 -> sub iter 99 : 90.31746031746032\n",
      "Iteration: 103\n",
      "Train accuracy: 90.48412698412699\n",
      "Val accuracy: 89.81428571428572\n",
      "Iter 103 -> sub iter 99 : 90.31746031746032\n",
      "Iteration: 104\n",
      "Train accuracy: 90.54920634920634\n",
      "Val accuracy: 89.87142857142857\n",
      "Iter 104 -> sub iter 99 : 90.31746031746032\n",
      "Iteration: 105\n",
      "Train accuracy: 90.60952380952381\n",
      "Val accuracy: 89.9\n",
      "Iter 105 -> sub iter 99 : 90.47619047619048\n",
      "Iteration: 106\n",
      "Train accuracy: 90.65873015873017\n",
      "Val accuracy: 89.97142857142858\n",
      "Iter 106 -> sub iter 99 : 90.47619047619048\n",
      "Iteration: 107\n",
      "Train accuracy: 90.7031746031746\n",
      "Val accuracy: 90.04285714285714\n",
      "Iter 107 -> sub iter 99 : 90.47619047619048\n",
      "Iteration: 108\n",
      "Train accuracy: 90.73174603174603\n",
      "Val accuracy: 90.08571428571429\n",
      "Iter 108 -> sub iter 99 : 90.47619047619048\n",
      "Iteration: 109\n",
      "Train accuracy: 90.78412698412698\n",
      "Val accuracy: 90.12857142857142\n",
      "Iter 109 -> sub iter 99 : 90.47619047619048\n",
      "Iteration: 110\n",
      "Train accuracy: 90.84603174603174\n",
      "Val accuracy: 90.15714285714286\n",
      "Iter 110 -> sub iter 99 : 90.79365079365083\n",
      "Iteration: 111\n",
      "Train accuracy: 90.89365079365079\n",
      "Val accuracy: 90.2\n",
      "Iter 111 -> sub iter 99 : 90.95238095238095\n",
      "Iteration: 112\n",
      "Train accuracy: 90.94920634920635\n",
      "Val accuracy: 90.24285714285715\n",
      "Iter 112 -> sub iter 99 : 91.26984126984127\n",
      "Iteration: 113\n",
      "Train accuracy: 91.0079365079365\n",
      "Val accuracy: 90.25714285714285\n",
      "Iter 113 -> sub iter 99 : 91.26984126984127\n",
      "Iteration: 114\n",
      "Train accuracy: 91.06349206349206\n",
      "Val accuracy: 90.27142857142857\n",
      "Iter 114 -> sub iter 99 : 91.26984126984127\n",
      "Iteration: 115\n",
      "Train accuracy: 91.10000000000001\n",
      "Val accuracy: 90.27142857142857\n",
      "Iter 115 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 116\n",
      "Train accuracy: 91.14603174603174\n",
      "Val accuracy: 90.31428571428572\n",
      "Iter 116 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 117\n",
      "Train accuracy: 91.1952380952381\n",
      "Val accuracy: 90.34285714285714\n",
      "Iter 117 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 118\n",
      "Train accuracy: 91.23968253968255\n",
      "Val accuracy: 90.4\n",
      "Iter 118 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 119\n",
      "Train accuracy: 91.28571428571428\n",
      "Val accuracy: 90.4\n",
      "Iter 119 -> sub iter 99 : 91.26984126984127\n",
      "Iteration: 120\n",
      "Train accuracy: 91.33015873015873\n",
      "Val accuracy: 90.42857142857143\n",
      "Iter 120 -> sub iter 99 : 91.26984126984127\n",
      "Iteration: 121\n",
      "Train accuracy: 91.35555555555555\n",
      "Val accuracy: 90.47142857142858\n",
      "Iter 121 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 122\n",
      "Train accuracy: 91.41269841269842\n",
      "Val accuracy: 90.52857142857142\n",
      "Iter 122 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 123\n",
      "Train accuracy: 91.43968253968254\n",
      "Val accuracy: 90.58571428571427\n",
      "Iter 123 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 124\n",
      "Train accuracy: 91.48412698412697\n",
      "Val accuracy: 90.60000000000001\n",
      "Iter 124 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 125\n",
      "Train accuracy: 91.53333333333333\n",
      "Val accuracy: 90.62857142857142\n",
      "Iter 125 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 126\n",
      "Train accuracy: 91.57142857142857\n",
      "Val accuracy: 90.65714285714286\n",
      "Iter 126 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 127\n",
      "Train accuracy: 91.60634920634921\n",
      "Val accuracy: 90.68571428571428\n",
      "Iter 127 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 128\n",
      "Train accuracy: 91.63650793650794\n",
      "Val accuracy: 90.71428571428571\n",
      "Iter 128 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 129\n",
      "Train accuracy: 91.66349206349206\n",
      "Val accuracy: 90.74285714285715\n",
      "Iter 129 -> sub iter 99 : 91.42857142857143\n",
      "Iteration: 130\n",
      "Train accuracy: 91.70158730158731\n",
      "Val accuracy: 90.8\n",
      "Iter 130 -> sub iter 99 : 91.58730158730158\n",
      "Iteration: 131\n",
      "Train accuracy: 91.72063492063492\n",
      "Val accuracy: 90.82857142857142\n",
      "Iter 131 -> sub iter 99 : 91.74603174603175\n",
      "Iteration: 132\n",
      "Train accuracy: 91.74285714285715\n",
      "Val accuracy: 90.84285714285714\n",
      "Iter 132 -> sub iter 99 : 91.74603174603175\n",
      "Iteration: 133\n",
      "Train accuracy: 91.76507936507936\n",
      "Val accuracy: 90.87142857142857\n",
      "Iter 133 -> sub iter 99 : 91.74603174603175\n",
      "Iteration: 134\n",
      "Train accuracy: 91.8015873015873\n",
      "Val accuracy: 90.9\n",
      "Iter 134 -> sub iter 99 : 91.74603174603175\n",
      "Iteration: 135\n",
      "Train accuracy: 91.83015873015873\n",
      "Val accuracy: 90.9\n",
      "Iter 135 -> sub iter 99 : 91.90476190476198\n",
      "Iteration: 136\n",
      "Train accuracy: 91.86666666666666\n",
      "Val accuracy: 90.9\n",
      "Iter 136 -> sub iter 99 : 91.90476190476198\n",
      "Iteration: 137\n",
      "Train accuracy: 91.91746031746032\n",
      "Val accuracy: 90.94285714285715\n",
      "Iter 137 -> sub iter 99 : 91.90476190476198\n",
      "Iteration: 138\n",
      "Train accuracy: 91.94761904761904\n",
      "Val accuracy: 90.97142857142858\n",
      "Iter 138 -> sub iter 99 : 91.90476190476198\n",
      "Iteration: 139\n",
      "Train accuracy: 91.98888888888888\n",
      "Val accuracy: 91.05714285714286\n",
      "Iter 139 -> sub iter 99 : 91.90476190476194\n",
      "Iteration: 140\n",
      "Train accuracy: 92.02698412698412\n",
      "Val accuracy: 91.11428571428571\n",
      "Iter 140 -> sub iter 99 : 91.90476190476194\n",
      "Iteration: 141\n",
      "Train accuracy: 92.05238095238096\n",
      "Val accuracy: 91.12857142857142\n",
      "Iter 141 -> sub iter 99 : 91.90476190476194\n",
      "Iteration: 142\n",
      "Train accuracy: 92.08571428571429\n",
      "Val accuracy: 91.15714285714286\n",
      "Iter 142 -> sub iter 99 : 91.90476190476194\n",
      "Iteration: 143\n",
      "Train accuracy: 92.1079365079365\n",
      "Val accuracy: 91.17142857142856\n",
      "Iter 143 -> sub iter 99 : 92.06349206349206\n",
      "Iteration: 144\n",
      "Train accuracy: 92.13809523809525\n",
      "Val accuracy: 91.21428571428571\n",
      "Iter 144 -> sub iter 99 : 92.06349206349206\n",
      "Iteration: 145\n",
      "Train accuracy: 92.17142857142858\n",
      "Val accuracy: 91.24285714285715\n",
      "Iter 145 -> sub iter 99 : 92.22222222222223\n",
      "Iteration: 146\n",
      "Train accuracy: 92.1968253968254\n",
      "Val accuracy: 91.25714285714285\n",
      "Iter 146 -> sub iter 99 : 92.22222222222223\n",
      "Iteration: 147\n",
      "Train accuracy: 92.23174603174603\n",
      "Val accuracy: 91.27142857142857\n",
      "Iter 147 -> sub iter 99 : 92.38095238095238\n",
      "Iteration: 148\n",
      "Train accuracy: 92.25873015873016\n",
      "Val accuracy: 91.3\n",
      "Iter 148 -> sub iter 99 : 92.38095238095238\n",
      "Iteration: 149\n",
      "Train accuracy: 92.28253968253968\n",
      "Val accuracy: 91.3\n",
      "Iter 149 -> sub iter 99 : 92.38095238095238\n",
      "Iteration: 150\n",
      "Train accuracy: 92.3015873015873\n",
      "Val accuracy: 91.3\n",
      "Training for 0.01\n",
      "Params Initialised\n",
      "Iter 0 -> sub iter 99 : 24.285714285714285\n",
      "Iteration: 1\n",
      "Train accuracy: 21.285714285714285\n",
      "Val accuracy: 20.42857142857143\n",
      "Iter 1 -> sub iter 99 : 26.666666666666668\n",
      "Iteration: 2\n",
      "Train accuracy: 24.23968253968254\n",
      "Val accuracy: 23.414285714285715\n",
      "Iter 2 -> sub iter 99 : 29.523809523809526\n",
      "Iteration: 3\n",
      "Train accuracy: 26.51904761904762\n",
      "Val accuracy: 25.785714285714285\n",
      "Iter 3 -> sub iter 99 : 34.285714285714285\n",
      "Iteration: 4\n",
      "Train accuracy: 30.831746031746032\n",
      "Val accuracy: 30.242857142857144\n",
      "Iter 4 -> sub iter 99 : 37.301587301587304\n",
      "Iteration: 5\n",
      "Train accuracy: 33.77460317460317\n",
      "Val accuracy: 33.15714285714286\n",
      "Iter 5 -> sub iter 99 : 39.047619047619054\n",
      "Iteration: 6\n",
      "Train accuracy: 35.75238095238095\n",
      "Val accuracy: 35.25714285714286\n",
      "Iter 6 -> sub iter 99 : 39.523809523809526\n",
      "Iteration: 7\n",
      "Train accuracy: 37.7\n",
      "Val accuracy: 37.25714285714285\n",
      "Iter 7 -> sub iter 99 : 42.698412698412696\n",
      "Iteration: 8\n",
      "Train accuracy: 41.15555555555556\n",
      "Val accuracy: 40.34285714285714\n",
      "Iter 8 -> sub iter 99 : 46.190476190476195\n",
      "Iteration: 9\n",
      "Train accuracy: 44.84444444444444\n",
      "Val accuracy: 43.67142857142857\n",
      "Iter 9 -> sub iter 99 : 51.904761904761916\n",
      "Iteration: 10\n",
      "Train accuracy: 52.49206349206349\n",
      "Val accuracy: 52.214285714285715\n",
      "Iter 10 -> sub iter 99 : 55.238095238095246\n",
      "Iteration: 11\n",
      "Train accuracy: 56.10793650793651\n",
      "Val accuracy: 55.442857142857136\n",
      "Iter 11 -> sub iter 99 : 58.412698412698425\n",
      "Iteration: 12\n",
      "Train accuracy: 58.439682539682536\n",
      "Val accuracy: 57.72857142857143\n",
      "Iter 12 -> sub iter 99 : 60.317460317460316\n",
      "Iteration: 13\n",
      "Train accuracy: 60.098412698412695\n",
      "Val accuracy: 59.61428571428572\n",
      "Iter 13 -> sub iter 99 : 62.698412698412696\n",
      "Iteration: 14\n",
      "Train accuracy: 61.66031746031746\n",
      "Val accuracy: 61.42857142857143\n",
      "Iter 14 -> sub iter 99 : 65.238095238095245\n",
      "Iteration: 15\n",
      "Train accuracy: 63.32698412698413\n",
      "Val accuracy: 62.857142857142854\n",
      "Iter 15 -> sub iter 99 : 66.190476190476196\n",
      "Iteration: 16\n",
      "Train accuracy: 64.60317460317461\n",
      "Val accuracy: 64.14285714285714\n",
      "Iter 16 -> sub iter 99 : 66.507936507936545\n",
      "Iteration: 17\n",
      "Train accuracy: 65.4952380952381\n",
      "Val accuracy: 65.17142857142856\n",
      "Iter 17 -> sub iter 99 : 67.777777777777796\n",
      "Iteration: 18\n",
      "Train accuracy: 66.21904761904761\n",
      "Val accuracy: 65.9\n",
      "Iter 18 -> sub iter 99 : 68.730158730158736\n",
      "Iteration: 19\n",
      "Train accuracy: 66.91111111111111\n",
      "Val accuracy: 66.60000000000001\n",
      "Iter 19 -> sub iter 99 : 71.111111111111116\n",
      "Iteration: 20\n",
      "Train accuracy: 68.81111111111112\n",
      "Val accuracy: 68.54285714285714\n",
      "Iter 20 -> sub iter 99 : 71.90476190476193\n",
      "Iteration: 21\n",
      "Train accuracy: 70.85396825396826\n",
      "Val accuracy: 70.61428571428571\n",
      "Iter 21 -> sub iter 99 : 73.01587301587301\n",
      "Iteration: 22\n",
      "Train accuracy: 72.33333333333334\n",
      "Val accuracy: 72.0\n",
      "Iter 22 -> sub iter 99 : 73.49206349206358\n",
      "Iteration: 23\n",
      "Train accuracy: 73.44444444444444\n",
      "Val accuracy: 73.17142857142858\n",
      "Iter 23 -> sub iter 99 : 74.44444444444444\n",
      "Iteration: 24\n",
      "Train accuracy: 74.31428571428572\n",
      "Val accuracy: 74.11428571428571\n",
      "Iter 24 -> sub iter 99 : 74.92063492063492\n",
      "Iteration: 25\n",
      "Train accuracy: 74.92857142857143\n",
      "Val accuracy: 74.67142857142856\n",
      "Iter 25 -> sub iter 99 : 75.23809523809524\n",
      "Iteration: 26\n",
      "Train accuracy: 75.4968253968254\n",
      "Val accuracy: 75.0\n",
      "Iter 26 -> sub iter 99 : 76.03174603174602\n",
      "Iteration: 27\n",
      "Train accuracy: 75.91904761904762\n",
      "Val accuracy: 75.44285714285715\n",
      "Iter 27 -> sub iter 99 : 76.03174603174602\n",
      "Iteration: 28\n",
      "Train accuracy: 76.29047619047618\n",
      "Val accuracy: 75.68571428571428\n",
      "Iter 28 -> sub iter 99 : 76.19047619047619\n",
      "Iteration: 29\n",
      "Train accuracy: 76.65238095238095\n",
      "Val accuracy: 76.0\n",
      "Iter 29 -> sub iter 99 : 76.19047619047619\n",
      "Iteration: 30\n",
      "Train accuracy: 76.95714285714286\n",
      "Val accuracy: 76.31428571428572\n",
      "Iter 30 -> sub iter 99 : 76.34920634920634\n",
      "Iteration: 31\n",
      "Train accuracy: 77.22063492063492\n",
      "Val accuracy: 76.6\n",
      "Iter 31 -> sub iter 99 : 76.82539682539684\n",
      "Iteration: 32\n",
      "Train accuracy: 77.4920634920635\n",
      "Val accuracy: 76.92857142857143\n",
      "Iter 32 -> sub iter 99 : 77.14285714285715\n",
      "Iteration: 33\n",
      "Train accuracy: 77.72222222222223\n",
      "Val accuracy: 77.08571428571429\n",
      "Iter 33 -> sub iter 99 : 77.30158730158731\n",
      "Iteration: 34\n",
      "Train accuracy: 77.96190476190476\n",
      "Val accuracy: 77.21428571428571\n",
      "Iter 34 -> sub iter 99 : 77.61904761904762\n",
      "Iteration: 35\n",
      "Train accuracy: 78.16984126984127\n",
      "Val accuracy: 77.47142857142858\n",
      "Iter 35 -> sub iter 99 : 77.61904761904762\n",
      "Iteration: 36\n",
      "Train accuracy: 78.37460317460318\n",
      "Val accuracy: 77.8\n",
      "Iter 36 -> sub iter 99 : 77.61904761904762\n",
      "Iteration: 37\n",
      "Train accuracy: 78.57936507936508\n",
      "Val accuracy: 77.91428571428571\n",
      "Iter 37 -> sub iter 99 : 78.09523809523812\n",
      "Iteration: 38\n",
      "Train accuracy: 78.75555555555556\n",
      "Val accuracy: 78.04285714285714\n",
      "Iter 38 -> sub iter 99 : 78.41269841269842\n",
      "Iteration: 39\n",
      "Train accuracy: 78.92063492063492\n",
      "Val accuracy: 78.22857142857143\n",
      "Iter 39 -> sub iter 99 : 78.57142857142857\n",
      "Iteration: 40\n",
      "Train accuracy: 79.0936507936508\n",
      "Val accuracy: 78.37142857142857\n",
      "Iter 40 -> sub iter 99 : 78.57142857142857\n",
      "Iteration: 41\n",
      "Train accuracy: 79.26666666666667\n",
      "Val accuracy: 78.51428571428572\n",
      "Iter 41 -> sub iter 99 : 78.57142857142857\n",
      "Iteration: 42\n",
      "Train accuracy: 79.4\n",
      "Val accuracy: 78.58571428571427\n",
      "Iter 42 -> sub iter 99 : 78.73015873015873\n",
      "Iteration: 43\n",
      "Train accuracy: 79.52539682539683\n",
      "Val accuracy: 78.77142857142857\n",
      "Iter 43 -> sub iter 99 : 78.57142857142857\n",
      "Iteration: 44\n",
      "Train accuracy: 79.62539682539682\n",
      "Val accuracy: 78.85714285714286\n",
      "Iter 44 -> sub iter 99 : 78.57142857142857\n",
      "Iteration: 45\n",
      "Train accuracy: 79.71587301587302\n",
      "Val accuracy: 79.04285714285714\n",
      "Iter 45 -> sub iter 99 : 78.88888888888889\n",
      "Iteration: 46\n",
      "Train accuracy: 79.83492063492064\n",
      "Val accuracy: 79.21428571428571\n",
      "Iter 46 -> sub iter 99 : 78.88888888888889\n",
      "Iteration: 47\n",
      "Train accuracy: 79.95396825396826\n",
      "Val accuracy: 79.37142857142857\n",
      "Iter 47 -> sub iter 99 : 78.73015873015873\n",
      "Iteration: 48\n",
      "Train accuracy: 80.04444444444444\n",
      "Val accuracy: 79.45714285714286\n",
      "Iter 48 -> sub iter 99 : 78.88888888888889\n",
      "Iteration: 49\n",
      "Train accuracy: 80.13333333333334\n",
      "Val accuracy: 79.60000000000001\n",
      "Iter 49 -> sub iter 99 : 78.88888888888889\n",
      "Iteration: 50\n",
      "Train accuracy: 80.21111111111111\n",
      "Val accuracy: 79.7\n",
      "Iter 50 -> sub iter 99 : 79.04761904761905\n",
      "Iteration: 51\n",
      "Train accuracy: 80.2984126984127\n",
      "Val accuracy: 79.84285714285714\n",
      "Iter 51 -> sub iter 99 : 79.20634920634924\n",
      "Iteration: 52\n",
      "Train accuracy: 80.38253968253967\n",
      "Val accuracy: 79.9\n",
      "Iter 52 -> sub iter 99 : 79.68253968253968\n",
      "Iteration: 53\n",
      "Train accuracy: 80.48095238095239\n",
      "Val accuracy: 79.91428571428571\n",
      "Iter 53 -> sub iter 99 : 80.15873015873017\n",
      "Iteration: 54\n",
      "Train accuracy: 80.56349206349206\n",
      "Val accuracy: 80.05714285714286\n",
      "Iter 54 -> sub iter 99 : 80.31746031746032\n",
      "Iteration: 55\n",
      "Train accuracy: 80.64126984126983\n",
      "Val accuracy: 80.12857142857143\n",
      "Iter 55 -> sub iter 99 : 80.47619047619048\n",
      "Iteration: 56\n",
      "Train accuracy: 80.70793650793651\n",
      "Val accuracy: 80.21428571428572\n",
      "Iter 56 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 57\n",
      "Train accuracy: 80.78888888888889\n",
      "Val accuracy: 80.32857142857142\n",
      "Iter 57 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 58\n",
      "Train accuracy: 80.85873015873017\n",
      "Val accuracy: 80.42857142857143\n",
      "Iter 58 -> sub iter 99 : 80.79365079365082\n",
      "Iteration: 59\n",
      "Train accuracy: 80.91904761904762\n",
      "Val accuracy: 80.48571428571428\n",
      "Iter 59 -> sub iter 99 : 80.79365079365087\n",
      "Iteration: 60\n",
      "Train accuracy: 80.99047619047619\n",
      "Val accuracy: 80.55714285714286\n",
      "Iter 60 -> sub iter 99 : 80.79365079365087\n",
      "Iteration: 61\n",
      "Train accuracy: 81.06507936507936\n",
      "Val accuracy: 80.61428571428571\n",
      "Iter 61 -> sub iter 99 : 80.79365079365087\n",
      "Iteration: 62\n",
      "Train accuracy: 81.12857142857143\n",
      "Val accuracy: 80.60000000000001\n",
      "Iter 62 -> sub iter 99 : 81.11111111111111\n",
      "Iteration: 63\n",
      "Train accuracy: 81.1920634920635\n",
      "Val accuracy: 80.62857142857143\n",
      "Iter 63 -> sub iter 99 : 81.11111111111111\n",
      "Iteration: 64\n",
      "Train accuracy: 81.25555555555556\n",
      "Val accuracy: 80.65714285714286\n",
      "Iter 64 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 65\n",
      "Train accuracy: 81.32857142857142\n",
      "Val accuracy: 80.7\n",
      "Iter 65 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 66\n",
      "Train accuracy: 81.37936507936509\n",
      "Val accuracy: 80.78571428571428\n",
      "Iter 66 -> sub iter 99 : 81.42857142857143\n",
      "Iteration: 67\n",
      "Train accuracy: 81.43333333333334\n",
      "Val accuracy: 80.80000000000001\n",
      "Iter 67 -> sub iter 99 : 81.42857142857143\n",
      "Iteration: 68\n",
      "Train accuracy: 81.48253968253968\n",
      "Val accuracy: 80.84285714285714\n",
      "Iter 68 -> sub iter 99 : 81.42857142857143\n",
      "Iteration: 69\n",
      "Train accuracy: 81.52539682539683\n",
      "Val accuracy: 80.88571428571429\n",
      "Iter 69 -> sub iter 99 : 81.42857142857143\n",
      "Iteration: 70\n",
      "Train accuracy: 81.5904761904762\n",
      "Val accuracy: 80.91428571428571\n",
      "Iter 70 -> sub iter 99 : 81.74603174603175\n",
      "Iteration: 71\n",
      "Train accuracy: 81.65238095238095\n",
      "Val accuracy: 80.91428571428571\n",
      "Iter 71 -> sub iter 99 : 81.90476190476192\n",
      "Iteration: 72\n",
      "Train accuracy: 81.70793650793651\n",
      "Val accuracy: 80.95714285714286\n",
      "Iter 72 -> sub iter 99 : 81.90476190476192\n",
      "Iteration: 73\n",
      "Train accuracy: 81.76825396825397\n",
      "Val accuracy: 80.98571428571428\n",
      "Iter 73 -> sub iter 99 : 81.90476190476192\n",
      "Iteration: 74\n",
      "Train accuracy: 81.81904761904762\n",
      "Val accuracy: 81.08571428571429\n",
      "Iter 74 -> sub iter 99 : 81.74603174603175\n",
      "Iteration: 75\n",
      "Train accuracy: 81.85238095238095\n",
      "Val accuracy: 81.12857142857143\n",
      "Iter 75 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 76\n",
      "Train accuracy: 81.8968253968254\n",
      "Val accuracy: 81.18571428571428\n",
      "Iter 76 -> sub iter 99 : 82.22222222222221\n",
      "Iteration: 77\n",
      "Train accuracy: 81.93015873015874\n",
      "Val accuracy: 81.24285714285713\n",
      "Iter 77 -> sub iter 99 : 82.22222222222221\n",
      "Iteration: 78\n",
      "Train accuracy: 82.0\n",
      "Val accuracy: 81.24285714285713\n",
      "Iter 78 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 79\n",
      "Train accuracy: 82.04444444444444\n",
      "Val accuracy: 81.27142857142857\n",
      "Iter 79 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 80\n",
      "Train accuracy: 82.1\n",
      "Val accuracy: 81.3\n",
      "Iter 80 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 81\n",
      "Train accuracy: 82.13333333333334\n",
      "Val accuracy: 81.34285714285714\n",
      "Iter 81 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 82\n",
      "Train accuracy: 82.15396825396826\n",
      "Val accuracy: 81.32857142857142\n",
      "Iter 82 -> sub iter 99 : 82.06349206349206\n",
      "Iteration: 83\n",
      "Train accuracy: 82.2015873015873\n",
      "Val accuracy: 81.37142857142857\n",
      "Iter 83 -> sub iter 99 : 82.22222222222221\n",
      "Iteration: 84\n",
      "Train accuracy: 82.24761904761905\n",
      "Val accuracy: 81.38571428571429\n",
      "Iter 84 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 85\n",
      "Train accuracy: 82.28412698412698\n",
      "Val accuracy: 81.41428571428571\n",
      "Iter 85 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 86\n",
      "Train accuracy: 82.33015873015873\n",
      "Val accuracy: 81.48571428571428\n",
      "Iter 86 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 87\n",
      "Train accuracy: 82.37301587301587\n",
      "Val accuracy: 81.52857142857142\n",
      "Iter 87 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 88\n",
      "Train accuracy: 82.43809523809524\n",
      "Val accuracy: 81.54285714285714\n",
      "Iter 88 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 89\n",
      "Train accuracy: 82.46507936507936\n",
      "Val accuracy: 81.58571428571429\n",
      "Iter 89 -> sub iter 99 : 82.69841269841273\n",
      "Iteration: 90\n",
      "Train accuracy: 82.5047619047619\n",
      "Val accuracy: 81.62857142857143\n",
      "Iter 90 -> sub iter 99 : 82.69841269841278\n",
      "Iteration: 91\n",
      "Train accuracy: 82.53650793650795\n",
      "Val accuracy: 81.62857142857143\n",
      "Iter 91 -> sub iter 99 : 82.85714285714286\n",
      "Iteration: 92\n",
      "Train accuracy: 82.57142857142857\n",
      "Val accuracy: 81.71428571428572\n",
      "Iter 92 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 93\n",
      "Train accuracy: 82.6015873015873\n",
      "Val accuracy: 81.74285714285713\n",
      "Iter 93 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 94\n",
      "Train accuracy: 82.62857142857143\n",
      "Val accuracy: 81.77142857142857\n",
      "Iter 94 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 95\n",
      "Train accuracy: 82.65714285714286\n",
      "Val accuracy: 81.81428571428572\n",
      "Iter 95 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 96\n",
      "Train accuracy: 82.6920634920635\n",
      "Val accuracy: 81.89999999999999\n",
      "Iter 96 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 97\n",
      "Train accuracy: 82.72222222222221\n",
      "Val accuracy: 81.89999999999999\n",
      "Iter 97 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 98\n",
      "Train accuracy: 82.74603174603175\n",
      "Val accuracy: 81.94285714285714\n",
      "Iter 98 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 99\n",
      "Train accuracy: 82.78095238095237\n",
      "Val accuracy: 81.95714285714286\n",
      "Iter 99 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 100\n",
      "Train accuracy: 82.81746031746032\n",
      "Val accuracy: 81.95714285714286\n",
      "Iter 100 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 101\n",
      "Train accuracy: 82.84603174603174\n",
      "Val accuracy: 81.98571428571428\n",
      "Iter 101 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 102\n",
      "Train accuracy: 82.87777777777777\n",
      "Val accuracy: 81.98571428571428\n",
      "Iter 102 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 103\n",
      "Train accuracy: 82.89047619047619\n",
      "Val accuracy: 82.02857142857142\n",
      "Iter 103 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 104\n",
      "Train accuracy: 82.92380952380952\n",
      "Val accuracy: 82.01428571428572\n",
      "Iter 104 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 105\n",
      "Train accuracy: 82.95555555555556\n",
      "Val accuracy: 82.02857142857142\n",
      "Iter 105 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 106\n",
      "Train accuracy: 82.97777777777777\n",
      "Val accuracy: 82.05714285714286\n",
      "Iter 106 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 107\n",
      "Train accuracy: 83.0\n",
      "Val accuracy: 82.12857142857143\n",
      "Iter 107 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 108\n",
      "Train accuracy: 83.02539682539683\n",
      "Val accuracy: 82.12857142857143\n",
      "Iter 108 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 109\n",
      "Train accuracy: 83.05079365079365\n",
      "Val accuracy: 82.14285714285714\n",
      "Iter 109 -> sub iter 99 : 83.65079365079366\n",
      "Iteration: 110\n",
      "Train accuracy: 83.07460317460318\n",
      "Val accuracy: 82.18571428571428\n",
      "Iter 110 -> sub iter 99 : 83.65079365079366\n",
      "Iteration: 111\n",
      "Train accuracy: 83.1\n",
      "Val accuracy: 82.21428571428572\n",
      "Iter 111 -> sub iter 99 : 83.65079365079366\n",
      "Iteration: 112\n",
      "Train accuracy: 83.13015873015873\n",
      "Val accuracy: 82.21428571428572\n",
      "Iter 112 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 113\n",
      "Train accuracy: 83.16190476190476\n",
      "Val accuracy: 82.24285714285713\n",
      "Iter 113 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 114\n",
      "Train accuracy: 83.17936507936507\n",
      "Val accuracy: 82.27142857142857\n",
      "Iter 114 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 115\n",
      "Train accuracy: 83.20476190476191\n",
      "Val accuracy: 82.28571428571428\n",
      "Iter 115 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 116\n",
      "Train accuracy: 83.22698412698412\n",
      "Val accuracy: 82.32857142857142\n",
      "Iter 116 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 117\n",
      "Train accuracy: 83.25396825396825\n",
      "Val accuracy: 82.37142857142857\n",
      "Iter 117 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 118\n",
      "Train accuracy: 83.28253968253968\n",
      "Val accuracy: 82.38571428571429\n",
      "Iter 118 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 119\n",
      "Train accuracy: 83.30634920634921\n",
      "Val accuracy: 82.39999999999999\n",
      "Iter 119 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 120\n",
      "Train accuracy: 83.31904761904761\n",
      "Val accuracy: 82.42857142857143\n",
      "Iter 120 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 121\n",
      "Train accuracy: 83.34603174603174\n",
      "Val accuracy: 82.45714285714286\n",
      "Iter 121 -> sub iter 99 : 83.80952380952381\n",
      "Iteration: 122\n",
      "Train accuracy: 83.37460317460318\n",
      "Val accuracy: 82.48571428571428\n",
      "Iter 122 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 123\n",
      "Train accuracy: 83.38888888888889\n",
      "Val accuracy: 82.51428571428572\n",
      "Iter 123 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 124\n",
      "Train accuracy: 83.4095238095238\n",
      "Val accuracy: 82.55714285714286\n",
      "Iter 124 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 125\n",
      "Train accuracy: 83.44444444444444\n",
      "Val accuracy: 82.6\n",
      "Iter 125 -> sub iter 99 : 84.12698412698413\n",
      "Iteration: 126\n",
      "Train accuracy: 83.46190476190476\n",
      "Val accuracy: 82.62857142857143\n",
      "Iter 126 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 127\n",
      "Train accuracy: 83.49047619047619\n",
      "Val accuracy: 82.67142857142858\n",
      "Iter 127 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 128\n",
      "Train accuracy: 83.5079365079365\n",
      "Val accuracy: 82.71428571428572\n",
      "Iter 128 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 129\n",
      "Train accuracy: 83.53333333333333\n",
      "Val accuracy: 82.71428571428572\n",
      "Iter 129 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 130\n",
      "Train accuracy: 83.54920634920634\n",
      "Val accuracy: 82.71428571428572\n",
      "Iter 130 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 131\n",
      "Train accuracy: 83.57460317460318\n",
      "Val accuracy: 82.72857142857143\n",
      "Iter 131 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 132\n",
      "Train accuracy: 83.6015873015873\n",
      "Val accuracy: 82.78571428571428\n",
      "Iter 132 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 133\n",
      "Train accuracy: 83.62857142857143\n",
      "Val accuracy: 82.8\n",
      "Iter 133 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 134\n",
      "Train accuracy: 83.65714285714286\n",
      "Val accuracy: 82.81428571428572\n",
      "Iter 134 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 135\n",
      "Train accuracy: 83.67460317460318\n",
      "Val accuracy: 82.84285714285714\n",
      "Iter 135 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 136\n",
      "Train accuracy: 83.69682539682539\n",
      "Val accuracy: 82.85714285714286\n",
      "Iter 136 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 137\n",
      "Train accuracy: 83.72539682539683\n",
      "Val accuracy: 82.87142857142857\n",
      "Iter 137 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 138\n",
      "Train accuracy: 83.74444444444444\n",
      "Val accuracy: 82.88571428571429\n",
      "Iter 138 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 139\n",
      "Train accuracy: 83.75873015873016\n",
      "Val accuracy: 82.88571428571429\n",
      "Iter 139 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 140\n",
      "Train accuracy: 83.77619047619046\n",
      "Val accuracy: 82.88571428571429\n",
      "Iter 140 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 141\n",
      "Train accuracy: 83.7968253968254\n",
      "Val accuracy: 82.94285714285714\n",
      "Iter 141 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 142\n",
      "Train accuracy: 83.82063492063492\n",
      "Val accuracy: 82.95714285714286\n",
      "Iter 142 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 143\n",
      "Train accuracy: 83.83809523809524\n",
      "Val accuracy: 82.95714285714286\n",
      "Iter 143 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 144\n",
      "Train accuracy: 83.86190476190475\n",
      "Val accuracy: 82.97142857142858\n",
      "Iter 144 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 145\n",
      "Train accuracy: 83.88571428571429\n",
      "Val accuracy: 82.98571428571428\n",
      "Iter 145 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 146\n",
      "Train accuracy: 83.9031746031746\n",
      "Val accuracy: 83.01428571428572\n",
      "Iter 146 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 147\n",
      "Train accuracy: 83.91904761904762\n",
      "Val accuracy: 83.01428571428572\n",
      "Iter 147 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 148\n",
      "Train accuracy: 83.95238095238096\n",
      "Val accuracy: 83.0\n",
      "Iter 148 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 149\n",
      "Train accuracy: 83.97301587301588\n",
      "Val accuracy: 83.01428571428572\n",
      "Iter 149 -> sub iter 99 : 83.96825396825398\n",
      "Iteration: 150\n",
      "Train accuracy: 83.97460317460317\n",
      "Val accuracy: 83.04285714285714\n",
      "Training for 0.001\n",
      "Params Initialised\n",
      "Iter 0 -> sub iter 99 : 20.158730158730158\n",
      "Iteration: 1\n",
      "Train accuracy: 16.414285714285715\n",
      "Val accuracy: 15.814285714285713\n",
      "Iter 1 -> sub iter 99 : 30.158730158730158\n",
      "Iteration: 2\n",
      "Train accuracy: 27.836507936507935\n",
      "Val accuracy: 27.15714285714286\n",
      "Iter 2 -> sub iter 99 : 37.936507936507946\n",
      "Iteration: 3\n",
      "Train accuracy: 36.93015873015873\n",
      "Val accuracy: 36.15714285714286\n",
      "Iter 3 -> sub iter 99 : 44.285714285714285\n",
      "Iteration: 4\n",
      "Train accuracy: 42.15238095238095\n",
      "Val accuracy: 41.27142857142857\n",
      "Iter 4 -> sub iter 99 : 47.777777777777786\n",
      "Iteration: 5\n",
      "Train accuracy: 46.84285714285714\n",
      "Val accuracy: 45.92857142857143\n",
      "Iter 5 -> sub iter 99 : 51.904761904761914\n",
      "Iteration: 6\n",
      "Train accuracy: 51.34603174603175\n",
      "Val accuracy: 50.55714285714286\n",
      "Iter 6 -> sub iter 99 : 54.603174603174605\n",
      "Iteration: 7\n",
      "Train accuracy: 54.85079365079365\n",
      "Val accuracy: 53.51428571428571\n",
      "Iter 7 -> sub iter 99 : 56.825396825396824\n",
      "Iteration: 8\n",
      "Train accuracy: 57.369841269841274\n",
      "Val accuracy: 56.07142857142857\n",
      "Iter 8 -> sub iter 99 : 58.253968253968264\n",
      "Iteration: 9\n",
      "Train accuracy: 59.23492063492064\n",
      "Val accuracy: 57.8\n",
      "Iter 9 -> sub iter 99 : 59.841269841269844\n",
      "Iteration: 10\n",
      "Train accuracy: 60.663492063492065\n",
      "Val accuracy: 59.5\n",
      "Iter 10 -> sub iter 99 : 60.476190476190474\n",
      "Iteration: 11\n",
      "Train accuracy: 61.850793650793655\n",
      "Val accuracy: 60.785714285714285\n",
      "Iter 11 -> sub iter 99 : 61.587301587301596\n",
      "Iteration: 12\n",
      "Train accuracy: 62.790476190476184\n",
      "Val accuracy: 62.02857142857143\n",
      "Iter 12 -> sub iter 99 : 62.539682539682545\n",
      "Iteration: 13\n",
      "Train accuracy: 63.549206349206344\n",
      "Val accuracy: 62.94285714285714\n",
      "Iter 13 -> sub iter 99 : 63.492063492063495\n",
      "Iteration: 14\n",
      "Train accuracy: 64.18253968253968\n",
      "Val accuracy: 63.67142857142857\n",
      "Iter 14 -> sub iter 99 : 63.809523809523835\n",
      "Iteration: 15\n",
      "Train accuracy: 64.75555555555556\n",
      "Val accuracy: 64.24285714285715\n",
      "Iter 15 -> sub iter 99 : 64.603174603174615\n",
      "Iteration: 16\n",
      "Train accuracy: 65.28412698412698\n",
      "Val accuracy: 64.85714285714286\n",
      "Iter 16 -> sub iter 99 : 65.079365079365085\n",
      "Iteration: 17\n",
      "Train accuracy: 65.6952380952381\n",
      "Val accuracy: 65.18571428571428\n",
      "Iter 17 -> sub iter 99 : 66.031746031746024\n",
      "Iteration: 18\n",
      "Train accuracy: 66.10317460317461\n",
      "Val accuracy: 65.84285714285714\n",
      "Iter 18 -> sub iter 99 : 66.190476190476195\n",
      "Iteration: 19\n",
      "Train accuracy: 66.45555555555556\n",
      "Val accuracy: 66.17142857142856\n",
      "Iter 19 -> sub iter 99 : 66.507936507936514\n",
      "Iteration: 20\n",
      "Train accuracy: 66.79047619047618\n",
      "Val accuracy: 66.57142857142857\n",
      "Iter 20 -> sub iter 99 : 66.666666666666665\n",
      "Iteration: 21\n",
      "Train accuracy: 67.14126984126985\n",
      "Val accuracy: 66.8\n",
      "Iter 21 -> sub iter 99 : 66.666666666666665\n",
      "Iteration: 22\n",
      "Train accuracy: 67.43492063492063\n",
      "Val accuracy: 67.0\n",
      "Iter 22 -> sub iter 99 : 67.142857142857146\n",
      "Iteration: 23\n",
      "Train accuracy: 67.76507936507936\n",
      "Val accuracy: 67.31428571428572\n",
      "Iter 23 -> sub iter 99 : 67.460317460317474\n",
      "Iteration: 24\n",
      "Train accuracy: 68.03968253968254\n",
      "Val accuracy: 67.52857142857142\n",
      "Iter 24 -> sub iter 99 : 68.09523809523813\n",
      "Iteration: 25\n",
      "Train accuracy: 68.27619047619048\n",
      "Val accuracy: 67.92857142857143\n",
      "Iter 25 -> sub iter 99 : 68.25396825396825\n",
      "Iteration: 26\n",
      "Train accuracy: 68.53174603174604\n",
      "Val accuracy: 68.14285714285714\n",
      "Iter 26 -> sub iter 99 : 68.73015873015873\n",
      "Iteration: 27\n",
      "Train accuracy: 68.77301587301588\n",
      "Val accuracy: 68.27142857142857\n",
      "Iter 27 -> sub iter 99 : 69.20634920634922\n",
      "Iteration: 28\n",
      "Train accuracy: 68.98412698412699\n",
      "Val accuracy: 68.51428571428572\n",
      "Iter 28 -> sub iter 99 : 69.20634920634922\n",
      "Iteration: 29\n",
      "Train accuracy: 69.19047619047619\n",
      "Val accuracy: 68.77142857142857\n",
      "Iter 29 -> sub iter 99 : 69.36507936507937\n",
      "Iteration: 30\n",
      "Train accuracy: 69.39047619047619\n",
      "Val accuracy: 68.94285714285714\n",
      "Iter 30 -> sub iter 99 : 69.52380952380952\n",
      "Iteration: 31\n",
      "Train accuracy: 69.55238095238096\n",
      "Val accuracy: 69.07142857142857\n",
      "Iter 31 -> sub iter 99 : 70.15873015873015\n",
      "Iteration: 32\n",
      "Train accuracy: 69.72857142857143\n",
      "Val accuracy: 69.22857142857143\n",
      "Iter 32 -> sub iter 99 : 70.31746031746032\n",
      "Iteration: 33\n",
      "Train accuracy: 69.92063492063491\n",
      "Val accuracy: 69.32857142857142\n",
      "Iter 33 -> sub iter 99 : 70.47619047619048\n",
      "Iteration: 34\n",
      "Train accuracy: 70.0904761904762\n",
      "Val accuracy: 69.44285714285714\n",
      "Iter 34 -> sub iter 99 : 70.63492063492063\n",
      "Iteration: 35\n",
      "Train accuracy: 70.22380952380952\n",
      "Val accuracy: 69.69999999999999\n",
      "Iter 35 -> sub iter 99 : 70.63492063492063\n",
      "Iteration: 36\n",
      "Train accuracy: 70.36984126984127\n",
      "Val accuracy: 69.88571428571429\n",
      "Iter 36 -> sub iter 99 : 70.63492063492063\n",
      "Iteration: 37\n",
      "Train accuracy: 70.5\n",
      "Val accuracy: 69.98571428571428\n",
      "Iter 37 -> sub iter 99 : 70.95238095238095\n",
      "Iteration: 38\n",
      "Train accuracy: 70.63650793650794\n",
      "Val accuracy: 70.02857142857142\n",
      "Iter 38 -> sub iter 99 : 70.95238095238095\n",
      "Iteration: 39\n",
      "Train accuracy: 70.74126984126984\n",
      "Val accuracy: 70.11428571428571\n",
      "Iter 39 -> sub iter 99 : 70.95238095238095\n",
      "Iteration: 40\n",
      "Train accuracy: 70.84920634920636\n",
      "Val accuracy: 70.15714285714286\n",
      "Iter 40 -> sub iter 99 : 70.95238095238095\n",
      "Iteration: 41\n",
      "Train accuracy: 70.92539682539683\n",
      "Val accuracy: 70.3\n",
      "Iter 41 -> sub iter 99 : 70.95238095238095\n",
      "Iteration: 42\n",
      "Train accuracy: 71.02539682539683\n",
      "Val accuracy: 70.34285714285714\n",
      "Iter 42 -> sub iter 99 : 71.11111111111111\n",
      "Iteration: 43\n",
      "Train accuracy: 71.13650793650793\n",
      "Val accuracy: 70.39999999999999\n",
      "Iter 43 -> sub iter 99 : 71.11111111111111\n",
      "Iteration: 44\n",
      "Train accuracy: 71.22222222222221\n",
      "Val accuracy: 70.48571428571428\n",
      "Iter 44 -> sub iter 99 : 71.26984126984127\n",
      "Iteration: 45\n",
      "Train accuracy: 71.28730158730158\n",
      "Val accuracy: 70.55714285714285\n",
      "Iter 45 -> sub iter 99 : 71.58730158730158\n",
      "Iteration: 46\n",
      "Train accuracy: 71.36984126984127\n",
      "Val accuracy: 70.71428571428572\n",
      "Iter 46 -> sub iter 99 : 71.58730158730158\n",
      "Iteration: 47\n",
      "Train accuracy: 71.44603174603175\n",
      "Val accuracy: 70.84285714285714\n",
      "Iter 47 -> sub iter 99 : 71.74603174603175\n",
      "Iteration: 48\n",
      "Train accuracy: 71.5047619047619\n",
      "Val accuracy: 70.94285714285714\n",
      "Iter 48 -> sub iter 99 : 71.90476190476196\n",
      "Iteration: 49\n",
      "Train accuracy: 71.56825396825397\n",
      "Val accuracy: 70.98571428571428\n",
      "Iter 49 -> sub iter 99 : 71.90476190476193\n",
      "Iteration: 50\n",
      "Train accuracy: 71.615873015873\n",
      "Val accuracy: 71.02857142857142\n",
      "Iter 50 -> sub iter 99 : 71.74603174603175\n",
      "Iteration: 51\n",
      "Train accuracy: 71.67301587301587\n",
      "Val accuracy: 71.11428571428571\n",
      "Iter 51 -> sub iter 99 : 71.90476190476192\n",
      "Iteration: 52\n",
      "Train accuracy: 71.73650793650793\n",
      "Val accuracy: 71.21428571428572\n",
      "Iter 52 -> sub iter 99 : 71.90476190476192\n",
      "Iteration: 53\n",
      "Train accuracy: 71.8047619047619\n",
      "Val accuracy: 71.25714285714285\n",
      "Iter 53 -> sub iter 99 : 72.06349206349206\n",
      "Iteration: 54\n",
      "Train accuracy: 71.88253968253969\n",
      "Val accuracy: 71.28571428571429\n",
      "Iter 54 -> sub iter 99 : 72.06349206349206\n",
      "Iteration: 55\n",
      "Train accuracy: 71.96984126984127\n",
      "Val accuracy: 71.35714285714285\n",
      "Iter 55 -> sub iter 99 : 72.06349206349206\n",
      "Iteration: 56\n",
      "Train accuracy: 72.04126984126984\n",
      "Val accuracy: 71.35714285714285\n",
      "Iter 56 -> sub iter 99 : 72.06349206349206\n",
      "Iteration: 57\n",
      "Train accuracy: 72.0920634920635\n",
      "Val accuracy: 71.35714285714285\n",
      "Iter 57 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 58\n",
      "Train accuracy: 72.16984126984127\n",
      "Val accuracy: 71.41428571428573\n",
      "Iter 58 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 59\n",
      "Train accuracy: 72.22698412698414\n",
      "Val accuracy: 71.45714285714286\n",
      "Iter 59 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 60\n",
      "Train accuracy: 72.27936507936508\n",
      "Val accuracy: 71.55714285714285\n",
      "Iter 60 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 61\n",
      "Train accuracy: 72.33333333333334\n",
      "Val accuracy: 71.64285714285714\n",
      "Iter 61 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 62\n",
      "Train accuracy: 72.38888888888889\n",
      "Val accuracy: 71.68571428571428\n",
      "Iter 62 -> sub iter 99 : 72.53968253968253\n",
      "Iteration: 63\n",
      "Train accuracy: 72.45238095238096\n",
      "Val accuracy: 71.7\n",
      "Iter 63 -> sub iter 99 : 72.69841269841276\n",
      "Iteration: 64\n",
      "Train accuracy: 72.52222222222223\n",
      "Val accuracy: 71.75714285714285\n",
      "Iter 64 -> sub iter 99 : 72.85714285714285\n",
      "Iteration: 65\n",
      "Train accuracy: 72.59523809523809\n",
      "Val accuracy: 71.77142857142857\n",
      "Iter 65 -> sub iter 99 : 72.69841269841278\n",
      "Iteration: 66\n",
      "Train accuracy: 72.65079365079366\n",
      "Val accuracy: 71.82857142857144\n",
      "Iter 66 -> sub iter 99 : 72.85714285714285\n",
      "Iteration: 67\n",
      "Train accuracy: 72.73650793650793\n",
      "Val accuracy: 71.97142857142858\n",
      "Iter 67 -> sub iter 99 : 73.01587301587301\n",
      "Iteration: 68\n",
      "Train accuracy: 73.05396825396825\n",
      "Val accuracy: 72.27142857142857\n",
      "Iter 68 -> sub iter 99 : 75.39682539682539\n",
      "Iteration: 69\n",
      "Train accuracy: 74.32857142857144\n",
      "Val accuracy: 73.97142857142858\n",
      "Iter 69 -> sub iter 99 : 78.73015873015873\n",
      "Iteration: 70\n",
      "Train accuracy: 76.29206349206349\n",
      "Val accuracy: 75.61428571428571\n",
      "Iter 70 -> sub iter 99 : 79.36507936507937\n",
      "Iteration: 71\n",
      "Train accuracy: 77.46507936507938\n",
      "Val accuracy: 76.81428571428572\n",
      "Iter 71 -> sub iter 99 : 79.68253968253968\n",
      "Iteration: 72\n",
      "Train accuracy: 78.24126984126984\n",
      "Val accuracy: 77.54285714285714\n",
      "Iter 72 -> sub iter 99 : 80.31746031746032\n",
      "Iteration: 73\n",
      "Train accuracy: 78.8\n",
      "Val accuracy: 77.95714285714286\n",
      "Iter 73 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 74\n",
      "Train accuracy: 79.25555555555556\n",
      "Val accuracy: 78.38571428571429\n",
      "Iter 74 -> sub iter 99 : 80.63492063492063\n",
      "Iteration: 75\n",
      "Train accuracy: 79.56031746031746\n",
      "Val accuracy: 78.7\n",
      "Iter 75 -> sub iter 99 : 80.95238095238095\n",
      "Iteration: 76\n",
      "Train accuracy: 79.81428571428572\n",
      "Val accuracy: 78.95714285714286\n",
      "Iter 76 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 77\n",
      "Train accuracy: 79.98571428571428\n",
      "Val accuracy: 79.11428571428571\n",
      "Iter 77 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 78\n",
      "Train accuracy: 80.18571428571428\n",
      "Val accuracy: 79.34285714285714\n",
      "Iter 78 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 79\n",
      "Train accuracy: 80.33015873015873\n",
      "Val accuracy: 79.48571428571428\n",
      "Iter 79 -> sub iter 99 : 81.42857142857143\n",
      "Iteration: 80\n",
      "Train accuracy: 80.43492063492064\n",
      "Val accuracy: 79.60000000000001\n",
      "Iter 80 -> sub iter 99 : 81.26984126984127\n",
      "Iteration: 81\n",
      "Train accuracy: 80.56349206349206\n",
      "Val accuracy: 79.72857142857143\n",
      "Iter 81 -> sub iter 99 : 81.58730158730158\n",
      "Iteration: 82\n",
      "Train accuracy: 80.71428571428572\n",
      "Val accuracy: 79.82857142857142\n",
      "Iter 82 -> sub iter 99 : 81.74603174603175\n",
      "Iteration: 83\n",
      "Train accuracy: 80.80952380952381\n",
      "Val accuracy: 79.97142857142858\n",
      "Iter 83 -> sub iter 99 : 81.74603174603175\n",
      "Iteration: 84\n",
      "Train accuracy: 80.91904761904762\n",
      "Val accuracy: 80.07142857142857\n",
      "Iter 84 -> sub iter 99 : 81.90476190476199\n",
      "Iteration: 85\n",
      "Train accuracy: 81.0047619047619\n",
      "Val accuracy: 80.17142857142858\n",
      "Iter 85 -> sub iter 99 : 81.90476190476194\n",
      "Iteration: 86\n",
      "Train accuracy: 81.10952380952381\n",
      "Val accuracy: 80.30000000000001\n",
      "Iter 86 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 87\n",
      "Train accuracy: 81.17460317460318\n",
      "Val accuracy: 80.34285714285714\n",
      "Iter 87 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 88\n",
      "Train accuracy: 81.26031746031745\n",
      "Val accuracy: 80.42857142857143\n",
      "Iter 88 -> sub iter 99 : 82.38095238095238\n",
      "Iteration: 89\n",
      "Train accuracy: 81.33968253968254\n",
      "Val accuracy: 80.47142857142858\n",
      "Iter 89 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 90\n",
      "Train accuracy: 81.41428571428571\n",
      "Val accuracy: 80.51428571428572\n",
      "Iter 90 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 91\n",
      "Train accuracy: 81.48571428571428\n",
      "Val accuracy: 80.54285714285714\n",
      "Iter 91 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 92\n",
      "Train accuracy: 81.54444444444444\n",
      "Val accuracy: 80.55714285714286\n",
      "Iter 92 -> sub iter 99 : 82.53968253968253\n",
      "Iteration: 93\n",
      "Train accuracy: 81.6047619047619\n",
      "Val accuracy: 80.61428571428571\n",
      "Iter 93 -> sub iter 99 : 82.69841269841272\n",
      "Iteration: 94\n",
      "Train accuracy: 81.66984126984127\n",
      "Val accuracy: 80.62857142857143\n",
      "Iter 94 -> sub iter 99 : 82.85714285714286\n",
      "Iteration: 95\n",
      "Train accuracy: 81.72539682539683\n",
      "Val accuracy: 80.71428571428572\n",
      "Iter 95 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 96\n",
      "Train accuracy: 81.78730158730158\n",
      "Val accuracy: 80.77142857142857\n",
      "Iter 96 -> sub iter 99 : 82.85714285714286\n",
      "Iteration: 97\n",
      "Train accuracy: 81.83809523809525\n",
      "Val accuracy: 80.87142857142857\n",
      "Iter 97 -> sub iter 99 : 82.85714285714286\n",
      "Iteration: 98\n",
      "Train accuracy: 81.87619047619049\n",
      "Val accuracy: 80.87142857142857\n",
      "Iter 98 -> sub iter 99 : 82.85714285714286\n",
      "Iteration: 99\n",
      "Train accuracy: 81.93333333333334\n",
      "Val accuracy: 80.88571428571429\n",
      "Iter 99 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 100\n",
      "Train accuracy: 81.99047619047619\n",
      "Val accuracy: 80.91428571428571\n",
      "Iter 100 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 101\n",
      "Train accuracy: 82.02063492063492\n",
      "Val accuracy: 80.98571428571428\n",
      "Iter 101 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 102\n",
      "Train accuracy: 82.05873015873016\n",
      "Val accuracy: 81.0\n",
      "Iter 102 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 103\n",
      "Train accuracy: 82.11746031746033\n",
      "Val accuracy: 81.02857142857142\n",
      "Iter 103 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 104\n",
      "Train accuracy: 82.15714285714286\n",
      "Val accuracy: 81.05714285714286\n",
      "Iter 104 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 105\n",
      "Train accuracy: 82.1968253968254\n",
      "Val accuracy: 81.11428571428571\n",
      "Iter 105 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 106\n",
      "Train accuracy: 82.24285714285713\n",
      "Val accuracy: 81.15714285714286\n",
      "Iter 106 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 107\n",
      "Train accuracy: 82.28412698412698\n",
      "Val accuracy: 81.18571428571428\n",
      "Iter 107 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 108\n",
      "Train accuracy: 82.32857142857142\n",
      "Val accuracy: 81.17142857142858\n",
      "Iter 108 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 109\n",
      "Train accuracy: 82.37619047619049\n",
      "Val accuracy: 81.22857142857143\n",
      "Iter 109 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 110\n",
      "Train accuracy: 82.41746031746032\n",
      "Val accuracy: 81.25714285714287\n",
      "Iter 110 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 111\n",
      "Train accuracy: 82.46190476190476\n",
      "Val accuracy: 81.28571428571428\n",
      "Iter 111 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 112\n",
      "Train accuracy: 82.4952380952381\n",
      "Val accuracy: 81.27142857142857\n",
      "Iter 112 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 113\n",
      "Train accuracy: 82.53015873015873\n",
      "Val accuracy: 81.35714285714286\n",
      "Iter 113 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 114\n",
      "Train accuracy: 82.55396825396826\n",
      "Val accuracy: 81.35714285714286\n",
      "Iter 114 -> sub iter 99 : 83.01587301587303\n",
      "Iteration: 115\n",
      "Train accuracy: 82.6015873015873\n",
      "Val accuracy: 81.35714285714286\n",
      "Iter 115 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 116\n",
      "Train accuracy: 82.63174603174603\n",
      "Val accuracy: 81.39999999999999\n",
      "Iter 116 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 117\n",
      "Train accuracy: 82.67142857142858\n",
      "Val accuracy: 81.42857142857143\n",
      "Iter 117 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 118\n",
      "Train accuracy: 82.7031746031746\n",
      "Val accuracy: 81.47142857142858\n",
      "Iter 118 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 119\n",
      "Train accuracy: 82.72222222222221\n",
      "Val accuracy: 81.48571428571428\n",
      "Iter 119 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 120\n",
      "Train accuracy: 82.74603174603175\n",
      "Val accuracy: 81.52857142857142\n",
      "Iter 120 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 121\n",
      "Train accuracy: 82.77460317460317\n",
      "Val accuracy: 81.57142857142857\n",
      "Iter 121 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 122\n",
      "Train accuracy: 82.79841269841269\n",
      "Val accuracy: 81.58571428571429\n",
      "Iter 122 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 123\n",
      "Train accuracy: 82.82380952380952\n",
      "Val accuracy: 81.6\n",
      "Iter 123 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 124\n",
      "Train accuracy: 82.86825396825397\n",
      "Val accuracy: 81.61428571428571\n",
      "Iter 124 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 125\n",
      "Train accuracy: 82.88412698412698\n",
      "Val accuracy: 81.62857142857143\n",
      "Iter 125 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 126\n",
      "Train accuracy: 82.91111111111111\n",
      "Val accuracy: 81.64285714285714\n",
      "Iter 126 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 127\n",
      "Train accuracy: 82.93174603174603\n",
      "Val accuracy: 81.64285714285714\n",
      "Iter 127 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 128\n",
      "Train accuracy: 82.94920634920635\n",
      "Val accuracy: 81.65714285714286\n",
      "Iter 128 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 129\n",
      "Train accuracy: 82.98253968253968\n",
      "Val accuracy: 81.68571428571428\n",
      "Iter 129 -> sub iter 99 : 83.17460317460318\n",
      "Iteration: 130\n",
      "Train accuracy: 83.01746031746032\n",
      "Val accuracy: 81.67142857142858\n",
      "Iter 130 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 131\n",
      "Train accuracy: 83.03968253968253\n",
      "Val accuracy: 81.71428571428572\n",
      "Iter 131 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 132\n",
      "Train accuracy: 83.06825396825397\n",
      "Val accuracy: 81.72857142857143\n",
      "Iter 132 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 133\n",
      "Train accuracy: 83.0952380952381\n",
      "Val accuracy: 81.75714285714287\n",
      "Iter 133 -> sub iter 99 : 83.33333333333334\n",
      "Iteration: 134\n",
      "Train accuracy: 83.12698412698413\n",
      "Val accuracy: 81.77142857142857\n",
      "Iter 134 -> sub iter 99 : 83.49206349206359\n",
      "Iteration: 135\n",
      "Train accuracy: 83.15714285714286\n",
      "Val accuracy: 81.78571428571428\n",
      "Iter 135 -> sub iter 99 : 83.49206349206359\n",
      "Iteration: 136\n",
      "Train accuracy: 83.18412698412698\n",
      "Val accuracy: 81.78571428571428\n",
      "Iter 136 -> sub iter 99 : 83.49206349206359\n",
      "Iteration: 137\n",
      "Train accuracy: 83.1984126984127\n",
      "Val accuracy: 81.82857142857142\n",
      "Iter 137 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 138\n",
      "Train accuracy: 83.21904761904761\n",
      "Val accuracy: 81.88571428571429\n",
      "Iter 138 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 139\n",
      "Train accuracy: 83.23968253968253\n",
      "Val accuracy: 81.92857142857143\n",
      "Iter 139 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 140\n",
      "Train accuracy: 83.27460317460319\n",
      "Val accuracy: 81.97142857142858\n",
      "Iter 140 -> sub iter 99 : 83.49206349206356\n",
      "Iteration: 141\n",
      "Train accuracy: 83.3015873015873\n",
      "Val accuracy: 82.04285714285714\n",
      "Iter 141 -> sub iter 99 : 83.49206349206351\n",
      "Iteration: 142\n",
      "Train accuracy: 83.32698412698413\n",
      "Val accuracy: 82.07142857142857\n",
      "Iter 142 -> sub iter 99 : 83.49206349206357\n",
      "Iteration: 143\n",
      "Train accuracy: 83.34444444444445\n",
      "Val accuracy: 82.12857142857143\n",
      "Iter 143 -> sub iter 99 : 83.49206349206357\n",
      "Iteration: 144\n",
      "Train accuracy: 83.36031746031746\n",
      "Val accuracy: 82.17142857142858\n",
      "Iter 144 -> sub iter 99 : 83.49206349206357\n",
      "Iteration: 145\n",
      "Train accuracy: 83.38888888888889\n",
      "Val accuracy: 82.18571428571428\n",
      "Iter 145 -> sub iter 99 : 83.49206349206357\n",
      "Iteration: 146\n",
      "Train accuracy: 83.40793650793651\n",
      "Val accuracy: 82.19999999999999\n",
      "Iter 146 -> sub iter 99 : 83.49206349206357\n",
      "Iteration: 147\n",
      "Train accuracy: 83.43015873015874\n",
      "Val accuracy: 82.19999999999999\n",
      "Iter 147 -> sub iter 99 : 83.49206349206357\n",
      "Iteration: 148\n",
      "Train accuracy: 83.45555555555556\n",
      "Val accuracy: 82.22857142857143\n",
      "Iter 148 -> sub iter 99 : 83.49206349206352\n",
      "Iteration: 149\n",
      "Train accuracy: 83.47777777777777\n",
      "Val accuracy: 82.25714285714287\n",
      "Iter 149 -> sub iter 99 : 83.49206349206352\n",
      "Iteration: 150\n",
      "Train accuracy: 83.4920634920635\n",
      "Val accuracy: 82.27142857142857\n",
      "Training for 0.0001\n",
      "Params Initialised\n",
      "Iter 0 -> sub iter 99 : 21.904761904761905\n",
      "Iteration: 1\n",
      "Train accuracy: 22.957142857142856\n",
      "Val accuracy: 24.22857142857143\n",
      "Iter 1 -> sub iter 99 : 27.777777777777785\n",
      "Iteration: 2\n",
      "Train accuracy: 29.887301587301586\n",
      "Val accuracy: 31.157142857142855\n",
      "Iter 2 -> sub iter 99 : 31.904761904761975\n",
      "Iteration: 3\n",
      "Train accuracy: 34.33968253968254\n",
      "Val accuracy: 35.65714285714286\n",
      "Iter 3 -> sub iter 99 : 38.571428571428584\n",
      "Iteration: 4\n",
      "Train accuracy: 39.353968253968254\n",
      "Val accuracy: 40.87142857142857\n",
      "Iter 4 -> sub iter 99 : 41.111111111111116\n",
      "Iteration: 5\n",
      "Train accuracy: 42.35714285714286\n",
      "Val accuracy: 43.9\n",
      "Iter 5 -> sub iter 99 : 42.539682539682546\n",
      "Iteration: 6\n",
      "Train accuracy: 44.34603174603174\n",
      "Val accuracy: 46.1\n",
      "Iter 6 -> sub iter 99 : 44.603174603174614\n",
      "Iteration: 7\n",
      "Train accuracy: 45.76190476190476\n",
      "Val accuracy: 47.599999999999994\n",
      "Iter 7 -> sub iter 99 : 46.031746031746034\n",
      "Iteration: 8\n",
      "Train accuracy: 46.68571428571428\n",
      "Val accuracy: 48.22857142857143\n",
      "Iter 8 -> sub iter 99 : 46.825396825396824\n",
      "Iteration: 9\n",
      "Train accuracy: 47.41746031746032\n",
      "Val accuracy: 48.871428571428574\n",
      "Iter 9 -> sub iter 99 : 48.095238095238095\n",
      "Iteration: 10\n",
      "Train accuracy: 48.03809523809524\n",
      "Val accuracy: 49.542857142857144\n",
      "Iter 10 -> sub iter 99 : 48.253968253968254\n",
      "Iteration: 11\n",
      "Train accuracy: 48.53174603174603\n",
      "Val accuracy: 49.81428571428572\n",
      "Iter 11 -> sub iter 99 : 48.253968253968254\n",
      "Iteration: 12\n",
      "Train accuracy: 48.94761904761904\n",
      "Val accuracy: 50.24285714285715\n",
      "Iter 12 -> sub iter 99 : 48.571428571428575\n",
      "Iteration: 13\n",
      "Train accuracy: 49.32857142857143\n",
      "Val accuracy: 50.5\n",
      "Iter 13 -> sub iter 99 : 49.206349206349296\n",
      "Iteration: 14\n",
      "Train accuracy: 49.71111111111111\n",
      "Val accuracy: 50.91428571428571\n",
      "Iter 14 -> sub iter 99 : 49.841269841269844\n",
      "Iteration: 15\n",
      "Train accuracy: 50.00476190476191\n",
      "Val accuracy: 51.28571428571429\n",
      "Iter 15 -> sub iter 99 : 49.841269841269844\n",
      "Iteration: 16\n",
      "Train accuracy: 50.3111111111111\n",
      "Val accuracy: 51.4\n",
      "Iter 16 -> sub iter 99 : 50.317460317460316\n",
      "Iteration: 17\n",
      "Train accuracy: 50.56349206349206\n",
      "Val accuracy: 51.72857142857142\n",
      "Iter 17 -> sub iter 99 : 50.476190476190474\n",
      "Iteration: 18\n",
      "Train accuracy: 50.7984126984127\n",
      "Val accuracy: 52.028571428571425\n",
      "Iter 18 -> sub iter 99 : 50.476190476190474\n",
      "Iteration: 19\n",
      "Train accuracy: 51.01269841269841\n",
      "Val accuracy: 52.214285714285715\n",
      "Iter 19 -> sub iter 99 : 50.158730158730165\n",
      "Iteration: 20\n",
      "Train accuracy: 51.217460317460315\n",
      "Val accuracy: 52.51428571428571\n",
      "Iter 20 -> sub iter 99 : 50.158730158730164\n",
      "Iteration: 21\n",
      "Train accuracy: 51.42539682539683\n",
      "Val accuracy: 52.65714285714286\n",
      "Iter 21 -> sub iter 99 : 50.317460317460316\n",
      "Iteration: 22\n",
      "Train accuracy: 51.65238095238095\n",
      "Val accuracy: 52.87142857142857\n",
      "Iter 22 -> sub iter 99 : 50.476190476190474\n",
      "Iteration: 23\n",
      "Train accuracy: 51.866666666666674\n",
      "Val accuracy: 53.128571428571426\n",
      "Iter 23 -> sub iter 99 : 50.952380952380956\n",
      "Iteration: 24\n",
      "Train accuracy: 52.05714285714286\n",
      "Val accuracy: 53.38571428571428\n",
      "Iter 24 -> sub iter 99 : 51.428571428571426\n",
      "Iteration: 25\n",
      "Train accuracy: 52.23174603174603\n",
      "Val accuracy: 53.57142857142857\n",
      "Iter 25 -> sub iter 99 : 51.428571428571426\n",
      "Iteration: 26\n",
      "Train accuracy: 52.38095238095239\n",
      "Val accuracy: 53.7\n",
      "Iter 26 -> sub iter 99 : 51.587301587301596\n",
      "Iteration: 27\n",
      "Train accuracy: 52.549206349206344\n",
      "Val accuracy: 53.800000000000004\n",
      "Iter 27 -> sub iter 99 : 51.746031746031754\n",
      "Iteration: 28\n",
      "Train accuracy: 52.7079365079365\n",
      "Val accuracy: 54.0\n",
      "Iter 28 -> sub iter 99 : 51.746031746031754\n",
      "Iteration: 29\n",
      "Train accuracy: 52.84920634920635\n",
      "Val accuracy: 54.142857142857146\n",
      "Iter 29 -> sub iter 99 : 51.904761904761914\n",
      "Iteration: 30\n",
      "Train accuracy: 52.957142857142856\n",
      "Val accuracy: 54.27142857142857\n",
      "Iter 30 -> sub iter 99 : 51.904761904761914\n",
      "Iteration: 31\n",
      "Train accuracy: 53.07777777777778\n",
      "Val accuracy: 54.371428571428574\n",
      "Iter 31 -> sub iter 99 : 52.222222222222234\n",
      "Iteration: 32\n",
      "Train accuracy: 53.20952380952381\n",
      "Val accuracy: 54.51428571428571\n",
      "Iter 32 -> sub iter 99 : 52.222222222222235\n",
      "Iteration: 33\n",
      "Train accuracy: 53.31428571428572\n",
      "Val accuracy: 54.65714285714286\n",
      "Iter 33 -> sub iter 99 : 52.539682539682545\n",
      "Iteration: 34\n",
      "Train accuracy: 53.42857142857142\n",
      "Val accuracy: 54.75714285714286\n",
      "Iter 34 -> sub iter 99 : 52.539682539682545\n",
      "Iteration: 35\n",
      "Train accuracy: 53.51904761904762\n",
      "Val accuracy: 54.95714285714286\n",
      "Iter 35 -> sub iter 99 : 52.698412698412785\n",
      "Iteration: 36\n",
      "Train accuracy: 53.642857142857146\n",
      "Val accuracy: 55.01428571428571\n",
      "Iter 36 -> sub iter 99 : 52.698412698412746\n",
      "Iteration: 37\n",
      "Train accuracy: 53.73015873015873\n",
      "Val accuracy: 55.08571428571428\n",
      "Iter 37 -> sub iter 99 : 52.698412698412746\n",
      "Iteration: 38\n",
      "Train accuracy: 53.78571428571428\n",
      "Val accuracy: 55.22857142857143\n",
      "Iter 38 -> sub iter 99 : 52.857142857142865\n",
      "Iteration: 39\n",
      "Train accuracy: 53.86825396825397\n",
      "Val accuracy: 55.371428571428574\n",
      "Iter 39 -> sub iter 99 : 52.857142857142866\n",
      "Iteration: 40\n",
      "Train accuracy: 53.955555555555556\n",
      "Val accuracy: 55.385714285714286\n",
      "Iter 40 -> sub iter 99 : 53.174603174603184\n",
      "Iteration: 41\n",
      "Train accuracy: 54.03174603174603\n",
      "Val accuracy: 55.471428571428575\n",
      "Iter 41 -> sub iter 99 : 53.174603174603186\n",
      "Iteration: 42\n",
      "Train accuracy: 54.1\n",
      "Val accuracy: 55.58571428571428\n",
      "Iter 42 -> sub iter 99 : 53.492063492063494\n",
      "Iteration: 43\n",
      "Train accuracy: 54.179365079365084\n",
      "Val accuracy: 55.68571428571428\n",
      "Iter 43 -> sub iter 99 : 53.650793650793654\n",
      "Iteration: 44\n",
      "Train accuracy: 54.250793650793646\n",
      "Val accuracy: 55.74285714285714\n",
      "Iter 44 -> sub iter 99 : 53.809523809523814\n",
      "Iteration: 45\n",
      "Train accuracy: 54.31587301587302\n",
      "Val accuracy: 55.84285714285714\n",
      "Iter 45 -> sub iter 99 : 53.809523809523814\n",
      "Iteration: 46\n",
      "Train accuracy: 54.37777777777778\n",
      "Val accuracy: 55.871428571428574\n",
      "Iter 46 -> sub iter 99 : 53.968253968253975\n",
      "Iteration: 47\n",
      "Train accuracy: 54.44126984126984\n",
      "Val accuracy: 55.91428571428572\n",
      "Iter 47 -> sub iter 99 : 53.968253968253975\n",
      "Iteration: 48\n",
      "Train accuracy: 54.50000000000001\n",
      "Val accuracy: 56.04285714285714\n",
      "Iter 48 -> sub iter 99 : 53.968253968253975\n",
      "Iteration: 49\n",
      "Train accuracy: 54.541269841269845\n",
      "Val accuracy: 56.04285714285714\n",
      "Iter 49 -> sub iter 99 : 53.968253968253975\n",
      "Iteration: 50\n",
      "Train accuracy: 54.6063492063492\n",
      "Val accuracy: 56.128571428571426\n",
      "Iter 50 -> sub iter 99 : 53.968253968253976\n",
      "Iteration: 51\n",
      "Train accuracy: 54.646031746031746\n",
      "Val accuracy: 56.15714285714286\n",
      "Iter 51 -> sub iter 99 : 54.126984126984136\n",
      "Iteration: 52\n",
      "Train accuracy: 54.68730158730158\n",
      "Val accuracy: 56.214285714285715\n",
      "Iter 52 -> sub iter 99 : 54.285714285714285\n",
      "Iteration: 53\n",
      "Train accuracy: 54.72380952380952\n",
      "Val accuracy: 56.27142857142857\n",
      "Iter 53 -> sub iter 99 : 54.444444444444446\n",
      "Iteration: 54\n",
      "Train accuracy: 54.75714285714286\n",
      "Val accuracy: 56.34285714285714\n",
      "Iter 54 -> sub iter 99 : 54.444444444444446\n",
      "Iteration: 55\n",
      "Train accuracy: 54.801587301587304\n",
      "Val accuracy: 56.385714285714286\n",
      "Iter 55 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 56\n",
      "Train accuracy: 54.82857142857143\n",
      "Val accuracy: 56.41428571428572\n",
      "Iter 56 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 57\n",
      "Train accuracy: 54.87301587301587\n",
      "Val accuracy: 56.385714285714286\n",
      "Iter 57 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 58\n",
      "Train accuracy: 54.919047619047625\n",
      "Val accuracy: 56.41428571428572\n",
      "Iter 58 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 59\n",
      "Train accuracy: 54.96507936507936\n",
      "Val accuracy: 56.442857142857136\n",
      "Iter 59 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 60\n",
      "Train accuracy: 55.00158730158731\n",
      "Val accuracy: 56.49999999999999\n",
      "Iter 60 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 61\n",
      "Train accuracy: 55.05238095238095\n",
      "Val accuracy: 56.51428571428572\n",
      "Iter 61 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 62\n",
      "Train accuracy: 55.093650793650795\n",
      "Val accuracy: 56.528571428571425\n",
      "Iter 62 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 63\n",
      "Train accuracy: 55.141269841269846\n",
      "Val accuracy: 56.557142857142864\n",
      "Iter 63 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 64\n",
      "Train accuracy: 55.18253968253968\n",
      "Val accuracy: 56.58571428571428\n",
      "Iter 64 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 65\n",
      "Train accuracy: 55.21904761904762\n",
      "Val accuracy: 56.614285714285714\n",
      "Iter 65 -> sub iter 99 : 54.761904761904766\n",
      "Iteration: 66\n",
      "Train accuracy: 55.24444444444444\n",
      "Val accuracy: 56.614285714285714\n",
      "Iter 66 -> sub iter 99 : 54.920634920634924\n",
      "Iteration: 67\n",
      "Train accuracy: 55.269841269841265\n",
      "Val accuracy: 56.67142857142857\n",
      "Iter 67 -> sub iter 99 : 55.079365079365084\n",
      "Iteration: 68\n",
      "Train accuracy: 55.304761904761904\n",
      "Val accuracy: 56.714285714285715\n",
      "Iter 68 -> sub iter 99 : 55.079365079365084\n",
      "Iteration: 69\n",
      "Train accuracy: 55.33968253968254\n",
      "Val accuracy: 56.74285714285714\n",
      "Iter 69 -> sub iter 99 : 55.079365079365084\n",
      "Iteration: 70\n",
      "Train accuracy: 55.37460317460317\n",
      "Val accuracy: 56.81428571428572\n",
      "Iter 70 -> sub iter 99 : 55.238095238095244\n",
      "Iteration: 71\n",
      "Train accuracy: 55.4031746031746\n",
      "Val accuracy: 56.84285714285714\n",
      "Iter 71 -> sub iter 99 : 55.396825396825435\n",
      "Iteration: 72\n",
      "Train accuracy: 55.43492063492064\n",
      "Val accuracy: 56.871428571428574\n",
      "Iter 72 -> sub iter 99 : 55.396825396825434\n",
      "Iteration: 73\n",
      "Train accuracy: 55.474603174603175\n",
      "Val accuracy: 56.89999999999999\n",
      "Iter 73 -> sub iter 99 : 55.396825396825436\n",
      "Iteration: 74\n",
      "Train accuracy: 55.4952380952381\n",
      "Val accuracy: 56.91428571428572\n",
      "Iter 74 -> sub iter 99 : 55.396825396825436\n",
      "Iteration: 75\n",
      "Train accuracy: 55.52222222222222\n",
      "Val accuracy: 56.92857142857143\n",
      "Iter 75 -> sub iter 99 : 55.396825396825476\n",
      "Iteration: 76\n",
      "Train accuracy: 55.55238095238095\n",
      "Val accuracy: 56.91428571428572\n",
      "Iter 76 -> sub iter 99 : 55.396825396825476\n",
      "Iteration: 77\n",
      "Train accuracy: 55.574603174603176\n",
      "Val accuracy: 56.98571428571428\n",
      "Iter 77 -> sub iter 99 : 55.396825396825476\n",
      "Iteration: 78\n",
      "Train accuracy: 55.6063492063492\n",
      "Val accuracy: 56.99999999999999\n",
      "Iter 78 -> sub iter 99 : 55.396825396825476\n",
      "Iteration: 79\n",
      "Train accuracy: 55.62222222222222\n",
      "Val accuracy: 57.028571428571425\n",
      "Iter 79 -> sub iter 99 : 55.396825396825475\n",
      "Iteration: 80\n",
      "Train accuracy: 55.63809523809524\n",
      "Val accuracy: 57.04285714285714\n",
      "Iter 80 -> sub iter 99 : 55.396825396825475\n",
      "Iteration: 81\n",
      "Train accuracy: 55.65714285714286\n",
      "Val accuracy: 57.08571428571428\n",
      "Iter 81 -> sub iter 99 : 55.396825396825475\n",
      "Iteration: 82\n",
      "Train accuracy: 55.68730158730158\n",
      "Val accuracy: 57.08571428571428\n",
      "Iter 82 -> sub iter 99 : 55.396825396825475\n",
      "Iteration: 83\n",
      "Train accuracy: 55.70952380952381\n",
      "Val accuracy: 57.08571428571428\n",
      "Iter 83 -> sub iter 99 : 55.396825396825475\n",
      "Iteration: 84\n",
      "Train accuracy: 55.72380952380952\n",
      "Val accuracy: 57.15714285714286\n",
      "Iter 84 -> sub iter 99 : 55.396825396825475\n",
      "Iteration: 85\n",
      "Train accuracy: 55.73968253968255\n",
      "Val accuracy: 57.17142857142857\n",
      "Iter 85 -> sub iter 99 : 55.396825396825474\n",
      "Iteration: 86\n",
      "Train accuracy: 55.76190476190476\n",
      "Val accuracy: 57.18571428571428\n",
      "Iter 86 -> sub iter 99 : 55.396825396825476\n",
      "Iteration: 87\n",
      "Train accuracy: 55.78412698412698\n",
      "Val accuracy: 57.214285714285715\n",
      "Iter 87 -> sub iter 99 : 55.396825396825474\n",
      "Iteration: 88\n",
      "Train accuracy: 55.7952380952381\n",
      "Val accuracy: 57.214285714285715\n",
      "Iter 88 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 89\n",
      "Train accuracy: 55.80952380952381\n",
      "Val accuracy: 57.24285714285714\n",
      "Iter 89 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 90\n",
      "Train accuracy: 55.822222222222216\n",
      "Val accuracy: 57.25714285714286\n",
      "Iter 90 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 91\n",
      "Train accuracy: 55.83968253968254\n",
      "Val accuracy: 57.27142857142857\n",
      "Iter 91 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 92\n",
      "Train accuracy: 55.85555555555556\n",
      "Val accuracy: 57.285714285714285\n",
      "Iter 92 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 93\n",
      "Train accuracy: 55.87777777777778\n",
      "Val accuracy: 57.3\n",
      "Iter 93 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 94\n",
      "Train accuracy: 55.888888888888886\n",
      "Val accuracy: 57.3\n",
      "Iter 94 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 95\n",
      "Train accuracy: 55.907936507936505\n",
      "Val accuracy: 57.32857142857143\n",
      "Iter 95 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 96\n",
      "Train accuracy: 55.919047619047625\n",
      "Val accuracy: 57.371428571428574\n",
      "Iter 96 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 97\n",
      "Train accuracy: 55.93015873015873\n",
      "Val accuracy: 57.385714285714286\n",
      "Iter 97 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 98\n",
      "Train accuracy: 55.941269841269836\n",
      "Val accuracy: 57.44285714285714\n",
      "Iter 98 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 99\n",
      "Train accuracy: 55.94920634920635\n",
      "Val accuracy: 57.45714285714286\n",
      "Iter 99 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 100\n",
      "Train accuracy: 55.96666666666666\n",
      "Val accuracy: 57.45714285714286\n",
      "Iter 100 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 101\n",
      "Train accuracy: 55.98888888888889\n",
      "Val accuracy: 57.48571428571429\n",
      "Iter 101 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 102\n",
      "Train accuracy: 56.007936507936506\n",
      "Val accuracy: 57.48571428571429\n",
      "Iter 102 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 103\n",
      "Train accuracy: 56.019047619047626\n",
      "Val accuracy: 57.48571428571429\n",
      "Iter 103 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 104\n",
      "Train accuracy: 56.03174603174603\n",
      "Val accuracy: 57.49999999999999\n",
      "Iter 104 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 105\n",
      "Train accuracy: 56.046031746031744\n",
      "Val accuracy: 57.51428571428572\n",
      "Iter 105 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 106\n",
      "Train accuracy: 56.06666666666666\n",
      "Val accuracy: 57.54285714285714\n",
      "Iter 106 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 107\n",
      "Train accuracy: 56.092063492063495\n",
      "Val accuracy: 57.557142857142864\n",
      "Iter 107 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 108\n",
      "Train accuracy: 56.1031746031746\n",
      "Val accuracy: 57.557142857142864\n",
      "Iter 108 -> sub iter 99 : 55.555555555555565\n",
      "Iteration: 109\n",
      "Train accuracy: 56.12380952380952\n",
      "Val accuracy: 57.57142857142858\n",
      "Iter 109 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 110\n",
      "Train accuracy: 56.14285714285714\n",
      "Val accuracy: 57.58571428571428\n",
      "Iter 110 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 111\n",
      "Train accuracy: 56.15555555555556\n",
      "Val accuracy: 57.58571428571428\n",
      "Iter 111 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 112\n",
      "Train accuracy: 56.18253968253968\n",
      "Val accuracy: 57.58571428571428\n",
      "Iter 112 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 113\n",
      "Train accuracy: 56.19047619047619\n",
      "Val accuracy: 57.61428571428572\n",
      "Iter 113 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 114\n",
      "Train accuracy: 56.2047619047619\n",
      "Val accuracy: 57.64285714285714\n",
      "Iter 114 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 115\n",
      "Train accuracy: 56.21587301587302\n",
      "Val accuracy: 57.64285714285714\n",
      "Iter 115 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 116\n",
      "Train accuracy: 56.23650793650794\n",
      "Val accuracy: 57.657142857142865\n",
      "Iter 116 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 117\n",
      "Train accuracy: 56.25238095238095\n",
      "Val accuracy: 57.67142857142857\n",
      "Iter 117 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 118\n",
      "Train accuracy: 56.268253968253966\n",
      "Val accuracy: 57.68571428571428\n",
      "Iter 118 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 119\n",
      "Train accuracy: 56.29206349206349\n",
      "Val accuracy: 57.699999999999996\n",
      "Iter 119 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 120\n",
      "Train accuracy: 56.3031746031746\n",
      "Val accuracy: 57.67142857142857\n",
      "Iter 120 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 121\n",
      "Train accuracy: 56.31587301587302\n",
      "Val accuracy: 57.67142857142857\n",
      "Iter 121 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 122\n",
      "Train accuracy: 56.33015873015873\n",
      "Val accuracy: 57.699999999999996\n",
      "Iter 122 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 123\n",
      "Train accuracy: 56.34603174603174\n",
      "Val accuracy: 57.699999999999996\n",
      "Iter 123 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 124\n",
      "Train accuracy: 56.353968253968254\n",
      "Val accuracy: 57.714285714285715\n",
      "Iter 124 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 125\n",
      "Train accuracy: 56.35714285714286\n",
      "Val accuracy: 57.699999999999996\n",
      "Iter 125 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 126\n",
      "Train accuracy: 56.36190476190476\n",
      "Val accuracy: 57.699999999999996\n",
      "Iter 126 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 127\n",
      "Train accuracy: 56.371428571428574\n",
      "Val accuracy: 57.714285714285715\n",
      "Iter 127 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 128\n",
      "Train accuracy: 56.38253968253968\n",
      "Val accuracy: 57.74285714285714\n",
      "Iter 128 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 129\n",
      "Train accuracy: 56.3968253968254\n",
      "Val accuracy: 57.77142857142857\n",
      "Iter 129 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 130\n",
      "Train accuracy: 56.4015873015873\n",
      "Val accuracy: 57.785714285714285\n",
      "Iter 130 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 131\n",
      "Train accuracy: 56.41111111111111\n",
      "Val accuracy: 57.8\n",
      "Iter 131 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 132\n",
      "Train accuracy: 56.423809523809524\n",
      "Val accuracy: 57.8\n",
      "Iter 132 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 133\n",
      "Train accuracy: 56.426984126984124\n",
      "Val accuracy: 57.8\n",
      "Iter 133 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 134\n",
      "Train accuracy: 56.442857142857136\n",
      "Val accuracy: 57.82857142857143\n",
      "Iter 134 -> sub iter 99 : 55.555555555555566\n",
      "Iteration: 135\n",
      "Train accuracy: 56.44603174603174\n",
      "Val accuracy: 57.81428571428572\n",
      "Iter 135 -> sub iter 99 : 55.396825396825436\n",
      "Iteration: 136\n",
      "Train accuracy: 56.45873015873016\n",
      "Val accuracy: 57.81428571428572\n",
      "Iter 136 -> sub iter 99 : 55.396825396825434\n",
      "Iteration: 137\n",
      "Train accuracy: 56.461904761904755\n",
      "Val accuracy: 57.82857142857143\n",
      "Iter 137 -> sub iter 99 : 55.396825396825434\n",
      "Iteration: 138\n",
      "Train accuracy: 56.46984126984127\n",
      "Val accuracy: 57.82857142857143\n",
      "Iter 138 -> sub iter 99 : 55.396825396825434\n",
      "Iteration: 139\n",
      "Train accuracy: 56.48253968253968\n",
      "Val accuracy: 57.84285714285714\n",
      "Iter 139 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 140\n",
      "Train accuracy: 56.48412698412698\n",
      "Val accuracy: 57.871428571428574\n",
      "Iter 140 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 141\n",
      "Train accuracy: 56.48888888888889\n",
      "Val accuracy: 57.885714285714286\n",
      "Iter 141 -> sub iter 99 : 55.555555555555564\n",
      "Iteration: 142\n",
      "Train accuracy: 56.5031746031746\n",
      "Val accuracy: 57.91428571428572\n",
      "Iter 142 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 143\n",
      "Train accuracy: 56.50952380952381\n",
      "Val accuracy: 57.92857142857143\n",
      "Iter 143 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 144\n",
      "Train accuracy: 56.51587301587302\n",
      "Val accuracy: 57.91428571428572\n",
      "Iter 144 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 145\n",
      "Train accuracy: 56.52063492063492\n",
      "Val accuracy: 57.91428571428572\n",
      "Iter 145 -> sub iter 99 : 55.714285714285715\n",
      "Iteration: 146\n",
      "Train accuracy: 56.526984126984125\n",
      "Val accuracy: 57.92857142857143\n",
      "Iter 146 -> sub iter 99 : 55.873015873015874\n",
      "Iteration: 147\n",
      "Train accuracy: 56.528571428571425\n",
      "Val accuracy: 57.92857142857143\n",
      "Iter 147 -> sub iter 99 : 55.873015873015874\n",
      "Iteration: 148\n",
      "Train accuracy: 56.53650793650794\n",
      "Val accuracy: 57.92857142857143\n",
      "Iter 148 -> sub iter 99 : 55.873015873015874\n",
      "Iteration: 149\n",
      "Train accuracy: 56.54920634920635\n",
      "Val accuracy: 57.92857142857143\n",
      "Iter 149 -> sub iter 99 : 55.873015873015875\n",
      "Iteration: 150\n",
      "Train accuracy: 56.56031746031746\n",
      "Val accuracy: 57.92857142857143\n"
     ]
    }
   ],
   "source": [
    "for pert in pertList:\n",
    "    print(f\"Training for {pert}\")\n",
    "    W1, b1, W2, b2, W3, b3, train_acc, val_acc, train_loss, val_loss, sum_weights = batchGDNP(x_train,y_train,epochsToTrain, 0.01, pert, 1)\n",
    "    trainAccPertList.append(train_acc)\n",
    "    valAccPertList.append(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n",
      "Iteration: 1\n",
      "Train accuracy: 81.30158730158729\n",
      "Val accuracy: 81.25714285714287\n",
      "Iteration: 2\n",
      "Train accuracy: 86.32698412698413\n",
      "Val accuracy: 86.38571428571429\n",
      "Iteration: 3\n",
      "Train accuracy: 88.46507936507936\n",
      "Val accuracy: 88.15714285714286\n",
      "Iteration: 4\n",
      "Train accuracy: 89.75079365079365\n",
      "Val accuracy: 89.12857142857142\n",
      "Iteration: 5\n",
      "Train accuracy: 90.65555555555555\n",
      "Val accuracy: 89.87142857142857\n",
      "Iteration: 6\n",
      "Train accuracy: 91.42698412698412\n",
      "Val accuracy: 90.65714285714286\n",
      "Iteration: 7\n",
      "Train accuracy: 91.93174603174603\n",
      "Val accuracy: 91.08571428571427\n",
      "Iteration: 8\n",
      "Train accuracy: 92.41428571428571\n",
      "Val accuracy: 91.47142857142858\n",
      "Iteration: 9\n",
      "Train accuracy: 92.77142857142857\n",
      "Val accuracy: 91.78571428571428\n",
      "Iteration: 10\n",
      "Train accuracy: 93.13650793650794\n",
      "Val accuracy: 92.05714285714286\n",
      "Iteration: 11\n",
      "Train accuracy: 93.44285714285714\n",
      "Val accuracy: 92.31428571428572\n",
      "Iteration: 12\n",
      "Train accuracy: 93.75396825396825\n",
      "Val accuracy: 92.67142857142858\n",
      "Iteration: 13\n",
      "Train accuracy: 94.00952380952381\n",
      "Val accuracy: 92.87142857142857\n",
      "Iteration: 14\n",
      "Train accuracy: 94.22857142857143\n",
      "Val accuracy: 93.02857142857142\n",
      "Iteration: 15\n",
      "Train accuracy: 94.41746031746032\n",
      "Val accuracy: 93.28571428571428\n",
      "Iteration: 16\n",
      "Train accuracy: 94.61904761904762\n",
      "Val accuracy: 93.42857142857143\n",
      "Iteration: 17\n",
      "Train accuracy: 94.81269841269841\n",
      "Val accuracy: 93.60000000000001\n",
      "Iteration: 18\n",
      "Train accuracy: 94.97777777777779\n",
      "Val accuracy: 93.75714285714287\n",
      "Iteration: 19\n",
      "Train accuracy: 95.10793650793651\n",
      "Val accuracy: 93.91428571428571\n",
      "Iteration: 20\n",
      "Train accuracy: 95.23174603174603\n",
      "Val accuracy: 94.05714285714286\n",
      "Iteration: 21\n",
      "Train accuracy: 95.32698412698413\n",
      "Val accuracy: 94.17142857142858\n",
      "Iteration: 22\n",
      "Train accuracy: 95.44444444444444\n",
      "Val accuracy: 94.38571428571429\n",
      "Iteration: 23\n",
      "Train accuracy: 95.55396825396826\n",
      "Val accuracy: 94.41428571428571\n",
      "Iteration: 24\n",
      "Train accuracy: 95.67301587301587\n",
      "Val accuracy: 94.5\n",
      "Iteration: 25\n",
      "Train accuracy: 95.76666666666667\n",
      "Val accuracy: 94.65714285714286\n",
      "Iteration: 26\n",
      "Train accuracy: 95.85555555555555\n",
      "Val accuracy: 94.74285714285713\n",
      "Iteration: 27\n",
      "Train accuracy: 95.96349206349205\n",
      "Val accuracy: 94.71428571428572\n",
      "Iteration: 28\n",
      "Train accuracy: 96.05873015873016\n",
      "Val accuracy: 94.77142857142857\n",
      "Iteration: 29\n",
      "Train accuracy: 96.16031746031746\n",
      "Val accuracy: 94.78571428571428\n",
      "Iteration: 30\n",
      "Train accuracy: 96.22857142857143\n",
      "Val accuracy: 94.8\n",
      "Iteration: 31\n",
      "Train accuracy: 96.32222222222222\n",
      "Val accuracy: 94.8\n",
      "Iteration: 32\n",
      "Train accuracy: 96.38571428571429\n",
      "Val accuracy: 94.85714285714286\n",
      "Iteration: 33\n",
      "Train accuracy: 96.44761904761904\n",
      "Val accuracy: 94.87142857142857\n",
      "Iteration: 34\n",
      "Train accuracy: 96.52380952380952\n",
      "Val accuracy: 94.92857142857143\n",
      "Iteration: 35\n",
      "Train accuracy: 96.58412698412698\n",
      "Val accuracy: 94.94285714285714\n",
      "Iteration: 36\n",
      "Train accuracy: 96.64920634920635\n",
      "Val accuracy: 94.97142857142858\n",
      "Iteration: 37\n",
      "Train accuracy: 96.71746031746031\n",
      "Val accuracy: 94.98571428571428\n",
      "Iteration: 38\n",
      "Train accuracy: 96.77460317460319\n",
      "Val accuracy: 94.95714285714286\n",
      "Iteration: 39\n",
      "Train accuracy: 96.83492063492064\n",
      "Val accuracy: 94.97142857142858\n",
      "Iteration: 40\n",
      "Train accuracy: 96.8920634920635\n",
      "Val accuracy: 95.0\n",
      "Iteration: 41\n",
      "Train accuracy: 96.93968253968254\n",
      "Val accuracy: 95.02857142857142\n",
      "Iteration: 42\n",
      "Train accuracy: 96.98571428571428\n",
      "Val accuracy: 95.08571428571429\n",
      "Iteration: 43\n",
      "Train accuracy: 97.04444444444445\n",
      "Val accuracy: 95.08571428571429\n",
      "Iteration: 44\n",
      "Train accuracy: 97.10952380952381\n",
      "Val accuracy: 95.19999999999999\n",
      "Iteration: 45\n",
      "Train accuracy: 97.15079365079366\n",
      "Val accuracy: 95.24285714285713\n",
      "Iteration: 46\n",
      "Train accuracy: 97.18730158730159\n",
      "Val accuracy: 95.27142857142857\n",
      "Iteration: 47\n",
      "Train accuracy: 97.24285714285715\n",
      "Val accuracy: 95.32857142857142\n",
      "Iteration: 48\n",
      "Train accuracy: 97.27936507936508\n",
      "Val accuracy: 95.42857142857143\n",
      "Iteration: 49\n",
      "Train accuracy: 97.32222222222222\n",
      "Val accuracy: 95.45714285714286\n",
      "Iteration: 50\n",
      "Train accuracy: 97.35555555555555\n",
      "Val accuracy: 95.5\n",
      "Iteration: 51\n",
      "Train accuracy: 97.4015873015873\n",
      "Val accuracy: 95.51428571428572\n",
      "Iteration: 52\n",
      "Train accuracy: 97.43333333333334\n",
      "Val accuracy: 95.51428571428572\n",
      "Iteration: 53\n",
      "Train accuracy: 97.46507936507936\n",
      "Val accuracy: 95.54285714285714\n",
      "Iteration: 54\n",
      "Train accuracy: 97.5047619047619\n",
      "Val accuracy: 95.61428571428571\n",
      "Iteration: 55\n",
      "Train accuracy: 97.53333333333333\n",
      "Val accuracy: 95.6\n",
      "Iteration: 56\n",
      "Train accuracy: 97.56190476190476\n",
      "Val accuracy: 95.6\n",
      "Iteration: 57\n",
      "Train accuracy: 97.6047619047619\n",
      "Val accuracy: 95.62857142857143\n",
      "Iteration: 58\n",
      "Train accuracy: 97.65714285714286\n",
      "Val accuracy: 95.61428571428571\n",
      "Iteration: 59\n",
      "Train accuracy: 97.68412698412699\n",
      "Val accuracy: 95.62857142857143\n",
      "Iteration: 60\n",
      "Train accuracy: 97.72539682539683\n",
      "Val accuracy: 95.62857142857143\n",
      "Iteration: 61\n",
      "Train accuracy: 97.75714285714285\n",
      "Val accuracy: 95.64285714285714\n",
      "Iteration: 62\n",
      "Train accuracy: 97.79841269841269\n",
      "Val accuracy: 95.64285714285714\n",
      "Iteration: 63\n",
      "Train accuracy: 97.82857142857144\n",
      "Val accuracy: 95.64285714285714\n",
      "Iteration: 64\n",
      "Train accuracy: 97.86190476190477\n",
      "Val accuracy: 95.65714285714286\n",
      "Iteration: 65\n",
      "Train accuracy: 97.89523809523808\n",
      "Val accuracy: 95.68571428571428\n",
      "Iteration: 66\n",
      "Train accuracy: 97.93333333333332\n",
      "Val accuracy: 95.68571428571428\n",
      "Iteration: 67\n",
      "Train accuracy: 97.96190476190476\n",
      "Val accuracy: 95.72857142857143\n",
      "Iteration: 68\n",
      "Train accuracy: 97.9904761904762\n",
      "Val accuracy: 95.67142857142858\n",
      "Iteration: 69\n",
      "Train accuracy: 98.03492063492062\n",
      "Val accuracy: 95.67142857142858\n",
      "Iteration: 70\n",
      "Train accuracy: 98.05873015873016\n",
      "Val accuracy: 95.7\n",
      "Iteration: 71\n",
      "Train accuracy: 98.0904761904762\n",
      "Val accuracy: 95.72857142857143\n",
      "Iteration: 72\n",
      "Train accuracy: 98.12222222222222\n",
      "Val accuracy: 95.75714285714285\n",
      "Iteration: 73\n",
      "Train accuracy: 98.15079365079366\n",
      "Val accuracy: 95.77142857142857\n",
      "Iteration: 74\n",
      "Train accuracy: 98.18730158730159\n",
      "Val accuracy: 95.77142857142857\n",
      "Iteration: 75\n",
      "Train accuracy: 98.21904761904761\n",
      "Val accuracy: 95.8\n",
      "Iteration: 76\n",
      "Train accuracy: 98.25555555555555\n",
      "Val accuracy: 95.81428571428572\n",
      "Iteration: 77\n",
      "Train accuracy: 98.27460317460317\n",
      "Val accuracy: 95.78571428571429\n",
      "Iteration: 78\n",
      "Train accuracy: 98.3015873015873\n",
      "Val accuracy: 95.78571428571429\n",
      "Iteration: 79\n",
      "Train accuracy: 98.32539682539682\n",
      "Val accuracy: 95.78571428571429\n",
      "Iteration: 80\n",
      "Train accuracy: 98.34126984126983\n",
      "Val accuracy: 95.78571428571429\n",
      "Iteration: 81\n",
      "Train accuracy: 98.37619047619047\n",
      "Val accuracy: 95.75714285714285\n",
      "Iteration: 82\n",
      "Train accuracy: 98.3873015873016\n",
      "Val accuracy: 95.77142857142857\n",
      "Iteration: 83\n",
      "Train accuracy: 98.42857142857143\n",
      "Val accuracy: 95.78571428571429\n",
      "Iteration: 84\n",
      "Train accuracy: 98.44126984126984\n",
      "Val accuracy: 95.8\n",
      "Iteration: 85\n",
      "Train accuracy: 98.47619047619047\n",
      "Val accuracy: 95.82857142857144\n",
      "Iteration: 86\n",
      "Train accuracy: 98.49365079365079\n",
      "Val accuracy: 95.8\n",
      "Iteration: 87\n",
      "Train accuracy: 98.53174603174604\n",
      "Val accuracy: 95.78571428571429\n",
      "Iteration: 88\n",
      "Train accuracy: 98.54285714285714\n",
      "Val accuracy: 95.8\n",
      "Iteration: 89\n",
      "Train accuracy: 98.56031746031746\n",
      "Val accuracy: 95.8\n",
      "Iteration: 90\n",
      "Train accuracy: 98.58888888888889\n",
      "Val accuracy: 95.81428571428572\n",
      "Iteration: 91\n",
      "Train accuracy: 98.615873015873\n",
      "Val accuracy: 95.81428571428572\n",
      "Iteration: 92\n",
      "Train accuracy: 98.64444444444445\n",
      "Val accuracy: 95.84285714285714\n",
      "Iteration: 93\n",
      "Train accuracy: 98.67301587301587\n",
      "Val accuracy: 95.85714285714285\n",
      "Iteration: 94\n",
      "Train accuracy: 98.69365079365079\n",
      "Val accuracy: 95.87142857142858\n",
      "Iteration: 95\n",
      "Train accuracy: 98.71904761904761\n",
      "Val accuracy: 95.84285714285714\n",
      "Iteration: 96\n",
      "Train accuracy: 98.74126984126984\n",
      "Val accuracy: 95.91428571428573\n",
      "Iteration: 97\n",
      "Train accuracy: 98.77301587301586\n",
      "Val accuracy: 95.88571428571429\n",
      "Iteration: 98\n",
      "Train accuracy: 98.79523809523809\n",
      "Val accuracy: 95.88571428571429\n",
      "Iteration: 99\n",
      "Train accuracy: 98.81111111111112\n",
      "Val accuracy: 95.88571428571429\n",
      "Iteration: 100\n",
      "Train accuracy: 98.82539682539682\n",
      "Val accuracy: 95.91428571428573\n",
      "Iteration: 101\n",
      "Train accuracy: 98.85714285714286\n",
      "Val accuracy: 95.92857142857143\n",
      "Iteration: 102\n",
      "Train accuracy: 98.87936507936507\n",
      "Val accuracy: 95.91428571428573\n",
      "Iteration: 103\n",
      "Train accuracy: 98.9031746031746\n",
      "Val accuracy: 95.92857142857143\n",
      "Iteration: 104\n",
      "Train accuracy: 98.93174603174603\n",
      "Val accuracy: 95.91428571428573\n",
      "Iteration: 105\n",
      "Train accuracy: 98.94126984126984\n",
      "Val accuracy: 95.94285714285714\n",
      "Iteration: 106\n",
      "Train accuracy: 98.96825396825398\n",
      "Val accuracy: 95.92857142857143\n",
      "Iteration: 107\n",
      "Train accuracy: 98.98412698412699\n",
      "Val accuracy: 95.94285714285714\n",
      "Iteration: 108\n",
      "Train accuracy: 98.9952380952381\n",
      "Val accuracy: 95.94285714285714\n",
      "Iteration: 109\n",
      "Train accuracy: 99.0142857142857\n",
      "Val accuracy: 95.88571428571429\n",
      "Iteration: 110\n",
      "Train accuracy: 99.02698412698413\n",
      "Val accuracy: 95.89999999999999\n",
      "Iteration: 111\n",
      "Train accuracy: 99.04920634920636\n",
      "Val accuracy: 95.91428571428573\n",
      "Iteration: 112\n",
      "Train accuracy: 99.06349206349206\n",
      "Val accuracy: 95.92857142857143\n",
      "Iteration: 113\n",
      "Train accuracy: 99.07936507936508\n",
      "Val accuracy: 95.92857142857143\n",
      "Iteration: 114\n",
      "Train accuracy: 99.0936507936508\n",
      "Val accuracy: 95.94285714285714\n",
      "Iteration: 115\n",
      "Train accuracy: 99.10793650793651\n",
      "Val accuracy: 95.95714285714286\n",
      "Iteration: 116\n",
      "Train accuracy: 99.12380952380953\n",
      "Val accuracy: 95.94285714285714\n",
      "Iteration: 117\n",
      "Train accuracy: 99.13333333333333\n",
      "Val accuracy: 95.94285714285714\n",
      "Iteration: 118\n",
      "Train accuracy: 99.15079365079366\n",
      "Val accuracy: 95.98571428571428\n",
      "Iteration: 119\n",
      "Train accuracy: 99.17142857142856\n",
      "Val accuracy: 95.97142857142858\n",
      "Iteration: 120\n",
      "Train accuracy: 99.1888888888889\n",
      "Val accuracy: 95.98571428571428\n",
      "Iteration: 121\n",
      "Train accuracy: 99.1984126984127\n",
      "Val accuracy: 95.98571428571428\n",
      "Iteration: 122\n",
      "Train accuracy: 99.20952380952382\n",
      "Val accuracy: 95.98571428571428\n",
      "Iteration: 123\n",
      "Train accuracy: 99.22222222222223\n",
      "Val accuracy: 96.01428571428572\n",
      "Iteration: 124\n",
      "Train accuracy: 99.23968253968253\n",
      "Val accuracy: 96.01428571428572\n",
      "Iteration: 125\n",
      "Train accuracy: 99.25079365079365\n",
      "Val accuracy: 96.05714285714285\n",
      "Iteration: 126\n",
      "Train accuracy: 99.25873015873016\n",
      "Val accuracy: 96.05714285714285\n",
      "Iteration: 127\n",
      "Train accuracy: 99.28412698412698\n",
      "Val accuracy: 96.04285714285714\n",
      "Iteration: 128\n",
      "Train accuracy: 99.2904761904762\n",
      "Val accuracy: 96.04285714285714\n",
      "Iteration: 129\n",
      "Train accuracy: 99.31269841269841\n",
      "Val accuracy: 96.04285714285714\n",
      "Iteration: 130\n",
      "Train accuracy: 99.32539682539682\n",
      "Val accuracy: 96.05714285714285\n",
      "Iteration: 131\n",
      "Train accuracy: 99.34444444444445\n",
      "Val accuracy: 96.04285714285714\n",
      "Iteration: 132\n",
      "Train accuracy: 99.35555555555555\n",
      "Val accuracy: 96.07142857142857\n",
      "Iteration: 133\n",
      "Train accuracy: 99.36666666666667\n",
      "Val accuracy: 96.08571428571429\n",
      "Iteration: 134\n",
      "Train accuracy: 99.38253968253969\n",
      "Val accuracy: 96.08571428571429\n",
      "Iteration: 135\n",
      "Train accuracy: 99.39365079365079\n",
      "Val accuracy: 96.1\n",
      "Iteration: 136\n",
      "Train accuracy: 99.4\n",
      "Val accuracy: 96.11428571428571\n",
      "Iteration: 137\n",
      "Train accuracy: 99.40476190476191\n",
      "Val accuracy: 96.11428571428571\n",
      "Iteration: 138\n",
      "Train accuracy: 99.42063492063492\n",
      "Val accuracy: 96.08571428571429\n",
      "Iteration: 139\n",
      "Train accuracy: 99.43650793650794\n",
      "Val accuracy: 96.12857142857143\n",
      "Iteration: 140\n",
      "Train accuracy: 99.44920634920635\n",
      "Val accuracy: 96.1\n",
      "Iteration: 141\n",
      "Train accuracy: 99.45079365079366\n",
      "Val accuracy: 96.11428571428571\n",
      "Iteration: 142\n",
      "Train accuracy: 99.47460317460317\n",
      "Val accuracy: 96.11428571428571\n",
      "Iteration: 143\n",
      "Train accuracy: 99.48253968253968\n",
      "Val accuracy: 96.11428571428571\n",
      "Iteration: 144\n",
      "Train accuracy: 99.4920634920635\n",
      "Val accuracy: 96.1\n",
      "Iteration: 145\n",
      "Train accuracy: 99.51269841269841\n",
      "Val accuracy: 96.1\n",
      "Iteration: 146\n",
      "Train accuracy: 99.51587301587301\n",
      "Val accuracy: 96.12857142857143\n",
      "Iteration: 147\n",
      "Train accuracy: 99.52698412698413\n",
      "Val accuracy: 96.14285714285714\n",
      "Iteration: 148\n",
      "Train accuracy: 99.53492063492064\n",
      "Val accuracy: 96.17142857142858\n",
      "Iteration: 149\n",
      "Train accuracy: 99.54126984126984\n",
      "Val accuracy: 96.14285714285714\n",
      "Iteration: 150\n",
      "Train accuracy: 99.55238095238094\n",
      "Val accuracy: 96.14285714285714\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3, train_acc_bp, val_acc_bp, train_loss_bp, val_loss_bp, sum_weights_bp = batch_grad_descent(x_train,y_train,epochsToTrain, 0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14c18eaf250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(trainAccPertList[-1], \"r.\")\n",
    "plt.plot(train_acc_bp, \"gx\")\n",
    "plt.title([\"Training accuracy using node perturbation(baseline)\"])\n",
    "plt.xlabel(\"Epochs\", size=10)\n",
    "plt.ylabel(\"Training accuracy\", size = 10)\n",
    "plt.legend([\"NP\", \"BP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 63000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = one_hot_encoding(y_train)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Initialised\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = params_init()\n",
    "Z1, A1, Z2, A2, Z3, A3 = forward(x_train, W1, b1, W2, b2, W3, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.026984126984125"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions(A3), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = Z1- np.max(Z1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-12.25566136,  -9.77496698,  -8.79695744, ...,  -7.80636298,\n",
       "        -15.92526741, -20.02611282],\n",
       "       [ -9.72121696,  -6.22091867,  -4.8731629 , ...,  -2.55752564,\n",
       "         -6.59775347,  -8.95087339],\n",
       "       [ -9.92643277,  -7.37246957,  -4.52480223, ...,  -4.3854183 ,\n",
       "         -7.4639615 , -14.91604123],\n",
       "       ...,\n",
       "       [ -9.19078321, -10.62944845,  -5.44019187, ...,  -7.29793901,\n",
       "         -8.65648547, -15.0731984 ],\n",
       "       [-10.07853589,  -7.45615704,  -4.86311216, ...,  -3.71657699,\n",
       "         -6.66754462,  -9.58466006],\n",
       "       [ -9.76332042,  -9.69017676,  -7.12985019, ...,  -3.66609792,\n",
       "         -7.81213824, -11.37297805]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.79819857e-06, 1.57063805e-05, 2.90428273e-05, ...,\n",
       "        4.92898014e-05, 5.26667133e-08, 1.95759529e-09],\n",
       "       [4.78930925e-05, 5.49009277e-04, 1.46933629e-03, ...,\n",
       "        9.38205907e-03, 5.92139527e-04, 1.26368340e-04],\n",
       "       [3.90075601e-05, 1.73567131e-04, 2.08167210e-03, ...,\n",
       "        1.50818448e-03, 2.49020261e-04, 3.24338723e-07],\n",
       "       ...,\n",
       "       [8.14024228e-05, 6.68312413e-06, 8.33419493e-04, ...,\n",
       "        8.19526110e-05, 7.55662908e-05, 2.77170056e-07],\n",
       "       [3.35035820e-05, 1.59632927e-04, 1.48417867e-03, ...,\n",
       "        2.94393730e-03, 5.52222552e-04, 6.70483701e-05],\n",
       "       [4.59184882e-05, 1.70962177e-05, 1.53834721e-04, ...,\n",
       "        3.09635923e-03, 1.75801852e-04, 1.12132523e-05]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(Z1)/np.sum(np.exp(Z1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Z3.shape[1]\n",
    "pert = 0.1\n",
    "lossBeforePert = np.sum((A3-one_hot_encoding(y_train))**2, axis=0)\n",
    "lossArrayAfterPertZ3 = np.zeros_like(Z3)\n",
    "for i in range(Z3.shape[0]):\n",
    "    Z3pert = Z3.copy() #creates a local copy of the array since python arrays are sent by reference andnot copy!!\n",
    "    Z3pert[i] +=  pert\n",
    "    A3pert = softmax(Z3pert)\n",
    "    lossArrayAfterPertZ3[i] = np.sum((A3pert-one_hot_encoding(y_train))**2, axis=0)\n",
    "\n",
    "\n",
    "dZ3 = (lossArrayAfterPertZ3 - lossBeforePert)/pert\n",
    "\n",
    "dW3 = 1/m*np.matmul(dZ3,A2.T)\n",
    "\n",
    "db3 = 1/m*np.sum(dZ3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossArrayAfterPertZ2 = np.zeros_like(Z2)\n",
    "\n",
    "for i in range(Z2.shape[0]):\n",
    "    Z2pert = Z2.copy()\n",
    "    Z2pert[i] += pert\n",
    "\n",
    "    A2pert = relu(Z2pert)\n",
    "\n",
    "    Z3pert = np.matmul(W3,A2pert) + b3\n",
    "    A3pert = softmax(Z3pert)\n",
    "    lossArrayAfterPertZ2[i] = np.sum((A3pert-one_hot_encoding(y_train))**2, axis=0)\n",
    "\n",
    "\n",
    "dZ2 = (lossArrayAfterPertZ2 - lossBeforePert)/pert\n",
    "\n",
    "dW2 = 1/m*np.matmul(dZ2,A1.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "db2 = 1/m*np.sum(dZ2, axis=1) #db1 is 50*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.44652722e-05, -1.91071142e-03, -6.83915406e-04, ...,\n",
       "         1.04829187e-04, -1.18278904e-03, -7.32349391e-05],\n",
       "       [ 6.67987678e-05, -6.42835995e-03, -3.27877653e-04, ...,\n",
       "         7.59078499e-04,  5.46900503e-04, -5.25011768e-03],\n",
       "       [ 1.47084256e-04,  7.05337784e-03,  3.20616679e-03, ...,\n",
       "         8.04822963e-04,  1.13577690e-03,  9.12609766e-03],\n",
       "       ...,\n",
       "       [ 7.65987155e-05,  5.07250451e-03, -2.77136700e-03, ...,\n",
       "        -7.51528691e-04,  1.75562552e-03, -5.69986091e-04],\n",
       "       [ 1.66104750e-04,  4.44860294e-03, -1.58931222e-04, ...,\n",
       "        -2.10381943e-04,  2.30341943e-04,  3.00307195e-03],\n",
       "       [ 2.78581124e-07,  1.40669897e-04,  9.54493959e-05, ...,\n",
       "         3.54828288e-05,  1.59083036e-04,  2.20893989e-04]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub iter: 0\n",
      "sub iter: 1\n",
      "sub iter: 2\n",
      "sub iter: 3\n",
      "sub iter: 4\n",
      "sub iter: 5\n",
      "sub iter: 6\n",
      "sub iter: 7\n",
      "sub iter: 8\n",
      "sub iter: 9\n",
      "sub iter: 10\n",
      "sub iter: 11\n",
      "sub iter: 12\n",
      "sub iter: 13\n",
      "sub iter: 14\n",
      "sub iter: 15\n",
      "sub iter: 16\n",
      "sub iter: 17\n",
      "sub iter: 18\n",
      "sub iter: 19\n",
      "sub iter: 20\n",
      "sub iter: 21\n",
      "sub iter: 22\n",
      "sub iter: 23\n",
      "sub iter: 24\n",
      "sub iter: 25\n",
      "sub iter: 26\n",
      "sub iter: 27\n",
      "sub iter: 28\n",
      "sub iter: 29\n",
      "sub iter: 30\n",
      "sub iter: 31\n",
      "sub iter: 32\n",
      "sub iter: 33\n",
      "sub iter: 34\n",
      "sub iter: 35\n",
      "sub iter: 36\n",
      "sub iter: 37\n",
      "sub iter: 38\n",
      "sub iter: 39\n",
      "sub iter: 40\n",
      "sub iter: 41\n",
      "sub iter: 42\n",
      "sub iter: 43\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000032?line=5'>6</a>\u001b[0m A1pert \u001b[39m=\u001b[39m relu(Z1pert)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000032?line=7'>8</a>\u001b[0m Z2pert \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(W2,A1pert) \u001b[39m+\u001b[39m b2 \n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000032?line=8'>9</a>\u001b[0m A2pert \u001b[39m=\u001b[39m relu(Z2pert)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000032?line=10'>11</a>\u001b[0m Z3pert \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(W3,A2pert) \u001b[39m+\u001b[39m b3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000032?line=11'>12</a>\u001b[0m A3pert \u001b[39m=\u001b[39m softmax(Z3pert)\n",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 5'\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000009?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrelu\u001b[39m(x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000009?line=48'>49</a>\u001b[0m    \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mmaximum(x,\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossArrayAfterPertZ1 = np.zeros_like(Z1)\n",
    "for i in range(Z1.shape[0]):\n",
    "    Z1pert = Z1.copy()\n",
    "    Z1pert[i] += pert\n",
    "\n",
    "    A1pert = relu(Z1pert)\n",
    "\n",
    "    Z2pert = np.matmul(W2,A1pert) + b2 \n",
    "    A2pert = relu(Z2pert)\n",
    "\n",
    "    Z3pert = np.matmul(W3,A2pert) + b3\n",
    "    A3pert = softmax(Z3pert)\n",
    "    print(f\"sub iter: {i}\")\n",
    "\n",
    "    lossArrayAfterPertZ1[i] = np.sum((A3pert-one_hot_encoding(y_train))**2, axis=0)\n",
    "\n",
    "dZ1 = (lossArrayAfterPertZ1 - lossBeforePert)/pert\n",
    "\n",
    "dW1 = 1/m*np.matmul(dZ1,x_train.T) #shape of dZ1 is 50*m, X is 784*m, dW1 = 50*784\n",
    "\n",
    "db1 = 1/m*np.sum(dZ1, axis = 1) #db1 is 50*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99999689, 1.90408986, 1.99817536, ..., 1.45310182, 0.0673587 ,\n",
       "        1.51451512],\n",
       "       [1.99999689, 1.90410139, 1.99817758, ..., 1.45310182, 0.07905707,\n",
       "        1.52943448],\n",
       "       [1.99999689, 1.90410138, 1.99817758, ..., 1.45310174, 0.07905707,\n",
       "        1.52943404],\n",
       "       ...,\n",
       "       [1.99999689, 1.90410139, 1.99817743, ..., 1.44761844, 0.07906075,\n",
       "        1.56006023],\n",
       "       [1.99999689, 1.90410131, 1.99809366, ..., 1.45310182, 0.07905746,\n",
       "        1.52942324],\n",
       "       [1.99999689, 1.8981823 , 1.99817747, ..., 1.44839261, 0.09191522,\n",
       "        1.52362005]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossArrayAfterPertZ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 63000)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((A3-Y)**2, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 4,  5],\n",
       "       [56, 67]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2], [4,5], [56, 67]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  67, 126, 113,  63, 133,  29, 134, 135, 169],\n",
       "       [126, 163, 171,  33,  81,  89, 178, 175, 114, 159],\n",
       "       [124, 110,  47, 114,  85, 175, 122,  30, 175,   8],\n",
       "       [101,  16,  33,  15,  25, 149,  98,  48,  61, 196],\n",
       "       [ 40, 107, 143,  19, 177,   2,  18,  20, 191, 118],\n",
       "       [ 61,  55, 136, 176,  18,  23,  66,  34, 145, 142]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.randint(1, 200, (6, 10))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59,  14,  35, 133,  88, 191, 129,  52, 174, 143])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(a):\n",
    "    c = a.copy()\n",
    "    c[1] += 4\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  67, 126, 113,  63, 133,  29, 134, 135, 169],\n",
       "       [130, 167, 175,  37,  85,  93, 182, 179, 118, 163],\n",
       "       [124, 110,  47, 114,  85, 175, 122,  30, 175,   8],\n",
       "       [101,  16,  33,  15,  25, 149,  98,  48,  61, 196],\n",
       "       [ 40, 107, 143,  19, 177,   2,  18,  20, 191, 118],\n",
       "       [ 61,  55, 136, 176,  18,  23,  66,  34, 145, 142]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = myfunc(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  67, 126, 113,  63, 133,  29, 134, 135, 169],\n",
       "       [126, 163, 171,  33,  81,  89, 178, 175, 114, 159],\n",
       "       [124, 110,  47, 114,  85, 175, 122,  30, 175,   8],\n",
       "       [101,  16,  33,  15,  25, 149,  98,  48,  61, 196],\n",
       "       [ 40, 107, 143,  19, 177,   2,  18,  20, 191, 118],\n",
       "       [ 61,  55, 136, 176,  18,  23,  66,  34, 145, 142]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,    8],\n",
       "       [  20,   29],\n",
       "       [3140, 4493]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = np.vectorize(myfunc)\n",
    "ss(a, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array() missing required argument 'object' (pos 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000019?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray()\n",
      "\u001b[1;31mTypeError\u001b[0m: array() missing required argument 'object' (pos 0)"
     ]
    }
   ],
   "source": [
    "a = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a, np.array([1,2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000024?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mappend(a, [np\u001b[39m.\u001b[39;49marray([\u001b[39m3\u001b[39;49m,\u001b[39m55\u001b[39;49m])], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:5440\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5438\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[0;32m   5439\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 5440\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "np.append(a, [np.array([3,55])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\perturbation_on_chip_learning\\Perturbation-techniques-in-CNNs\\code\\mnistNodePert.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/perturbation_on_chip_learning/Perturbation-techniques-in-CNNs/code/mnistNodePert.ipynb#ch0000025?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mvstack([a, np\u001b[39m.\u001b[39;49marray([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m])])\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "np.vstack([a, np.array([1,2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The factors of 12324049 are [12324049, 1597, 7717]\n",
      "The factors of 880325 are [880325, 5, 176065, 5, 35213, 23, 1531]\n",
      "The factors of 35468037 are [35468037, 11822679, 3940893, 1313631, 437877, 145959, 48653, 11, 4423]\n",
      "The factors of 11931245 are [11931245, 5, 2386249, 179, 13331]\n",
      "The factors of 44357249 are [44357249, 31, 1430879]\n",
      "The factors of 28560023 are [28560023, 67, 426269, 439, 971]\n",
      "The factors of 20507042 are [10253521, 19, 539659, 109, 4951]\n",
      "The factors of 28460977 are [28460977, 29, 981413, 613, 1601]\n",
      "The factors of 34336910 are [17168455, 5, 3433691]\n",
      "The factors of 24294129 are [24294129, 8098043]\n",
      "The factors of 4310270 are [2155135, 5, 431027, 29, 14863, 89, 167]\n",
      "The factors of 30462664 are [3807833]\n",
      "The factors of 3195983 are [3195983, 7, 456569, 17, 26857, 107, 251]\n",
      "The factors of 31280688 are [1955043, 651681, 217227, 72409, 19, 3811, 37, 103]\n",
      "The factors of 47429094 are [23714547, 7904849, 29, 272581]\n",
      "The factors of 37800281 are [37800281]\n",
      "The factors of 27288491 are [27288491, 83, 328777]\n",
      "The factors of 47282187 are [47282187, 15760729, 59, 267131]\n",
      "The factors of 44190730 are [22095365, 5, 4419073]\n",
      "The factors of 14441296 are [902581, 17, 53093]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing  \n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "import test\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    to_factor = [ random.randint(100000, 50000000) for i in range(20)]\n",
    "    results = pool.map(test.prime_factor, to_factor)\n",
    "    for value, factors in zip(to_factor, results):\n",
    "        print(\"The factors of {} are {}\".format(value, factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
